{"meta":{"title":"七路灯","subtitle":"人的一生应当有许多停靠站，但愿每一个站台都有一盏雾中的灯。","description":"人的一生应当有许多停靠站，但愿每一个站台都有一盏雾中的灯。","author":"七路灯","url":"http://www.lights8080.com","root":"/"},"pages":[{"title":"about","date":"2021-05-26T12:06:18.000Z","updated":"2021-06-01T10:47:46.000Z","comments":true,"path":"about/index.html","permalink":"http://www.lights8080.com/about/index.html","excerpt":"","text":"从事互联网开发，信奉终身成长的技术人。分享知识和记录成长。"},{"title":"categories","date":"2021-05-26T12:04:49.000Z","updated":"2021-06-01T10:47:46.000Z","comments":true,"path":"categories/index.html","permalink":"http://www.lights8080.com/categories/index.html","excerpt":"","text":""},{"title":"contact","date":"2021-05-26T12:06:42.000Z","updated":"2021-06-01T10:47:46.000Z","comments":true,"path":"contact/index.html","permalink":"http://www.lights8080.com/contact/index.html","excerpt":"","text":""},{"title":"tags","date":"2021-05-26T12:05:59.000Z","updated":"2021-06-01T10:47:46.000Z","comments":true,"path":"tags/index.html","permalink":"http://www.lights8080.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"ELK-实践20210629","slug":"技术/ELK/ELK-实践20210629","date":"2021-06-28T16:00:00.000Z","updated":"2021-06-29T09:39:49.000Z","comments":true,"path":"2021/06/29/技术/ELK/ELK-实践20210629/","link":"","permalink":"http://www.lights8080.com/2021/06/29/%E6%8A%80%E6%9C%AF/ELK/ELK-%E5%AE%9E%E8%B7%B520210629/","excerpt":"复合聚合按计数排序，TSVB使用脚本字段，滚动升级，Elastic中国社区官方博客","text":"复合聚合按计数排序，TSVB使用脚本字段，滚动升级，Elastic中国社区官方博客 1. 复合聚合按计数排序123456789101112131415161718192021222324252627282930313233343536373839404142434445GET /service-exception/_search&#123; &quot;size&quot;: 0, &quot;query&quot;: &#123; &quot;range&quot;: &#123; &quot;@timestamp&quot;: &#123; &quot;gte&quot;: &quot;2021-05-06 00:00:00&quot;, &quot;lte&quot;: &quot;2021-05-06 23:59:59&quot;, &quot;format&quot;: &quot;yyyy-MM-dd HH:mm:ss&quot;, &quot;time_zone&quot;:&quot;+08:00&quot; &#125; &#125; &#125;, &quot;aggs&quot;: &#123; &quot;group_by_fields&quot;: &#123; &quot;composite&quot;:&#123; &quot;sources&quot;: [ &#123; &quot;service_name&quot;: &#123; &quot;terms&quot;: &#123; &quot;field&quot;: &quot;service_name&quot; &#125; &#125; &#125;,&#123; &quot;error_message&quot;: &#123; &quot;terms&quot;: &#123; &quot;field&quot;: &quot;error_message&quot; &#125; &#125; &#125; ], &quot;size&quot;: 50 &#125;, &quot;aggs&quot;: &#123; &quot;top_bucket_sort&quot;:&#123; &quot;bucket_sort&quot;: &#123; &quot;sort&quot;: [ &#123; &quot;_count&quot;: &#123; &quot;order&quot;: &quot;desc&quot; &#125; &#125; ] &#125; &#125; &#125; &#125; &#125;&#125; 2. TSVB使用脚本字段（[TSVB] Visualize Scripted Fields）https://github.com/elastic/kibana/issues/13928https://github.com/elastic/kibana/issues/11999https://github.com/elastic/kibana/issues/82438 3. 滚动升级（Rolling Upgrade Elasticsearch）https://www.elastic.co/guide/en/elasticsearch/reference/current/setup-upgrade.html 注意事项： 不支持在升级期间以外在同一集群中运行多个版本的Elasticsearch，因为不能将分片从升级的节点复制到运行旧版本的节点。 升级时将集群的节点划分为两组并按顺序升级组（第一组：Nodes that are not Master-eligible，第二组：Master-eligible nodes），可以确保所有Master-ineligible节点都能够加入集群，无论符合Master-eligible节点是否已经升级。 一旦您开始将集群升级到指定版本，您就必须完成升级，它可能对其内部状态进行无法恢复的更改 升级步骤： 禁用分片分配 停止非必要的索引和执行同步刷新(可选) 暂时停止与活动机器学习作业和数据源相关的任务(可选) 关闭单个节点 升级关闭的节点(如果没有使用外部数据目录，请将旧数据目录复制到新安装) 升级任何插件 启动升级后的节点 重新启用分片分配 等待节点恢复 对于需要更新的每个节点重复这些步骤 重新启动机器学习作业 检查 123456789101112131415161718192021222324252627282930313233# 升级时将集群的节点划分为两组并按顺序升级组GET /_nodes/_all,master:falseGET /_nodes/master:true# 禁用分片分配PUT _cluster/settings&#123; &quot;persistent&quot;: &#123; &quot;cluster.routing.allocation.enable&quot;: &quot;primaries&quot; &#125;&#125;# 停止非必要的索引和执行同步刷新POST _flush/synced# 重新启用分片分配PUT _cluster/settings&#123; &quot;persistent&quot;: &#123; &quot;cluster.routing.allocation.enable&quot;: null &#125;&#125;# 等待节点恢复GET _cat/health?v=true# 对于需要更新的每个节点重复这些步骤GET /_cat/health?v=trueGET /_cat/nodes?h=ip,name,version&amp;v=true# 重新启动机器学习作业POST _ml/set_upgrade_mode?enabled=false 4. Elastic中国社区官方博客Kibana：如何让用户匿名访问 Kibana 中的 DashboardElasticsearch：运用 Python 来实现对搜索结果的分页","categories":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/"},{"name":"ELK","slug":"技术/ELK","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/ELK/"}],"tags":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/tags/%E6%8A%80%E6%9C%AF/"},{"name":"ELK","slug":"ELK","permalink":"http://www.lights8080.com/tags/ELK/"}]},{"title":"JAVA面向对象编程思想","slug":"技术/JAVA/JAVA面向对象编程思想","date":"2021-06-23T16:00:00.000Z","updated":"2021-06-24T08:20:16.000Z","comments":true,"path":"2021/06/24/技术/JAVA/JAVA面向对象编程思想/","link":"","permalink":"http://www.lights8080.com/2021/06/24/%E6%8A%80%E6%9C%AF/JAVA/JAVA%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E7%BC%96%E7%A8%8B%E6%80%9D%E6%83%B3/","excerpt":"翻看之前总结的文本，整理时在重新理解这些概念，发现编程思想真的非常重要，是怎么把复杂的逻辑梳理结构化的过程。","text":"翻看之前总结的文本，整理时在重新理解这些概念，发现编程思想真的非常重要，是怎么把复杂的逻辑梳理结构化的过程。 如何理解面向对象编程只定义业务的框架，而不去实现具体业务功能。就像盖楼房，有楼梯、电梯、门的位置等；只提供了一个框架和公共设施，不去管住户室内的设计，让住户按照自己的需求去实现。如Struts：提供了MVC的流程架构，具体的展示和业务实现交给用户处理。 面向接口编程：实现应用层与实现层的分离，提高系统维护和扩展。通过接口约束对象的属性和行为，是面向对象的一部分。 面向对象编程优点：1）易维护：代码可读性高，维护成本低2）易扩展：由于封装、继承、多态的特征设计出高内聚、低耦合的系统架构，提高系统灵活性和扩展性。 耦合：模块之间的关联强度应该是比较弱的，即低耦合。内聚：模块内的各个元素的联系时紧密的，即高内聚。面向对象编程是一种思想。主要特征是：封装、继承、多态、抽象。5个设计原则。 面向对象编程特征： 封装：把过程和数据包围起来，通过已定义的界面访问数据。提高代码重用性。 继承：对象的一个新类可以从现有的类中派生，这个过程叫做继承。新类继承了原有类的属性和方法。提高代码重用性。 多态：允许不同类的对象对同一消息做出响应。提高灵活性和重用性。 抽象：分离对象的行为和实现。 面向对象设计原则： 单一职责原则(Single Responsibility Principle-SRP)：一个对象只有一种单一的职责。过多的职责会使代码牵一发而动全身。 开放封闭原则(Open-Closed Principle-OCP)：对扩展开放，对修改封闭。是面向对象所有原则的核心。 依赖倒置原则(Dependency Inversion Principle-DIP)：核心思想是依赖于抽象，不依赖于具体。是面向对象设计的精髓。抽象的稳定性决定了系统的稳定性，因为抽象是不变的。 接口隔离原则(Interface Segregation Principle-ISP)：定义许多特定的接口好过定义一个通用的接口。 里氏替换原则(Liskvo Substitution Principle-LSP)：程序中子类必须能够替换其父类，这是保证继承复用的基础。是关于继承机制的设计原则。保证系统具有良好的拓展性，同时实现基于多态的抽象机制，能够减少代码冗余，避免运行期的类型判别。 迪米特法则(Law of Demeter or Least Knowlegde Principle-LoD or LKP)：一个对象应该尽可能少的去了解其他对象。松耦合原则。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/"},{"name":"JAVA","slug":"技术/JAVA","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/JAVA/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"http://www.lights8080.com/tags/JAVA/"},{"name":"编程思想","slug":"编程思想","permalink":"http://www.lights8080.com/tags/%E7%BC%96%E7%A8%8B%E6%80%9D%E6%83%B3/"}]},{"title":"Maven","slug":"技术/JAVA/Maven","date":"2021-06-23T16:00:00.000Z","updated":"2021-06-24T08:48:08.000Z","comments":true,"path":"2021/06/24/技术/JAVA/Maven/","link":"","permalink":"http://www.lights8080.com/2021/06/24/%E6%8A%80%E6%9C%AF/JAVA/Maven/","excerpt":"","text":"依赖范围Maven在编译、测试、运行环境下都需要独立的一套classpath。 compile：（默认）编译依赖范围，对于编译、测试、运行三种classpath都有效。典型的是spring-core，三种环境都使用。 test：测试依赖范围，只对于测试classpath有效。典型的是Junit，测试时使用。 provided：已提供依赖范围，对于编译和测试classpath有效。典型的是servlet-api，容器已提供。 runtime：运行时依赖范围，对于测试和运行classpath有效。典型的是JDBC驱动实现，编译时JDK提供了JDBC接口。 system：系统依赖范围，往往与本地系统绑定，造成不可移植性，谨慎使用。 依赖原则传递性依赖：A项目–依赖于–&gt;B项目–依赖于–&gt;C项目。A项目对于C项目是传递性依赖。依赖调解：A–&gt;B–&gt;C–&gt;X(1.0)，A–&gt;D–&gt;X(2.0)。传递性依赖有可能造成依赖问题。这时候依赖路径上有两个X版本，该依赖那条路径下的X项目呢？路径选择原则，第一原则：路径最近者优先，第二原则：第一声明者优先。可选依赖：A–&gt;B，B–&gt;X(可选)，B–&gt;Y(可选)。可选依赖只会对当前项目B产生影响，依赖不会被传递，A不会有任何影响。例如：X为mysql驱动包，Y为oracle驱动包，这种情况只能依赖一种数据库驱动包。POM代码：true。推荐采用单一职责原则。为mysql和oracle分别建立Maven项目。就不存在可选依赖了。 Maven插件和生命周期Maven插件执行详解： maven-clean-plugin:2.5:clean (default-clean) 删除target目录 maven-resources-plugin:2.6:resources (default-resources) 拷贝主程序配置文件到target/classes目录 maven-compiler-plugin:2.5.1:compile (default-compile) 编译主程序目录java文件到target/classes目录 maven-resources-plugin:2.6:testResources (default-testResources) 拷贝测试程序配置文件到target/classes目录 maven-compiler-plugin:2.5.1:testCompile (default-testCompile) 编译测试程序目录java文件到target/classes目录 maven-surefire-plugin:2.12.4:test (default-test) 运行测试用例 maven-jar-plugin:2.4:jar (default-jar) 将项目主代码打包成jar文件（不包含测试程序和测试配置文件） maven-install-plugin:2.4:install (default-install) 将项目输出的jar文件安装到Maven本地仓库中 mvn命令执行过程： mvn clean default-clean mvn compile default-resources–&gt; default-compile mvn test mvn compile–&gt; default-testResources–&gt; default-testCompile–&gt; default-test mvn package mvn test–&gt; default-jar mvn install mvn package–&gt; default-install mvn deploy 项目构建输出的构件部署到对应的远程仓库 mvn clean install-U 强制让Maven检查更新 mvn help:describe -Dplugin=compiler 获取插件compiler的描述信息 mvn dependency:tree 获得项目依赖树 插件说明1、设置源文件编码方式2、解决资源文件的编码问题3、配置多个源文件夹4、打包source文件为jar文件5、拷贝依赖的jar包到目录6、生成源代码包7、打包jar文件时，配置manifest文件，加入lib包的jar依赖8、编译java文件使用依赖本地jar包9、打war包配置项目webContext相对路径、排除文件10、生成可执行jar文件111、生成可执行jar文件212、编译错误（错误: 不兼容的类型）增加配置13、跳过测试 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201&lt;!-- 解决资源文件的编码问题 --&gt;&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt; &lt;version&gt;2.3&lt;/version&gt; &lt;configuration&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;/configuration&gt;&lt;/plugin&gt;&lt;!-- 打包source文件为jar文件 --&gt;&lt;plugin&gt; &lt;artifactId&gt;maven-source-plugin&lt;/artifactId&gt; &lt;version&gt;2.1&lt;/version&gt; &lt;configuration&gt; &lt;attach&gt;true&lt;/attach&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;compile&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;jar&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt;&lt;!-- 拷贝依赖的jar包到目录 --&gt;&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;copy&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;copy-dependencies&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;outputDirectory&gt; $&#123;project.build.directory&#125;/dependency &lt;/outputDirectory&gt; &lt;includeScope&gt;runtime&lt;/includeScope&gt; &lt;excludeScope&gt;provided&lt;/excludeScope&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt;&lt;!-- 设置源文件编码方式 --&gt;&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;defaultLibBundleDir&gt;lib&lt;/defaultLibBundleDir&gt; &lt;source&gt;1.6&lt;/source&gt; &lt;target&gt;1.6&lt;/target&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;/configuration&gt;&lt;/plugin&gt;&lt;!-- 打包jar文件时，配置manifest文件，加入lib包的jar依赖 --&gt;&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;archive&gt; &lt;manifest&gt; &lt;addClasspath&gt;true&lt;/addClasspath&gt; &lt;classpathPrefix&gt;lib/&lt;/classpathPrefix&gt; &lt;mainClass&gt;.....MonitorMain&lt;/mainClass&gt; &lt;/manifest&gt; &lt;/archive&gt; &lt;/configuration&gt;&lt;/plugin&gt;&lt;!-- 配置多个源文件夹 --&gt;&lt;plugin&gt; &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt; &lt;artifactId&gt;build-helper-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;generate-sources&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;add-source&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;sources&gt; &lt;source&gt;src/utils&lt;/source&gt; &lt;source&gt;src/platform&lt;/source&gt; &lt;/sources&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt;&lt;!-- 编译java文件使用依赖本地jar包 --&gt;&lt;plugin&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;source&gt;1.6&lt;/source&gt; &lt;target&gt;1.6&lt;/target&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;compilerArguments&gt; &lt;extdirs&gt;src\\main\\webapp\\WEB-INF\\lib或$&#123;basedir&#125;/WebContent/WEB-INF/lib&lt;/extdirs&gt; &lt;/compilerArguments&gt; &lt;/configuration&gt;&lt;/plugin&gt;&lt;!-- 打war包配置项目webContext相对路径、排除文件 --&gt;&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-war-plugin&lt;/artifactId&gt; &lt;version&gt;2.4&lt;/version&gt; &lt;configuration&gt; &lt;!--包含空文件夹--&gt; &lt;includeEmptyDirectories&gt;true&lt;/includeEmptyDirectories&gt; &lt;warSourceDirectory&gt;WebContent&lt;/warSourceDirectory&gt; &lt;!-- 排除文件 --&gt; &lt;packagingExcludes&gt;WEB-INF/classes/**/*.*,WEB-INF/lib/**/*&lt;/packagingExcludes&gt; &lt;!--将类文件打成jar包--&gt; &lt;archiveClasses&gt;true&lt;/archiveClasses&gt; &lt;/configuration&gt;&lt;/plugin&gt;&lt;!-- 生成源代码包 --&gt;&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-source-plugin&lt;/artifactId&gt; &lt;version&gt;2.1.1&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;attach-sources&lt;/id&gt; &lt;phase&gt;verify&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;jar-no-fork&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt;&lt;!-- 生成可执行jar文件1 --&gt;&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;archive&gt; &lt;manifest&gt; &lt;addClasspath&gt;true&lt;/addClasspath&gt; &lt;classpathPrefix&gt;lib/&lt;/classpathPrefix&gt; &lt;mainClass&gt;com.abc.ABCTest&lt;/mainClass&gt;&lt;!-- 入口类名 --&gt; &lt;/manifest&gt; &lt;/archive&gt; &lt;/configuration&gt;&lt;/plugin&gt;&lt;!-- 生成可执行jar文件2 执行命令：mvn clean install --&gt;&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt; &lt;version&gt;1.2.1&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;shade&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;transformers&gt; &lt;transformer implementation=&quot;org.apache.maven.plugins.shade.resource.ManifestResourceTransformer&quot;&gt; &lt;mainClass&gt;com.lihp.mvnbook.helloworld.HelloWorld&lt;/mainClass&gt; &lt;/transformer&gt; &lt;/transformers&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt;&lt;!-- 编译错误（错误: 不兼容的类型）增加配置 --&gt;&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.1&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.7&lt;/source&gt; &lt;target&gt;1.7&lt;/target&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;compilerId&gt;csharp&lt;/compilerId&gt; &lt;compilerArguments&gt; &lt;extdirs&gt;$&#123;lib.dir&#125;&lt;/extdirs&gt; &lt;/compilerArguments&gt; &lt;/configuration&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.codehaus.plexus&lt;/groupId&gt; &lt;artifactId&gt;plexus-compiler-csharp&lt;/artifactId&gt; &lt;version&gt;1.6&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/plugin&gt;&lt;!-- 跳过测试 --&gt;&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt; &lt;version&gt;2.5&lt;/version&gt; &lt;configuration&gt; &lt;skipTests&gt;true&lt;/skipTests&gt; &lt;/configuration&gt; &lt;/plugin&gt;","categories":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/"},{"name":"Java","slug":"技术/Java","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/Java/"}],"tags":[{"name":"Maven","slug":"Maven","permalink":"http://www.lights8080.com/tags/Maven/"}]},{"title":"编码","slug":"技术/JAVA/编码","date":"2021-06-23T16:00:00.000Z","updated":"2021-06-24T08:40:30.000Z","comments":true,"path":"2021/06/24/技术/JAVA/编码/","link":"","permalink":"http://www.lights8080.com/2021/06/24/%E6%8A%80%E6%9C%AF/JAVA/%E7%BC%96%E7%A0%81/","excerpt":"UTF-8、GBK、ASCII、Unicode的区别","text":"UTF-8、GBK、ASCII、Unicode的区别 UTF-8UTF-8：用来解决国际上字符的一种多字节编码，包含全世界所有国家需要用到的字符。通用性比较好。示例：使用UTF-8编码，如果外国人用英文IE访问中文网站，也能显示中文，不需要中文语言包支持。避免乱码问题 GBKGBK：包含所有的中文字符，在国家标准GB2312的基础上扩展。GB2312：1980年收录7445个字符GBK1.0：1995年收录21886个符号（汉字区和图形符号区），其中汉字区包括21003个字符GB18030：2000年其取代GBK1.0正式国家标准。收录27484个汉字，包括藏文、维吾尔文等少数民族文字。 GBK与UTF-8之间必须通过Unicode编码才能相互转换。UTF-8对于英文使用8位（一个字节）编码，对于中文使用24位（三个字节）编码。一个汉字GBK编码占两个字节，UTF-8编码占三个字节，所以UTF-8对中文来说占用空间要大。 ASCIIASCII：UTF-8是ASCII的超集。不需要转换和修改就能和UTF-8一起使用。 UnicodeUnicode：是国际组织制定的可以容纳所有文字和符号的字符编码方案。其用数字来映射字符，浏览器不能直接展示，只能转换成其他格式的编码（UTF-8、GBK）。Unicode用数字0-0x10FFFF来映射这些字符，最多可以容纳1114112（16^4 * 17） 个字符。","categories":[{"name":"计算机","slug":"计算机","permalink":"http://www.lights8080.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"计算机","slug":"计算机","permalink":"http://www.lights8080.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}]},{"title":"阻塞、非阻塞、异步","slug":"技术/JAVA/阻塞、非阻塞、异步","date":"2021-06-23T16:00:00.000Z","updated":"2021-06-24T08:40:42.000Z","comments":true,"path":"2021/06/24/技术/JAVA/阻塞、非阻塞、异步/","link":"","permalink":"http://www.lights8080.com/2021/06/24/%E6%8A%80%E6%9C%AF/JAVA/%E9%98%BB%E5%A1%9E%E3%80%81%E9%9D%9E%E9%98%BB%E5%A1%9E%E3%80%81%E5%BC%82%E6%AD%A5/","excerpt":"","text":"阻塞调用请求过来，要建立连接，然后再接收数据，接收数据后，再发送数据。具体到系统底层，就是读写事件，而当读写事件没有准备好时，必然不可操作，如果不用非阻塞的方式来调用，那就得阻塞调用了，事件没有准备好，那就只能等了，等事件准备好了，你再继续吧。cpu空闲没人用，cpu利用率自然上不去了，更别谈高并发了。好吧，你说加进程数，这跟apache的线程模型有什么区别，注意，别增加无谓的上下文切换。 非阻塞调用非阻塞就是，事件没有准备好，马上返回EAGAIN，告诉你，事件还没准备好呢，你慌什么，过会再来吧。好吧，你过一会，再来检查一下事件，直到事件准备好了为止，在这期间，你就可以先去做其它事情，然后再来看看事件好了没。虽然不阻塞了，但你得不时地过来检查一下事件的状态，你可以做更多的事情了，但带来的开销也是不小的。 异步非阻塞调用它们提供了一种机制，让你可以同时监控多个事件，调用他们是阻塞的，但可以设置超时时间，在超时时间之内，如果有事件准备好了，就返回。拿epoll为例(在后面的例子中，我们多以epoll为例子，以代表这一类函数)，当事件没准备好时，放到epoll里面，事件准备好了，我们就去读写，当读写返回EAGAIN时，我们将它再次加入到epoll里面。这样，只要有事件准备好了，我们就去处理它，只有当所有事件都没准备好时，才在epoll里面等着。这样，我们就可以并发处理大量的并发了，当然，这里的并发请求，是指未处理完的请求，线程只有一个，所以同时能处理的请求当然只有一个了，只是在请求间进行不断地切换而已，切换也是因为异步事件未准备好，而主动让出的。这里的切换是没有任何代价，你可以理解为循环处理多个准备好的事件，事实上就是这样的。与多线程相比，这种事件处理方式是有很大的优势的，不需要创建线程，每个请求占用的内存也很少，没有上下文切换，事件处理非常的轻量级。并发数再多也不会导致无谓的资源浪费（[link]上下文切换 ）。 异步非阻塞的理解http://blog.csdn.net/feitianxuxue/article/details/8936802 阻塞，非阻塞：关注的是程序在等待调用结果（消息或返回值）时的状态。进程/线程要访问的数据是否就绪，进程/线程是否需要等待； 同步，异步：关注的是消息通信机制。访问数据的方式，同步需要主动读写数据，在读写数据的过程中还是会阻塞；异步只需要I/O操作完成的通知，并不主动读写数据，由操作系统内核完成数据的读写。 故事(老张爱喝茶)1234567知乎老张爱喝茶，废话不说，煮开水。出场人物：老张，水壶两把（普通水壶，简称水壶；会响的水壶，简称响水壶）。1 老张把水壶放到火上，立等水开。（同步阻塞）老张觉得自己有点傻2 老张把水壶放到火上，去客厅看电视，时不时去厨房看看水开没有。（同步非阻塞）老张还是觉得自己有点傻，于是变高端了，买了把会响笛的那种水壶。水开之后，能大声发出嘀~~~~的噪音。3 老张把响水壶放到火上，立等水开。（异步阻塞）老张觉得这样傻等意义不大4 老张把响水壶放到火上，去客厅看电视，水壶响之前不再去看它了，响了再去拿壶。（异步非阻塞）老张觉得自己聪明了。所谓同步异步，只是对于水壶而言。普通水壶，同步；响水壶，异步。虽然都能干活，但响水壶可以在自己完工之后，提示老张水开了。这是普通水壶所不能及的。同步只能让调用者去轮询自己（情况2中），造成老张效率的低下。所谓阻塞非阻塞，仅仅对于老张而言。立等的老张，阻塞；看电视的老张，非阻塞。情况1和情况3中老张就是阻塞的，媳妇喊他都不知道。虽然3中响水壶是异步的，可对于立等的老张没有太大的意义。所以一般异步是配合非阻塞使用的，这样才能发挥异步的效用。","categories":[{"name":"计算机","slug":"计算机","permalink":"http://www.lights8080.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"计算机","slug":"计算机","permalink":"http://www.lights8080.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}]},{"title":"Linux使用总结","slug":"技术/Linux/Linux使用总结","date":"2021-06-23T16:00:00.000Z","updated":"2021-06-25T11:03:04.000Z","comments":true,"path":"2021/06/24/技术/Linux/Linux使用总结/","link":"","permalink":"http://www.lights8080.com/2021/06/24/%E6%8A%80%E6%9C%AF/Linux/Linux%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93/","excerpt":"","text":"常用命令12345678910111213141516171819# 查找目录下的所有文件中是否含有某个字符串,只打印出文件名称find . | xargs grep -ri &#x27;string&#x27; -l# 文件字符串替换sed -i &#x27;s/oldStr/newStr/g&#x27; demo# 将worker-5的异常前后20行保存到文件中cat all.log.2015-08-26 | grep &#x27;schedulerFactoryBean_Worker-5] - 异常信息&#x27; -A 20 -B 20 &gt; worker-5-exception.log# 查询文件中时间段的内容sed -n &#x27;/2014-05-16/,/2014-05-17/p&#x27; catalina.out &gt; 20140516tomcat.loggrep &quot;2014-07-23 13:[00-59]&quot; 20140514tomcat.log &gt;05-14.log# 正则匹配egrep &#x27;(-开始)|(-结束)&#x27; p.log &gt; begin-end.log# 昨天这个时候的时间date -d&quot;yesterday&quot; +&quot;%F %H:%M:%S&quot; 性能相关123456#查看CPU性能&gt;vmstat 1#显示CPU数，ALL为索引&gt;mpstat -P ALL 1#查看I/O性能&gt;iostat -m -x 1 Examples12345# linux 查询端口占用情况netstat -natp|grep 8080# 创建软连接ln -s 目标文件 连接文件","categories":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://www.lights8080.com/tags/Linux/"}]},{"title":"Mysql使用总结","slug":"技术/其他/Mysql使用总结","date":"2021-06-23T16:00:00.000Z","updated":"2021-06-24T10:24:40.000Z","comments":true,"path":"2021/06/24/技术/其他/Mysql使用总结/","link":"","permalink":"http://www.lights8080.com/2021/06/24/%E6%8A%80%E6%9C%AF/%E5%85%B6%E4%BB%96/Mysql%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93/","excerpt":"新建用户及授权、性能指标、数据库容量、导入导出、存储过程和事件、sql总结","text":"新建用户及授权、性能指标、数据库容量、导入导出、存储过程和事件、sql总结 新建用户及授权12345678910111213141516-- 添加用户CREATE USER &#x27;username&#x27;@&#x27;host&#x27; IDENTIFIED BY &#x27;password&#x27;;-- 授权GRANT [select,update,delete,create,drop] privileges ON databasename.tablename TO &#x27;username&#x27;@&#x27;host&#x27;;-- 授权示例GRANT all privileges ON *.* TO &#x27;user1&#x27;@&#x27;%&#x27; identified by &#x27;123456&#x27;;-- 刷新系统权限表flush privileges;-- 设置或更改用户密码SET PASSWORD FOR &#x27;username&#x27;@&#x27;host&#x27; = PASSWORD(&#x27;newpassword&#x27;);-- 撤销用户权限REVOKE privilege ON databasename.tablename FROM &#x27;username&#x27;@&#x27;host&#x27;;-- 查看授权信息SHOW GRANTS FOR &#x27;username&#x27;@&#x27;host&#x27;;-- 删除用户DROP USER &#x27;username&#x27;@&#x27;host&#x27;; Examples123456grant all privileges on *.* to root@&#x27;%&#x27; identified by &#x27;123456&#x27;;flush privileges;CREATE USER &#x27;lihaipeng&#x27;@&#x27;%&#x27; IDENTIFIED BY &#x27;123456&#x27;;GRANT all privileges ON *.* TO &#x27;lihaipeng&#x27;@&#x27;%&#x27; identified by &#x27;123456&#x27;;flush privileges; 性能指标1234567891011121314151617181920212223242526-- sql性能分析explain select * from xxx-- 显示正在执行语句show PROCESSLIST;-- 查询表连接数和锁表数show open tables;-- max_connections 最大连接数-- max_user_connections 单用户的最大连接数-- thread_cache_size 线程缓存最大数show variables like &#x27;%max_connections%&#x27;;-- Threads_cached 当前缓存中空闲的连接数量-- Threads_connected 当前打开的连接数量-- Threads_running 不在睡眠的线程数量show status like &#x27;Threads%&#x27;;-- Max_used_connections 同时使用的连接的最大数目-- Connections 试图连接到MySQL(不管是否连接成功)的连接数show status like &#x27;Max_used_connections&#x27;;-- 显示group_concat长度限制show session variables LIKE &#x27;%group_concat_max_len%&#x27;;-- 设置group_concat长度限制SET SESSION group_concat_max_len=512000; 事务和锁1234567891011-- 查看数据库当前的进程show processlist;select * from information_schema.processlist;-- 当前运行的所有事务SELECT * FROM information_schema.INNODB_TRX;-- 查看正在锁的事务SELECT * FROM information_schema.INNODB_LOCKS;-- 查看等待锁的事务SELECT * FROM information_schema.INNODB_LOCK_WAITS;-- 结束线程KILL &lt;trx_mysql_thread_id&gt;; 连接数和超时时间12345678910111213-- 查看服务器状态信息(分为全局和会话，支持like)SHOW global status LIKE &#x27;slow_queries&#x27;;-- 查看系统变量及其值(分为全局和会话，支持like)show global variables LIKE &#x27;%slow_queries%&#x27;;-- 更改全局变量，必须具有SUPER权限-- 最大连接数set global max_connections=1500;-- 关闭一个非交互的连接之前等待秒数 28800set global wait_timeout=600;-- 关闭一个交互的连接之前等待秒数 28800set global interactive_timeout=600;-- 锁等待时间 31536000set global lock_wait_timeout=600; 查看数据库容量123456789101112131415161718192021222324252627282930313233343536373839-- 查看所有数据库容量大小selecttable_schema as &#x27;数据库&#x27;,sum(table_rows) as &#x27;记录数&#x27;,sum(truncate(data_length/1024/1024, 2)) as &#x27;数据容量(MB)&#x27;,sum(truncate(index_length/1024/1024, 2)) as &#x27;索引容量(MB)&#x27;from information_schema.tablesgroup by table_schemaorder by sum(data_length) desc, sum(index_length) desc;-- 查看所有数据库各表容量大小selecttable_schema as &#x27;数据库&#x27;,table_name as &#x27;表名&#x27;,table_rows as &#x27;记录数&#x27;,truncate(data_length/1024/1024, 2) as &#x27;数据容量(MB)&#x27;,truncate(index_length/1024/1024, 2) as &#x27;索引容量(MB)&#x27;from information_schema.tablesorder by data_length desc, index_length desc;-- 查看指定数据库容量大小selecttable_schema as &#x27;数据库&#x27;,sum(table_rows) as &#x27;记录数&#x27;,sum(truncate(data_length/1024/1024, 2)) as &#x27;数据容量(MB)&#x27;,sum(truncate(index_length/1024/1024, 2)) as &#x27;索引容量(MB)&#x27;from information_schema.tableswhere table_schema=&#x27;mysql&#x27;;-- 查看指定数据库各表容量大小selecttable_schema as &#x27;数据库&#x27;,table_name as &#x27;表名&#x27;,table_rows as &#x27;记录数&#x27;,truncate(data_length/1024/1024, 2) as &#x27;数据容量(MB)&#x27;,truncate(index_length/1024/1024, 2) as &#x27;索引容量(MB)&#x27;from information_schema.tableswhere table_schema=&#x27;mysql&#x27;order by data_length desc, index_length desc; 导入/导出12345678910-- 导出指定库所有表结构mysqldump -u root -p234234 -h 192.168.1.75 -d [数据库] &gt; a.sql-- 导出指定数据库所有结构和数据mysqldump -u root -p234234 -h 192.168.1.75 [数据库] &gt; a.sql-- 导出指定数据库，指定表结构mysqldump -u root -p234234 -h 192.168.1.75 -d [数据库] [表] &gt; a.sql-- 导出指定数据库，指定表结构和数据mysqldump -u root -p234234 -h 192.168.1.75 [数据库] [表] &gt; a.sql-- 导入mysql -u root -proot test &lt; cid-fromto-1.sql to csv12345SELECT order_id,product_name,qty FROM ordersINTO OUTFILE &#x27;/tmp/orders.csv&#x27;FIELDS TERMINATED BY &#x27;,&#x27;ENCLOSED BY &#x27;&quot;&#x27;LINES TERMINATED BY &#x27;\\n&#x27; to txt12SELECT order_id,product_name,qty FROM ordersINTO OUTFILE &#x27;/tmp/orders.txt&#x27; Sql统计：mysql中每10分钟统计1234SELECT concat(date_format(createtime,&#x27;%Y-%m-%d %H:&#x27;) , floor( date_format(createtime, &#x27;%i&#x27;)/10)) AS c, count( id )FROM `qm_log`WHERE createtime BETWEEN &#x27;2015-11-24 07:00:00&#x27; and &#x27;2015-11-24 08:59:59&#x27;GROUP BY c 关联表更新1234update fesf_order.order_detail od set od.child_policy_no =(select pg.policy_no from fesf_commission.policy_general pg where pg.id = substring_index(od.child_policy_id,&quot;|&quot;,-1)); 数据库表迁移1234567891011-- 复制表create table database1.table1 like database2.table1;-- 复制表数据insert into database1.table1 select * from database2.table1;-- 数据库改名方案-- 1. 创建目标库CREATE SCHEMA `unififi_security` DEFAULT CHARACTER SET utf8;-- 2. 生成改表名的sqlselect concat(&#x27;rename table &#x27;,TABLE_SCHEMA,&#x27;.&#x27;,TABLE_NAME,&#x27; to target_schema.&#x27;,TABLE_NAME,&#x27;;&#x27;) from information_schema.TABLES where TABLE_SCHEMA=&#x27;origin_schema&#x27;; 数据库改名脚本rename_schema.sh 1234567891011#!/bin/bash# 假设将sakila数据库名改为new_sakila# MyISAM直接更改数据库目录下的文件即可mysql -uroot -p123456 -e &#x27;create database if not exists new_sakila&#x27;list_table=$(mysql -uroot -p123456 -Nse &quot;select table_name from information_schema.TABLES where TABLE_SCHEMA=&#x27;sakila&#x27;&quot;)for table in $list_tabledo mysql -uroot -p123456 -e &quot;rename table sakila.$table to new_sakila.$table&quot;done 库表操作1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556-- 创建库CREATE SCHEMA `lights` DEFAULT CHARACTER SET utf8;-- 删除/创建表drop table `lights`.`scheduler_log`;CREATE TABLE `lights`.`scheduler_log` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `task_id` varchar(64) DEFAULT NULL COMMENT &#x27;任务ID&#x27;, `task_type` varchar(10) DEFAULT NULL COMMENT &#x27;任务类型 once:一次性任务 cron:定时任务&#x27;, `task_module` varchar(100) DEFAULT NULL COMMENT &#x27;任务模块&#x27;, `callback_url` varchar(500) DEFAULT NULL COMMENT &#x27;回调URL&#x27;, `callback_request` varchar(3000) DEFAULT NULL COMMENT &#x27;回调请求内容&#x27;, `callback_response` varchar(3000) DEFAULT NULL COMMENT &#x27;回调响应内容&#x27;, `callback_status` int(11) DEFAULT &#x27;0&#x27; COMMENT &#x27;回调响应状态 0:成功&#x27;, `callback_spendms` int(11) DEFAULT &#x27;0&#x27; COMMENT &#x27;回调响应时间（毫秒）&#x27;, `gmt_create` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP, `gmt_modified` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP, PRIMARY KEY (`id`), KEY `idx_query` (`gmt_create`) USING BTREE, KEY `idx_task_module` (`task_module`) USING HASH) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8 ROW_FORMAT=DYNAMIC COMMENT=&#x27;任务执行日志表&#x27;;-- 修改表alter table `lights`.`scheduler_log` add column `test` longtext COMMENT &#x27;test&#x27; after callback_spendms;-- 创建索引create UNIQUE index uk_orderno on lights.order_main (order_no);create index idx_query on lights.order_main (gmt_create, status) USING BTREE;-- 创建存储过程drop procedure if exists `lights`.`proc_report`;create procedure `lights`.`proc_report`(IN report_day date) begin declare end_day date; declare usd_rmbratio decimal(18, 6) default 1; set usd_rmbratio = 6.890000; set end_day = date_add(date_add(report_day, interval 1 day), interval -1 microsecond); -- 可以执行delete、update、insert操作 select * from table; end;-- 调用存储过程call `lights`.proc_report(&#x27;2019-01-02&#x27;);select * from lights.proc_report;-- 创建事件drop event if exists `lights`.`proc_report`;CREATE EVENT `lights`.`event_call_proc_report` on schedule EVERY 1 DAY STARTS DATE_ADD(DATE_ADD(CURDATE(), INTERVAL 1 DAY), INTERVAL 1 HOUR) ON COMPLETION PRESERVEDO BEGIN call `lights`.`proc_report`(DATE_ADD(CURDATE(), INTERVAL -1 DAY)); END;","categories":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"http://www.lights8080.com/tags/Mysql/"}]},{"title":"Linux Shell","slug":"技术/Linux/Linux Shell","date":"2021-06-17T16:00:00.000Z","updated":"2021-06-18T06:19:22.000Z","comments":true,"path":"2021/06/18/技术/Linux/Linux Shell/","link":"","permalink":"http://www.lights8080.com/2021/06/18/%E6%8A%80%E6%9C%AF/Linux/Linux%20Shell/","excerpt":"shell介绍和shell环境","text":"shell介绍和shell环境 Shellshell是用户使用Linux系统的一座桥梁，是一种命令语言。Shell 脚本（shell script）是一种为 shell 编写的脚本程序。业界所说的 shell 通常都是指 shell 脚本，但是shell 和 shell script是两个不同的概念。 Linux Shell分类： Bourne Shell（/usr/bin/sh或/bin/sh） Bourne Again Shell（/bin/bash） C Shell（/usr/bin/csh） K Shell（/usr/bin/ksh） … Bash 也是大多数Linux系统默认的Shell。 命令： 1234# 查看shell外壳echo $SHELL# 切换bashchsh -s /bin/bash shell环境定制bash shell环境 /etc/profile：为系统的每个用户设置环境信息，当用户第一次登录时，该文件被执行 /etc/bashrc：为每一个运行bash shell的用户执行此文件，进行个性化设置 ~/.bash_profile：为当前用户设置专属的环境信息，当用户登录时该文件执行一次 ~/.bashrc：为当前用户每次打开新的shell时，读取该文件，进行个性化设置 ~/.bash_logout：退出shell时被读取 命令： 12# 立马生效source ~/.bash_profile","categories":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/"},{"name":"Linux","slug":"技术/Linux","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/Linux/"}],"tags":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/tags/%E6%8A%80%E6%9C%AF/"},{"name":"Linux","slug":"Linux","permalink":"http://www.lights8080.com/tags/Linux/"}]},{"title":"pyenv for Mac","slug":"技术/其他/pyenv for Mac","date":"2021-06-17T16:00:00.000Z","updated":"2021-06-18T02:56:42.000Z","comments":true,"path":"2021/06/18/技术/其他/pyenv for Mac/","link":"","permalink":"http://www.lights8080.com/2021/06/18/%E6%8A%80%E6%9C%AF/%E5%85%B6%E4%BB%96/pyenv%20for%20Mac/","excerpt":"pyenv for mac安装说明","text":"pyenv for mac安装说明 安装123brew install pyenv# pyenv管理的Python命令目录添加到$PATHecho &#x27;eval &quot;$(pyenv init --path)&quot;&#x27; &gt;&gt; ~/.bash_profile 命令123456789101112131415161718# 安装指定python版本pyenv install 3.6.9# 查看安装的python版本pyenv versions# 设置全局python版本pyenv global 3.5.2# 为本地环境设置python版本，覆盖globalpyenv local 3.6.9# 为当前shell会话设置python版本，覆盖localpyenv shell 3.6.9# 取消设置pyenv local --unset 参考https://github.com/pyenv/pyenv#homebrew-on-macoshttps://github.com/pyenv/pyenv/blob/master/COMMANDS.md#command-reference","categories":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://www.lights8080.com/tags/Python/"}]},{"title":"ElastAlert-实践","slug":"技术/ELK/ElastAlert-实践","date":"2021-06-16T16:00:00.000Z","updated":"2021-06-24T02:17:28.000Z","comments":true,"path":"2021/06/17/技术/ELK/ElastAlert-实践/","link":"","permalink":"http://www.lights8080.com/2021/06/17/%E6%8A%80%E6%9C%AF/ELK/ElastAlert-%E5%AE%9E%E8%B7%B5/","excerpt":"","text":"基于Elastalert的二次开发https://github.com/lights8080/elastalert forked from Yelp/elastalert 修改内容大致如下： 修改报警及日志的日期格式为%Y-%m-%d %H:%M:%S %Z 集成钉钉报警（支持At、secret认证），参考example_rules/example_frequency_lights8080.yaml PercentageMatchRule，报警内容增加match_bucket_count字段 FrequencyRule，报警内容增加doc_count字段 requirements.txt改为elasticsearch==7.0.0 优化日志 规则配置建议 buffer_time与run_every参数设置相同 支持钉钉报警 新增文件：elastalert_modules/dingtalk_alert.py 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485#! /usr/bin/env python# -*- coding: utf-8 -*-&quot;&quot;&quot;@author: xuyaoqiang,lights8080@contact: xuyaoqiang@gmail.com@date: 2017-09-14 17:35,2021-06-23@version: 0.0.0@license:@copyright:&quot;&quot;&quot;import jsonimport requestsfrom elastalert.alerts import Alerter, DateTimeEncoderfrom requests.exceptions import RequestExceptionfrom elastalert.util import EAExceptionimport sysimport ioimport timeimport datetimeimport hmacimport hashlibimport base64import urllibsys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding=&#x27;utf-8&#x27;)class DingTalkAlerter(Alerter): required_options = frozenset([&#x27;dingtalk_webhook&#x27;, &#x27;dingtalk_msgtype&#x27;]) def __init__(self, rule): super(DingTalkAlerter, self).__init__(rule) self.dingtalk_webhook_url = self.rule[&#x27;dingtalk_webhook&#x27;] self.dingtalk_msgtype = self.rule.get(&#x27;dingtalk_msgtype&#x27;, &#x27;text&#x27;) self.dingtalk_isAtAll = self.rule.get(&#x27;dingtalk_isAtAll&#x27;, False) self.dingtalk_title = self.rule.get(&#x27;dingtalk_title&#x27;, &#x27;&#x27;) self.dingtalk_atMobiles = self.rule.get(&#x27;dingtalk_atMobiles&#x27;, []) self.dingtalk_secret = self.rule.get(&#x27;dingtalk_secret&#x27;, &#x27;&#x27;) def format_body(self, body): return body.encode(&#x27;utf8&#x27;) def alert(self, matches): headers = &#123; &quot;Content-Type&quot;: &quot;application/json&quot;, &quot;Accept&quot;: &quot;application/json;charset=utf-8&quot; &#125; body = self.create_alert_body(matches) payload = &#123; &quot;msgtype&quot;: self.dingtalk_msgtype, &quot;text&quot;: &#123; &quot;content&quot;: body &#125;, &quot;at&quot;: &#123; &quot;isAtAll&quot;:False &#125; &#125; if len(self.dingtalk_atMobiles) &gt; 0: payload[&quot;at&quot;][&quot;atMobiles&quot;] = self.dingtalk_atMobiles url = self.dingtalk_webhook_url if len(self.dingtalk_secret) &gt; 0: timestamp = round(time.time() * 1000) secret_enc = bytes(self.dingtalk_secret, encoding=&#x27;utf8&#x27;) string_to_sign = &#x27;&#123;&#125;\\n&#123;&#125;&#x27;.format(timestamp, self.dingtalk_secret) string_to_sign_enc = bytes(string_to_sign, encoding=&#x27;utf8&#x27;) hmac_code = hmac.new(secret_enc, string_to_sign_enc, digestmod=hashlib.sha256).digest() sign = urllib.parse.quote(base64.b64encode(hmac_code)) url = &#x27;&#123;&#125;&amp;timestamp=&#123;&#125;&amp;sign=&#123;&#125;&#x27;.format(self.dingtalk_webhook_url, timestamp, sign) try: response = requests.post(url, data=json.dumps(payload, cls=DateTimeEncoder), headers=headers) response.raise_for_status() print(response) except RequestException as e: raise EAException(&quot;Error request to Dingtalk: &#123;0&#125;&quot;.format(str(e))) def get_info(self): return &#123; &quot;type&quot;: &quot;dingtalk&quot;, &quot;dingtalk_webhook&quot;: self.dingtalk_webhook_url &#125; pass 修改规则 12345678alert:- &quot;elastalert_modules.dingtalk_alert.DingTalkAlerter&quot;dingtalk_webhook: &quot;https://oapi.dingtalk.com/robot/send?access_token=token&quot;dingtalk_msgtype: &quot;text&quot;dingtalk_secret: &quot;secret&quot;dingtalk_atMobiles:- &quot;18610241024&quot; 报警实践转换为本地时区规则配置增强模块： 12match_enhancements:- &quot;elastalert.enhancements.TimeEnhancement&quot; 修改前： 1234Example ruleAt least 50 events occurred between 2021-06-18 19:55:24 CST and 2021-06-18 20:00:24 CST@timestamp: 2021-06-18T12:00:24.768631Z 修改后： 12345Example ruleAt least 50 events occurred between 2021-06-18 19:55:24 CST and 2021-06-18 20:00:24 CST@timestamp: 2021-06-18 20:00:24 CST","categories":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/"},{"name":"ELK","slug":"技术/ELK","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/ELK/"}],"tags":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/tags/%E6%8A%80%E6%9C%AF/"},{"name":"ELK","slug":"ELK","permalink":"http://www.lights8080.com/tags/ELK/"}]},{"title":"ElastAlert-核心逻辑流程及源码解析","slug":"技术/ELK/ElastAlert-核心逻辑流程及源码解析","date":"2021-06-09T16:00:00.000Z","updated":"2021-06-10T02:50:31.000Z","comments":true,"path":"2021/06/10/技术/ELK/ElastAlert-核心逻辑流程及源码解析/","link":"","permalink":"http://www.lights8080.com/2021/06/10/%E6%8A%80%E6%9C%AF/ELK/ElastAlert-%E6%A0%B8%E5%BF%83%E9%80%BB%E8%BE%91%E6%B5%81%E7%A8%8B%E5%8F%8A%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/","excerpt":"ElastAlert核心逻辑流程及源码解析 run_every、buffer_time、timeframe之间的关系 num_hits、num_matches说明","text":"ElastAlert核心逻辑流程及源码解析 run_every、buffer_time、timeframe之间的关系 num_hits、num_matches说明 1、核心主流程及源码解析核心主流程： 初始化ElastAlerter对象，并调用start()：加载规则、并启动job job调用规则处理(handle_rule_execution)：计算结束时间，run_rule，设置job下次执行时间 run_rule：计算查询开始和结束时间，run_query，send_alert，回写索引 run_query：根据规则调用ES查询，向规则中添加计数数据 send_alert：根据计数数据报警，回写索引 流程图如下： ElastAlert核心逻辑流程及源码解析 2、run_every、buffer_time、timeframe之间的关系 run_every：任务执行时间间隔 buffer_time：查询窗口范围。未设置use_count_query和use_terms_query时，有效 timeframe：事件数的时间窗口 3、num_hits、num_matches说明 match[‘num_hits’]：查询文档计数或聚合桶数 match[‘num_matches’]：查询符合过滤规则的计数123456789101112### match[&#x27;num_hits&#x27;]不同的查询统计，计算方式不同# get_hits_count：thread_data.num_hits += res[&#x27;count&#x27;]# get_hits：thread_data.num_hits += len(res[&#x27;hits&#x27;][&#x27;hits&#x27;])# get_hits_terms：thread_data.num_hits += len(res[&#x27;aggregations&#x27;][&#x27;counts&#x27;][&#x27;buckets&#x27;])# get_hits_aggregation：thread_data.num_hits += res[&#x27;hits&#x27;][&#x27;total&#x27;][&#x27;value&#x27;]","categories":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/"},{"name":"ELK","slug":"技术/ELK","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/ELK/"}],"tags":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/tags/%E6%8A%80%E6%9C%AF/"},{"name":"ELK","slug":"ELK","permalink":"http://www.lights8080.com/tags/ELK/"}]},{"title":"Hexo搭建个人博客系统","slug":"工具/Hexo搭建个人博客系统","date":"2021-06-07T16:00:00.000Z","updated":"2021-06-08T02:22:38.000Z","comments":true,"path":"2021/06/08/工具/Hexo搭建个人博客系统/","link":"","permalink":"http://www.lights8080.com/2021/06/08/%E5%B7%A5%E5%85%B7/Hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E7%B3%BB%E7%BB%9F/","excerpt":"介绍基于Hexo搭建个人博客，包括评论、图床、站内搜索、字数统计、PV统计、百度统计等","text":"介绍基于Hexo搭建个人博客，包括评论、图床、站内搜索、字数统计、PV统计、百度统计等 特色 Hexo（https://hexo.io/zh-cn/） 模板：pure（https://github.com/cofess/hexo-theme-pure.git） 模板2：hexo-theme-matery（https://github.com/blinkfox/hexo-theme-matery） 图床：gitee 评论：valine（https://console.leancloud.cn/apps） 站内搜索：insight 字数统计：postCount PV统计（leancloud） 百度统计（https://tongji.baidu.com/web/10000362099/homepage/index） 命令123456789101112131415# 切换Node版本nvm use v14.17.0# 生成静态文件（-d：部署；-w：监视文件变动）hexo generate/hexo g# 启动服务器hexo server/hexo s# 部署网站hexo deploy/hexo d# 更换主题后，清除缓存文件和已生成的静态文件hexo cleanhexo clean &amp;&amp; hexo deployhexo s -w 安装步骤1234567891011121314151617181920212223# 切换Node版本nvm use v14.17.0# Hexo初始化项目hexo init blogcd blog# 安装依赖模块npm install hexo-wordcount --savenpm install hexo-generator-json-content --savenpm install hexo-generator-feed --savenpm install hexo-generator-sitemap --savenpm install hexo-generator-baidu-sitemap --savenpm install hexo-deployer-git --savenpm install highlight.js --save# 下载pure模板cd themesgit clone git@github.com:cofess/hexo-theme-pure.git# 启动npm installhexo server 环境配置$ vim _config.yml 123456# Hexo发布deploy:- type: git repo: https://github.com/lights8080/lights8080.github.io branch: master token: $ vim themes/pure/_config.yml 12345678# 评论comment: valine: appid: appkey: # 百度统计plugins: baidu_analytics: 报错问题处理执行hexo server命令，报错 123456INFO Validating configINFO Start processingFATAL &#123; err: TypeError: line.matchAll is not a function at res.value.res.value.split.map.line (/home/seek/Data/hexosite/node_modules/hexo-util/lib/highlight.js:128:26) at Array.map (&lt;anonymous&gt;) 升级node到12以上https://stackoverflow.com/questions/67516168/i-just-installed-hexo-static-site-generator-on-debian-and-ran-hexo-server-to-see","categories":[{"name":"工具","slug":"工具","permalink":"http://www.lights8080.com/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://www.lights8080.com/tags/Hexo/"},{"name":"效率","slug":"效率","permalink":"http://www.lights8080.com/tags/%E6%95%88%E7%8E%87/"},{"name":"个人博客","slug":"个人博客","permalink":"http://www.lights8080.com/tags/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"}]},{"title":"NodeJs VS Nginx","slug":"技术/其他/NodeJs VS Nginx","date":"2021-06-07T16:00:00.000Z","updated":"2021-06-24T08:18:46.000Z","comments":true,"path":"2021/06/08/技术/其他/NodeJs VS Nginx/","link":"","permalink":"http://www.lights8080.com/2021/06/08/%E6%8A%80%E6%9C%AF/%E5%85%B6%E4%BB%96/NodeJs%20VS%20Nginx/","excerpt":"前端项目动态应用和静态应用的区别，有了 Vue + Nginx，为什么还要 Node？","text":"前端项目动态应用和静态应用的区别，有了 Vue + Nginx，为什么还要 Node？ Vue：只是一个 UI 层的框架，因此他打包出来的就是一套 UI 的静态文件：html + js-bundle Nginx：反向服务器，并不提供逻辑处理，只做譬如负载均衡、流量控制、静态服务器等功能 Node：运行在服务端的 JavaScript vue 对 node 的服务端渲染支持最好（反过来说就不准确了） NodeJS的核心优势 服务端渲染-SSR（Server Side Rendering） 鉴权 接口聚合 Node要避免一些高CPU开销的功能","categories":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/"},{"name":"前端","slug":"技术/前端","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/%E5%89%8D%E7%AB%AF/"}],"tags":[{"name":"NodeJs","slug":"NodeJs","permalink":"http://www.lights8080.com/tags/NodeJs/"},{"name":"Nginx","slug":"Nginx","permalink":"http://www.lights8080.com/tags/Nginx/"}]},{"title":"ELK-合集","slug":"技术/ELK/ELK-合集","date":"2021-06-06T16:00:00.000Z","updated":"2021-06-25T02:47:42.000Z","comments":true,"path":"2021/06/07/技术/ELK/ELK-合集/","link":"","permalink":"http://www.lights8080.com/2021/06/07/%E6%8A%80%E6%9C%AF/ELK/ELK-%E5%90%88%E9%9B%86/","excerpt":"ELK文章合集，《Elastic Stack 实战手册》","text":"ELK文章合集，《Elastic Stack 实战手册》 通过最近对ELK全家桶的学习和应用实践，总结成系列文章。如有疑问，欢迎私信，共同学习，一起成长。 安利一下《Elastic Stack 实战手册》早鸟版首发，这是我最近才关注到的，写的很好https://developer.aliyun.com/topic/elasticstack/playbook 文章合集ELK-实践（架构选择&amp;部署说明） ELK-实践（业务框架&amp;业务配置） ELK-加密通信的说明和配置教程 Elasticsearch-介绍 Elasticsearch-索引（Index） Elasticsearch-映射（Mapping） Elasticsearch-搜索（Search DSL） Elasticsearch-聚合（Aggregations） Elasticsearch-安全特性（Security） Logstash介绍 Logstash配置及说明 Beats-Filebeat命令&amp;配置说明 Beats-Filebeat介绍 Kibana-介绍 ElastAlert-介绍 ElastAlert-配置 ElastAlert-核心逻辑流程及源码解析 ElastAlert-实践 安利一下《Elastic Stack 实战手册》早鸟版首发，这是我最近才关注到的，写的很好 https://developer.aliyun.com/topic/elasticstack/playbook","categories":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/"},{"name":"ELK","slug":"技术/ELK","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/ELK/"}],"tags":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/tags/%E6%8A%80%E6%9C%AF/"},{"name":"ELK","slug":"ELK","permalink":"http://www.lights8080.com/tags/ELK/"}]},{"title":"ELK-实践（业务框架&业务配置）","slug":"技术/ELK/ELK-实践（业务框架&业务配置）","date":"2021-06-03T16:00:00.000Z","updated":"2021-06-08T10:55:27.000Z","comments":true,"path":"2021/06/04/技术/ELK/ELK-实践（业务框架&业务配置）/","link":"","permalink":"http://www.lights8080.com/2021/06/04/%E6%8A%80%E6%9C%AF/ELK/ELK-%E5%AE%9E%E8%B7%B5%EF%BC%88%E4%B8%9A%E5%8A%A1%E6%A1%86%E6%9E%B6&%E4%B8%9A%E5%8A%A1%E9%85%8D%E7%BD%AE%EF%BC%89/","excerpt":"介绍基于业务的数据模型框架和业务配置（Elasticsearch的映射和索引、Logstash配置管理、Filebeat规则管理、同步脚本等）。基于7.11版本。","text":"介绍基于业务的数据模型框架和业务配置（Elasticsearch的映射和索引、Logstash配置管理、Filebeat规则管理、同步脚本等）。基于7.11版本。 业务中Elasticsearch数据分为两类： 日志类：数据线性增长，无修改操作，无主键，数据价值随时间递减。如：用户操作、异常信息等 业务类：有主键，允许修改删除，长期保留。如：订单信息、基础信息 数据提取方式和特点： 日志类数据：Filebeat-&gt;Logstash-&gt;Elasticsearch。数据流、通用模型、容错性强 业务类数据：通过脚本获取数据信息（数据库、API等）直接更新到Elasticsearch。自定义灵活可控 1. Elasticsearch 映射和索引 lights-mappings：组件模板mappings lights-settings：组件模板settings lights-log：索引生命周期-日志类 lights-data：索引生命周期-数据类 lights-service-exception：服务异常信息（数据流） lights-nginx-web：Nginx日志（数据流） lights-order：订单信息（索引别名） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237### 创建索引模板组件-mappingPUT /_component_template/lights-mappings&#123; &quot;template&quot;: &#123; &quot;mappings&quot;: &#123; &quot;dynamic_date_formats&quot;: [ &quot;yyyy-MM-dd HH:mm:ss&quot;, &quot;yyyy-MM-dd HH:mm:ss Z&quot;, &quot;yyyy-MM-dd HH:mm:ss.SSS&quot;, &quot;yyyy-MM-dd HH:mm:ss.SSS Z&quot; ], &quot;dynamic_templates&quot;: [ &#123; &quot;string_as_keyword&quot;: &#123; &quot;match_mapping_type&quot;: &quot;string&quot;, &quot;mapping&quot;: &#123; &quot;type&quot;: &quot;keyword&quot;, &quot;ignore_above&quot;: 1024 &#125; &#125; &#125; ], &quot;properties&quot;: &#123; &quot;@timestamp&quot;: &#123; &quot;type&quot;: &quot;date&quot; &#125;, &quot;message&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;index&quot;: false &#125;, &quot;log&quot;: &#123; &quot;properties&quot;: &#123; &quot;file&quot;: &#123; &quot;properties&quot;: &#123; &quot;path&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;index&quot;: false &#125; &#125; &#125; &#125; &#125; &#125; &#125; &#125;&#125;### 创建索引模板组件-settingPUT /_component_template/lights-settings&#123; &quot;template&quot;: &#123; &quot;settings&quot;: &#123; &quot;index&quot;: &#123; &quot;number_of_shards&quot;: 1, &quot;number_of_replicas&quot;: 0, &quot;refresh_interval&quot;: &quot;15s&quot;, &quot;codec&quot;: &quot;best_compression&quot; &#125;, &quot;query&quot;: &#123; &quot;default_field&quot;: [ &quot;@timestamp&quot;, &quot;message&quot; ] &#125; &#125; &#125;&#125;### 创建索引生命周期-日志类PUT _ilm/policy/lights-log&#123; &quot;policy&quot;: &#123; &quot;phases&quot;: &#123; &quot;hot&quot;: &#123; &quot;actions&quot;: &#123; &quot;rollover&quot;: &#123; &quot;max_size&quot;: &quot;50GB&quot;, &quot;max_age&quot;: &quot;1d&quot; &#125; &#125; &#125;, &quot;delete&quot;: &#123; &quot;min_age&quot;: &quot;365d&quot;, &quot;actions&quot;: &#123; &quot;delete&quot;: &#123;&#125; &#125; &#125; &#125; &#125;&#125;### 创建索引生命周期-数据类PUT /_ilm/policy/lights-data&#123; &quot;policy&quot;: &#123; &quot;phases&quot;: &#123; &quot;hot&quot;: &#123; &quot;actions&quot;: &#123; &quot;rollover&quot;: &#123; &quot;max_size&quot;: &quot;50GB&quot;, &quot;max_age&quot;: &quot;30d&quot; &#125; &#125; &#125; &#125; &#125;&#125;### 创建索引模板（数据流）-服务异常信息POST /_index_template/lights-service-exception&#123; &quot;index_patterns&quot;: [ &quot;lights-service-exception&quot; ], &quot;data_stream&quot;: &#123;&#125;, &quot;template&quot;: &#123; &quot;settings&quot;: &#123; &quot;number_of_shards&quot;: 1, &quot;number_of_replicas&quot;: 0, &quot;refresh_interval&quot;: &quot;15s&quot;, &quot;index.lifecycle.name&quot;: &quot;lights-log-30&quot; &#125; &#125;, &quot;priority&quot;: 100, &quot;composed_of&quot;: [ &quot;lights-mappings&quot;, &quot;lights-settings&quot; ], &quot;_meta&quot;: &#123; &quot;description&quot;: &quot;索引模板-服务异常信息&quot; &#125;&#125;### 创建索引模板（数据流）-Nginx日志POST /_index_template/lights-nginx-web&#123; &quot;index_patterns&quot;: [ &quot;lights-nginx-web&quot; ], &quot;data_stream&quot;: &#123;&#125;, &quot;template&quot;: &#123; &quot;settings&quot;: &#123; &quot;number_of_shards&quot;: 1, &quot;number_of_replicas&quot;: 0, &quot;refresh_interval&quot;: &quot;15s&quot;, &quot;codec&quot;: &quot;best_compression&quot;, &quot;index.lifecycle.name&quot;: &quot;lights-log&quot; &#125;, &quot;mappings&quot;: &#123; &quot;properties&quot;: &#123; &quot;bytes&quot;: &#123; &quot;type&quot;: &quot;long&quot; &#125;, &quot;status&quot;: &#123; &quot;type&quot;: &quot;integer&quot; &#125;, &quot;request_time&quot;: &#123; &quot;type&quot;: &quot;double&quot; &#125;, &quot;upstream_status&quot;: &#123; &quot;type&quot;: &quot;integer&quot; &#125;, &quot;upstream_response_time&quot;: &#123; &quot;type&quot;: &quot;double&quot; &#125; &#125; &#125; &#125;, &quot;priority&quot;: 100, &quot;composed_of&quot;: [ &quot;lights-mappings&quot;, &quot;lights-settings&quot; ]&#125;### 创建索引模板（索引别名）-订单数据POST /_index_template/lights-order&#123; &quot;index_patterns&quot;: [ &quot;lights-order-*&quot; ], &quot;template&quot;: &#123; &quot;settings&quot;: &#123; &quot;number_of_shards&quot;: 1, &quot;number_of_replicas&quot;: 0, &quot;refresh_interval&quot;: &quot;15s&quot; &#125;, &quot;mappings&quot;: &#123; &quot;dynamic_date_formats&quot;: [ &quot;yyyy-MM-dd HH:mm:ss&quot;, &quot;yyyy-MM-dd HH:mm:ss Z&quot;, &quot;yyyy-MM-dd HH:mm:ss.SSS&quot;, &quot;yyyy-MM-dd HH:mm:ss.SSS Z&quot; ], &quot;dynamic_templates&quot;: [ &#123; &quot;string_as_keyword&quot;: &#123; &quot;match_mapping_type&quot;: &quot;string&quot;, &quot;mapping&quot;: &#123; &quot;type&quot;: &quot;keyword&quot;, &quot;ignore_above&quot;: 1024 &#125; &#125; &#125;, &#123; &quot;total_as_double&quot;: &#123; &quot;match_mapping_type&quot;: &quot;long&quot;, &quot;match&quot;: &quot;*Amount&quot;, &quot;mapping&quot;: &#123; &quot;type&quot;: &quot;double&quot; &#125; &#125; &#125; ], &quot;properties&quot;: &#123; &quot;orderNum&quot;: &#123; &quot;type&quot;: &quot;integer&quot; &#125;, &quot;logs&quot;: &#123; &quot;properties&quot;: &#123; &quot;remark&quot;: &#123; &quot;type&quot;: &quot;text&quot; &#125; &#125; &#125; &#125; &#125;, &quot;aliases&quot;: &#123; &quot;lights-order&quot;: &#123;&#125; &#125; &#125;, &quot;priority&quot;: 100, &quot;_meta&quot;: &#123; &quot;description&quot;: &quot;索引模板-订单数据&quot; &#125;&#125; 2. Logstash Config 通过Filebeat标签识别日志类型 根据具体的服务名称打上业务标签，过滤、处理数据 根据不同的业务标签，输出到不同的Elasticsearch索引 config/lights.conf 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122# Sample Logstash configuration for creating a simple# Beats -&gt; Logstash -&gt; Elasticsearch pipeline.input &#123; beats &#123; port =&gt; 5044 host =&gt; &quot;0.0.0.0&quot; &#125;&#125;filter &#123; if &quot;lights-service&quot; in [tags] &#123; if !([service_name]) &#123; mutate &#123; copy =&gt; &#123; &quot;[log][file][path]&quot; =&gt; &quot;log_file_path&quot; &#125; &#125; mutate &#123; split =&gt; [ &quot;log_file_path&quot; , &quot;/&quot; ] add_field =&gt; &#123; &quot;service_name&quot; =&gt; &quot;%&#123;[log_file_path][2]&#125;&quot; &#125; remove_field =&gt; [&quot;log_file_path&quot;] &#125; &#125; if [message] =~ &quot; ERROR &quot; and [message] =~ &quot;Exception&quot; &#123; truncate &#123; fields =&gt; [&quot;message&quot;] length_bytes =&gt; 10000 &#125; grok &#123; match =&gt; &#123; &quot;message&quot; =&gt; [ &quot;%&#123;TIMESTAMP_ISO8601:timestamp&#125; \\[%&#123;DATA:thread&#125;\\] %&#123;DATA:level&#125; %&#123;DATA:class&#125; - %&#123;DATA:error_message&#125;\\n%&#123;GREEDYDATA:throwable&#125;&quot;, &quot;%&#123;TIMESTAMP_ISO8601:timestamp&#125; \\[%&#123;DATA:thread&#125;\\] %&#123;DATA:level&#125; %&#123;DATA:class&#125; - %&#123;DATA:error_message&#125;&quot;, &quot;%&#123;TIMESTAMP_ISO8601:timestamp&#125; \\[%&#123;DATA:thread&#125;\\] %&#123;DATA:level&#125; - %&#123;DATA:error_message&#125;\\n%&#123;GREEDYDATA:throwable&#125;&quot;, &quot;%&#123;TIMESTAMP_ISO8601:timestamp&#125; \\[%&#123;DATA:thread&#125;\\] %&#123;DATA:level&#125; - %&#123;DATA:error_message&#125;&quot; ] &#125; id =&gt; &quot;service-exception&quot; &#125; mutate &#123; add_tag =&gt; [ &quot;service-exception&quot; ] &#125; if [throwable] &#123; mutate &#123; remove_field =&gt; [&quot;throwable&quot;] &#125; &#125; &#125; else &#123; if [service_name] == &quot;lights-search-service&quot; and [message] =~ &quot;LightSearchServiceImpl&quot; and [message] =~ &quot; INFO &quot; &#123; grok &#123; match =&gt; &#123; &quot;message&quot; =&gt; [ &quot;%&#123;TIMESTAMP_ISO8601:timestamp&#125; \\[%&#123;DATA:thread&#125;\\] %&#123;DATA:level&#125; %&#123;DATA:class&#125; - %&#123;GREEDYDATA:response_message&#125;&quot; ] &#125; id =&gt; &quot;lights-search-service&quot; &#125; mutate &#123; add_tag =&gt; [ &quot;lights-search-service&quot; ] remove_field =&gt; [&quot;message&quot;] &#125; &#125; &#125; &#125; if &quot;lights-nginx-web&quot; in [tags] &#123; grok &#123; match =&gt; &#123; &quot;message&quot; =&gt; [ &quot;%&#123;IPORHOST:clientip&#125; %&#123;IPORHOST:server_name&#125; %&#123;HTTPDUSER:ident&#125; %&#123;HTTPDUSER:auth&#125; \\[%&#123;HTTPDATE:timestamp&#125;\\] \\&quot;(?:%&#123;WORD:verb&#125; %&#123;DATA:request&#125;(?: HTTP/%&#123;NUMBER:httpversion&#125;)?|%&#123;DATA:rawrequest&#125;)\\&quot; (?:-|%&#123;NUMBER:status&#125;) (?:-|%&#123;NUMBER:request_time&#125;) (?:-|%&#123;NUMBER:bytes&#125;) \\&quot;%&#123;DATA:http_referer&#125;\\&quot; \\&quot;%&#123;DATA:http_user_agent&#125;\\&quot; \\&quot;%&#123;DATA:http_x_forwarded_for&#125;\\&quot; \\&quot;%&#123;DATA:upstream_addr&#125;\\&quot; %&#123;NUMBER:upstream_status&#125; %&#123;NUMBER:upstream_response_time&#125;&quot; ] &#125; &#125; mutate &#123; remove_field =&gt; [&quot;message&quot;] &#125; &#125; date &#123; match =&gt; [ &quot;timestamp&quot;, &quot;yyyy-MM-dd HH:mm:ss.SSS&quot;, &quot;dd/MMM/yyyy:HH:mm:ss Z&quot; ] &#125; mutate &#123; remove_field =&gt; [&quot;@version&quot;, &quot;timestamp&quot;, &quot;agent&quot;, &quot;input&quot;] &#125;&#125;output &#123; #stdout &#123; codec =&gt; rubydebug &#123; metadata =&gt; true &#125; &#125; if &quot;_grokparsefailure&quot; in [tags] &#123; file &#123; path =&gt; &quot;/opt/elk/logstash-7.11.2/_grokparsefailure-%&#123;+yyyy.MM.dd&#125;&quot; &#125; &#125; else &#123; if &quot;service-exception&quot; in [tags] &#123; elasticsearch &#123; hosts =&gt; [&quot;http://10.88.2.1:9200&quot;] index =&gt; &quot;lights-service-exception&quot; action =&gt; &quot;create&quot; user =&gt; &quot;elastic&quot; password =&gt; &quot;xxxxx&quot; &#125; &#125; if &quot;lights-search-service&quot; in [tags] &#123; elasticsearch &#123; hosts =&gt; [&quot;http://10.88.2.1:9200&quot;] index =&gt; &quot;lights-search&quot; #document_id =&gt; &quot;%&#123;[@metadata][_id]&#125;&quot; action =&gt; &quot;create&quot; user =&gt; &quot;elastic&quot; password =&gt; &quot;xxxxx&quot; &#125; &#125; if &quot;lights-nginx-web&quot; in [tags] &#123; elasticsearch &#123; hosts =&gt; [&quot;http://10.88.2.1:9200&quot;] index =&gt; &quot;lights-nginx-web&quot; action =&gt; &quot;create&quot; user =&gt; &quot;elastic&quot; password =&gt; &quot;xxxxx&quot; &#125; &#125; &#125;&#125; 3.1 Filebeat123456789101112131415161718192021# Nginx日志- type: log enabled: true paths: - /log/nginx/lights.log tags: [&quot;lights-nginx&quot;] tail_files: true# Java日志(异常多行合并)- type: log enabled: true paths: - /log/&lt;service-name&gt;/*.log exclude_lines: [&#x27;/actuator/&#x27;] exclude_files: [&#x27;.gz$&#x27;] tags: [&quot;lights-service&quot;] multiline.type: pattern multiline.pattern: &#x27;^\\d&#123;4&#125;-\\d&#123;2&#125;-\\d&#123;2&#125;&#x27; multiline.negate: true multiline.match: after ignore_older: 6h 3.2 脚本（同步到Elasticsearch）1234567891011121314151617181920212223242526272829303132333435363738#!/bin/bash# 判断脚本正在执行LOCK=$(cat $es_script_path/.lock_$file_suffix)if [ $LOCK -eq 1 ];then echo &quot;`date &quot;+%Y-%m-%d %H:%M:%S&quot;` locked&quot; &amp;&amp; exit 1fiecho &quot;1&quot; &gt; $es_script_path/.lock_$file_suffixDATE_BEGIN=$(cat $es_script_path/.lasttime_$file_suffix)DATE_END=`date +&quot;%Y-%m-%d %H:%M:%S&quot;`DATE_BEGIN=&quot;2021-05-01 09:00:10&quot;DATE_END=&quot;2021-05-01 09:00:10&quot;ORDERS_SQL=&quot;&quot;&quot;select order_no from lights.order where createtime BETWEEN &#x27;$DATE_BEGIN&#x27; and &#x27;$DATE_END&#x27;&quot;&quot;&quot;# 查询同步订单列表ORDERS_RESULT=$(mysql -u &lt;user&gt; &lt;db&gt; -e &quot;$ORDERS_SQL&quot;);for LINE in $ORDERS_RESULTdo if [ &#x27;order_no&#x27; != &quot;$LINE&quot; ];then es_index=`echo &quot;lights-order-20$LINE&quot;|cut -c 1-20` echo &quot;sync order time:$DATE_BEGIN ~ $DATE_END order no: $LINE, es index: $es_index&quot; # 调用查询接口 orderdetail_result=$(curl -XPOST -H &quot;Content-Type: application/json&quot; -d &#x27;&#123;&quot;orderNo&quot;:&quot;&#x27;$LINE&#x27;&quot;&#125;&#x27; http://localhost:8080/flights-order-service/order/detail) echo &quot;$orderdetail_result&quot; &gt; $es_script_path/.data_$file_suffix # 时区设置 cat $es_script_path/.data_$file_suffix |jq &#x27;.orderInfo&#x27; -c &gt;$es_script_path/.data_1_$file_suffix sed -i &#x27;s/[0-9]\\&#123;4\\&#125;-[0-9]\\&#123;2\\&#125;-[0-9]\\&#123;2\\&#125; [0-9]\\&#123;2\\&#125;:[0-9]\\&#123;2\\&#125;:[0-9]\\&#123;2\\&#125;/&amp; +0800/g&#x27; $es_script_path/.data_1_$file_suffix # 保持到Elasticsearch curl -XPOST --user &#x27;elastic:&lt;password&gt;&#x27; -H &quot;Content-Type: application/json&quot; http://localhost:9200/$es_index/_doc/$LINE -d@$es_script_path/.data_1_$file_suffix fidone# 更新同步时间 及 解除正在执行标记echo $DATE_END &gt; $es_script_path/.lasttime_$file_suffixecho &quot;0&quot; &gt; $es_script_path/.lock_$file_suffix 4. 其他1. Logstash Req-Resp合并成一条事件正常情况下Controller层会拦截请求参数和响应结果并输出到日志，如何基于线程ID将前后两条日志记录合并到一个事件中。 12345678910111213141516171819202122232425262728293031if [service_name] == &quot;lights-order-service&quot; and [message] =~ &quot;LIGHTS-RE&quot; and [message] =~ &quot; INFO &quot; &#123; grok &#123; match =&gt; &#123; &quot;message&quot; =&gt; [ &quot;%&#123;TIMESTAMP_ISO8601:timestamp&#125; \\[%&#123;DATA:thread&#125;\\] %&#123;DATA:level&#125; - LIGHTS-%&#123;DATA:type&#125;-\\[%&#123;DATA:class_method&#125;\\] \\[%&#123;DATA:username&#125;\\] \\[%&#123;GREEDYDATA:request&#125;\\]&quot;, &quot;%&#123;TIMESTAMP_ISO8601:timestamp&#125; \\[%&#123;DATA:thread&#125;\\] %&#123;DATA:level&#125; - LIGHTS-%&#123;DATA:type&#125;-\\[%&#123;DATA:class_method&#125;\\] %&#123;GREEDYDATA:response&#125; size:%&#123;DATA:size&#125; spend:%&#123;DATA:spend&#125;ms&quot; ] &#125; id =&gt; &quot;lights-order-service&quot; &#125; if [type] == &quot;REQ&quot; &#123; aggregate &#123; task_id =&gt; &quot;%&#123;thread&#125;&quot; code =&gt; &quot;map[&#x27;request_timestamp&#x27;] = event.get(&#x27;timestamp&#x27;); map[&#x27;username&#x27;] = event.get(&#x27;username&#x27;); map[&#x27;request&#x27;] = event.get(&#x27;request&#x27;)&quot; map_action =&gt; &quot;create&quot; &#125; &#125; if [type] == &quot;RESP&quot; &#123; aggregate &#123; task_id =&gt; &quot;%&#123;thread&#125;&quot; code =&gt; &quot;event.set(&#x27;request_timestamp&#x27;, map[&#x27;request_timestamp&#x27;]); event.set(&#x27;username&#x27;, map[&#x27;username&#x27;]); event.set(&#x27;request&#x27;, map[&#x27;request&#x27;])&quot; map_action =&gt; &quot;update&quot; end_of_task =&gt; true timeout =&gt; 120 &#125; mutate &#123; add_tag =&gt; [ &quot;lights-order-service&quot; ] remove_field =&gt; [&quot;message&quot;] &#125; &#125;&#125; 2. Kibana小技巧和注意事项 Kibana可视化中Lens(条形图、饼图等)，如何使用索引的另一个时间x字段统计？新建一个Kibana索引，选择x字段作为时间字段。 Kibana可视化中Lens(条形图、饼图等)，如何像TSVB那样使用公式计算值？使用Kibana索引的脚本字段，在Lens中使用 Kibana中Discover时间框搜索是大于等于(&gt;=)开始时间，小于(&lt;)结束时间，对时间敏感的搜索需要注意 3. Elasticsearch时区问题Elasticsearch存储和读取时都要带上时区 Logstash存储修改UTC时间为东八区时间 123ruby &#123; code =&gt; &quot;event.set(&#x27;temp&#x27;, event.get(&#x27;@timestamp&#x27;).time.localtime + 8*60*60); event.set(&#x27;@timestamp&#x27;, event.get(&#x27;temp&#x27;))&quot; &#125; 直接存储ES的时间字段要带上时区信息2021-05-15 00:00:00 +0800 1curl -XPOST --user &#x27;elastic:xxx&#x27; -H &quot;Content-Type: application/json&quot; http://127.0.0.1:9200/es_index/_doc/$LINE -d@/json_data Kibana搜索时带上时区 12345678910111213GET lights-order/_count&#123; &quot;query&quot;: &#123; &quot;range&quot;: &#123; &quot;@timestamp&quot;: &#123; &quot;gte&quot;: &quot;2021-04-15 00:00:00&quot;, &quot;lte&quot;: &quot;2021-04-15 23:59:59&quot;, &quot;format&quot;: &quot;yyyy-MM-dd HH:mm:ss&quot;, &quot;time_zone&quot;:&quot;+08:00&quot; &#125; &#125; &#125;&#125; 4. 设计上的原则数据清洗一定发生在写入ES之前，而不是请求数据后处理，那势必会降低请求速度和效率。让ES做他擅长的事，检索+不复杂的聚合，否则数据量+复杂的业务逻辑会有性能问题。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/"},{"name":"ELK","slug":"技术/ELK","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/ELK/"}],"tags":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/tags/%E6%8A%80%E6%9C%AF/"},{"name":"ELK","slug":"ELK","permalink":"http://www.lights8080.com/tags/ELK/"}]},{"title":"Elasticsearch-数据迁移","slug":"技术/ELK/Elasticsearch-数据迁移","date":"2021-06-02T16:00:00.000Z","updated":"2021-06-07T07:04:19.000Z","comments":true,"path":"2021/06/03/技术/ELK/Elasticsearch-数据迁移/","link":"","permalink":"http://www.lights8080.com/2021/06/03/%E6%8A%80%E6%9C%AF/ELK/Elasticsearch-%E6%95%B0%E6%8D%AE%E8%BF%81%E7%A7%BB/","excerpt":"","text":"Reindex数据迁移重建索引（_reindex），即：一旦索引被创建，则无法直接修改索引字段的mapping属性，必需要重建索引然后将旧的索引数据迁移到新的索引中才行（迁移过程底层使用了scroll API ）。 示例： 123456789101112131415161718POST _reindex &#123; &quot;conflicts&quot;: &quot;proceed&quot;, # 发生冲突继续执行 &quot;source&quot;: &#123; &quot;index&quot;: &quot;old_index&quot;, &quot;type&quot;: &quot;_doc&quot;, &quot;size&quot;: 5000, # 设置每批迁移的文档记录数 &quot;_source&quot;: [&quot;user&quot;, &quot;_doc&quot;], # 可设置要迁移的索引字段，不设置则默认所有字段 &quot;query&quot;: &#123; # 可设置要迁移的文档记录过滤条件 &quot;match_all&quot;: &#123; &#125; &#125; &#125;, &quot;dest&quot;: &#123; &quot;index&quot;: &quot;new_index&quot;, &quot;type&quot;: &quot;_doc&quot;, &quot;version_type&quot;: &quot;internal&quot; # &quot;internal&quot;或者不设置，则Elasticsearch强制性的将文档转储到目标中，覆盖具有相同类型和ID的任何内容 &#125; &#125;","categories":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/"},{"name":"ELK","slug":"技术/ELK","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/ELK/"}],"tags":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/tags/%E6%8A%80%E6%9C%AF/"},{"name":"ELK","slug":"ELK","permalink":"http://www.lights8080.com/tags/ELK/"},{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://www.lights8080.com/tags/Elasticsearch/"}]},{"title":"Elasticsearch-配置及系统配置说明","slug":"技术/ELK/Elasticsearch-配置及系统配置说明","date":"2021-06-02T16:00:00.000Z","updated":"2021-06-04T08:04:53.000Z","comments":true,"path":"2021/06/03/技术/ELK/Elasticsearch-配置及系统配置说明/","link":"","permalink":"http://www.lights8080.com/2021/06/03/%E6%8A%80%E6%9C%AF/ELK/Elasticsearch-%E9%85%8D%E7%BD%AE%E5%8F%8A%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E8%AF%B4%E6%98%8E/","excerpt":"系统配置、Elasticsearch配置说明","text":"系统配置、Elasticsearch配置说明 系统配置理想情况下，Elasticsearch应该单独运行在服务器上，并使用所有可用的资源。为了做到这一点，您需要配置您的操作系统，以允许运行Elasticsearch的用户访问超过默认允许的资源。 Important System Configuration 系统配置-参考$ vim /etc/security/limits.conf 12345678root soft nofile 65535root hard nofile 65535* soft nofile 65535* hard nofile 65535elasticsearch soft memlock unlimitedelasticsearch hard memlock unlimitedelasticsearch soft nproc 4096elasticsearch hard nproc 4096 $ vim /etc/sysctl.conf 12vm.max_map_count = 262144net.ipv4.tcp_retries2 = 5 系统配置-说明Disable swapping（禁用内存交互）大多数操作系统尝试为文件系统缓存使用尽可能多的内存，并急切地交换未使用的应用程序内存。这可能导致部分JVM堆甚至其可执行页被交换到磁盘。交换对于性能和节点稳定性非常不利，应该不惜一切代价避免。 On Linux systems，临时禁用 1sudo swapoff -a On Linux systems，永久禁用编辑/etc/fstab，注释掉包含swap的任意行 Elasticsearch配置set bootstrap.memory_lock to true in elasticsearch.yml $ vim /etc/security/limits.conf 123# allow user &#x27;elasticsearch&#x27; mlockallelasticsearch soft memlock unlimitedelasticsearch hard memlock unlimited 检查：GET _nodes?filter_path=**.mlockall如果为false，最可能的原因是，运行Elasticsearch的用户没有锁定内存的权限，通过以下方式授权 File Descriptors（文件描述符）Elasticsearch使用了很多文件描述符或文件句柄。耗尽文件描述符可能是灾难性的，很可能会导致数据丢失。确保将运行Elasticsearch的用户打开文件描述符数量的限制增加到65536或更高。 $ vim /etc/security/limits.conf 12345# elasticsearch - nofile 65535root soft nofile 65535root hard nofile 65535* soft nofile 65535* hard nofile 65535 检查：GET _nodes/stats/process?filter_path=**.max_file_descriptors Virtual memory（虚拟内存）Elasticsearch默认使用一个mappfs目录来存储索引。默认操作系统对mmap计数的限制可能太低，这可能会导致内存不足异常。 暂时设置sysctl -w vm.max_map_count=262144 永久设置 $ vim /etc/sysctl.conf 123# 设置操作系统mmap数限制，Elasticsearch与Lucene使用mmap来映射部分索引到Elasticsearch的地址空间# 为了让mmap生效，Elasticsearch还需要有创建需要内存映射区的能力。最大map数检查是确保内核允许创建至少262144个内存映射区vm.max_map_count = 262144 Number of threads（线程数）Elasticsearch为不同类型的操作使用了许多线程池。它能够在需要时创建新线程，这一点很重要。确保Elasticsearch用户可以创建的线程数量至少是4096个。 $ vim /etc/security/limits.conf 12elasticsearch soft nproc 4096elasticsearch hard nproc 4096 TCP retransmission timeout（TCP重传超时）集群中的每一对节点通过许多TCP连接进行通信，这些TCP连接一直保持打开状态，直到其中一个节点关闭或由于底层基础设施中的故障而中断节点之间的通信。 TCP通过对通信应用程序隐藏临时的网络中断，在偶尔不可靠的网络上提供可靠的通信。在通知发送者任何问题之前，您的操作系统将多次重新传输任何丢失的消息。大多数Linux发行版默认重传任何丢失的数据包15次。重传速度呈指数级下降，所以这15次重传需要900秒才能完成。这意味着Linux使用这种方法需要花费许多分钟来检测网络分区或故障节点。Windows默认只有5次重传，相当于6秒左右的超时。 Linux默认允许在可能经历很长时间包丢失的网络上进行通信，但是对于单个数据中心内的生产网络来说，这个默认值太大了，就像大多数Elasticsearch集群一样。高可用集群必须能够快速检测节点故障，以便它们能够通过重新分配丢失的碎片、重新路由搜索以及可能选择一个新的主节点来迅速作出反应。因此，Linux用户应该减少TCP重传的最大数量。 $ vim /etc/sysctl.conf 1net.ipv4.tcp_retries2 = 5 Elasticsearch配置默认情况Elasticsearch假设处于开发模式中，任何的配置不正确都会在日志文件中写入警告，能够正常启动和运行节点；一旦配置了像network.host这样的网络设置，Elasticsearch就会假设处于生产环境中，并将上面的警告升级为异常，这些异常将阻止节点启动。 Important Elasticsearch configuration config/elasticsearch.yml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# ES数据目录和日志目录，path.data可以设置多个路径path: logs: /var/log/elasticsearch data: /var/data/elasticsearch# 集群名称，默认elasticsearch。相同的集群名称的节点，才能加入集群cluster.name: elasticsearch# 设置全新群集中符合主机资格的节点的初始集合（首次启动集群时需要）；默认为空表示该节点希望加入已经被引导的集群cluster.initial_master_nodes: [&quot;10.188.80.14&quot;]# 节点名称，默认随机生成node.name: prod-data-2node.master: truenode.data: true# 启用预处理，默认启用node.ingest: true# 集群绑定的主机名或IP地址，用于形成一个可以相互通讯的集群；0.0.0.0表示绑定到所有网络接口network.host: 192.168.1.10# 节点间通讯绑定端口，默认9300-9400transport.port: 9300# 提供可访问的集群列表，没有给出端口的通过`transport.port`确定端口，以前使用`discovery.zen.ping.unicast.hosts`discovery.seed_hosts: [&quot;10.188.80.14&quot;]# 启用单节点发现（节点将选举自己为主节点，并且不会与任何其他节点一起加入集群），推迟了TLS的配置；默认形成多节点集群（发现其他节点，并允许他们加入集群）discovery.type: single-node# 集群的最小master节点数，避免集群脑裂discovery.zen.minimum_master_nodes: 2# HTTP服务绑定到的主机地址http.bind_host: # 发布以供HTTP客户端连接的主机地址http.publish_host: # http.bind_host and the http.publish_hosthttp.host: &quot;10.188.80.14&quot;# HTTP请求绑定端口，默认9200-9300http.port: 9200# 允许跨域http.cors.enabled: truehttp.cors.allow-origin: &quot;*&quot;# 禁用swapping，避免影响集群的性能和稳定性，默认开启。（大多数操作系统尝试使用尽可能多的内存文件系统缓存和热切换出未使用的应用程序内存，避免JVM堆交互到磁盘上）bootstrap.memory_lock: true# 开启通过系统调用过滤器检查，默认为true，如果自己承担禁用系统调用过滤器的风险，设置为falsebootstrap.system_call_filter: true# 自动创建索引，默认为trueaction.auto_create_index: true# 删除索引时必须显示的指定名称，默认为trueaction.destructive_requires_name: true config/ jvm.options Elasticsearch有足够的可用堆是非常重要的。 堆的最小值（Xms）与堆的最大值（Xmx）设置成相同的。 Elasticsearch的可用堆越大，它能在内存中缓存的数据越多。但是需要注意堆越大在垃圾回收时造成的暂停会越长。 设置Xmx不要大于物理内存的50%。用来确保有足够多的物理内存预留给操作系统缓存。 禁止用串行收集器来运行Elasticsearch（-XX:+UseSerialGC），默认JVM配置通过Elasticsearch的配置将使用CMS回收器。 12-Xms8g-Xmx8g","categories":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/"},{"name":"ELK","slug":"技术/ELK","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/ELK/"}],"tags":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/tags/%E6%8A%80%E6%9C%AF/"},{"name":"ELK","slug":"ELK","permalink":"http://www.lights8080.com/tags/ELK/"},{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://www.lights8080.com/tags/Elasticsearch/"}]},{"title":"人体系统-糖","slug":"人体系统/人体系统-糖","date":"2021-06-01T16:00:00.000Z","updated":"2021-06-07T01:59:46.000Z","comments":true,"path":"2021/06/02/人体系统/人体系统-糖/","link":"","permalink":"http://www.lights8080.com/2021/06/02/%E4%BA%BA%E4%BD%93%E7%B3%BB%E7%BB%9F/%E4%BA%BA%E4%BD%93%E7%B3%BB%E7%BB%9F-%E7%B3%96/","excerpt":"糖对人体的重要性。什么是糖、糖的作用、糖的分类、葡萄糖的人体旅程。","text":"糖对人体的重要性。什么是糖、糖的作用、糖的分类、葡萄糖的人体旅程。 什么是糖糖是一大类化学物质，糖类都是由碳氢氧三种元素构成的，最初观察发现其中氢和氧的比例是2:1，好像就是碳原子和几个水分子构成的，所以把糖类叫碳水化合物。后来发现一些糖中的氢和氧的比例不是2:1，所以把糖类叫碳水化合物不严谨。但是这个名字一直流传下来，平时所说的碳水化合物一般指的就是糖。 糖的作用糖是最主要的能源物质，人体进行各项生命活动所消耗的能量主要来自于糖类的氧化分解。分解速度快，提供能量非常迅速，我们的大脑和生理活动都需要糖。 人体获得能量：葡萄糖 + 氧气 =&gt; 水 + 二氧化碳 + 能量 葡萄糖在无氧的情况下葡萄糖 =&gt; 乳酸 + 能量(酸奶)葡萄糖 =&gt; 酒精 + 能量(酒) 糖的分类糖不一定是甜的，甜的也不一定是糖。 单糖单糖是构成各种糖分子的基本单位，不能再水解，可以直接被人体吸收。饮食中主要单糖有葡萄糖、果糖、半乳糖，其中葡萄糖是最重要的单糖。所有含碳水化合物的食物进入血液之前，都要分解转化为葡萄糖，到达肠道后，在转运蛋白的帮助下穿过肠壁，最快地为人体提供能量。 葡萄糖：经过肠道直接被人体吸收，进入到血液，称为血糖 果糖（水果、蜂蜜）：不直接被人体吸收，进入肝脏转换为葡萄糖或脂肪，因为其运转机制迟滞，没有葡萄糖进入血液得快，果糖更容易变成脂肪 半乳糖（牛奶）：不直接被人体吸收，进入肝脏转换为葡萄糖 二糖/双糖两个单糖结合在一起组成了双糖，可以水解成单糖，被人体吸收 麦芽糖（麦芽）：葡萄糖+葡萄糖 蔗糖（甘蔗）：葡萄糖+果糖 乳糖（牛奶）：葡萄糖+半乳糖 多糖多糖相对来讲是复合的碳水化合物，由很多单糖通过糖苷链接在一起形成的聚合物，因此多糖结构非常大，经常有分支和很多分子。多糖不溶于水而且没有甜味。 淀粉（大米、白面）：由葡萄糖连接而成 糖原（肝脏、肌肉）：肝脏可以把多余的单糖合成糖原储存在肝脏和肌肉里，当身体需要能量时糖原会迅速分解成葡萄糖。 脂肪（皮下、内脏）：糖原储存不下，更多的单糖会合成脂肪储存在皮下和内脏 纤维（木头、棉花、蔬菜）：不能消化的碳水化合物被划归为“膳食纤维”或者“不可用碳水化合物”。作用：有饱腹感、促进肠道蠕动、促进粪便形成 几丁质（虾壳、蟹壳）：人体不能消化的东西 代糖/甜味剂通过人工化学改造或者合成的具有甜味的化学物质。特点是甜度非常高，几乎没有热量，也不具有任何营养价值。 阿斯巴甜：甜度是等量蔗糖的200倍 三氯蔗糖：甜度是等量蔗糖的600倍 葡萄糖的人体旅程食物中的碳水化合物通过分解转换为单糖，其中葡萄糖经过肠壁吸收直接进入血液（此时叫血糖），果糖和半乳糖经过吸收进入到肝脏，被转换为葡萄糖、糖原或脂肪。 葡萄糖 ==&gt; 糖原/脂肪：胰岛素葡萄糖 &lt;== 糖原/脂肪：胰高血糖素 参考碳水化合物和糖有什么区别？","categories":[{"name":"人体系统","slug":"人体系统","permalink":"http://www.lights8080.com/categories/%E4%BA%BA%E4%BD%93%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"李永乐老师","slug":"李永乐老师","permalink":"http://www.lights8080.com/tags/%E6%9D%8E%E6%B0%B8%E4%B9%90%E8%80%81%E5%B8%88/"},{"name":"人体系统","slug":"人体系统","permalink":"http://www.lights8080.com/tags/%E4%BA%BA%E4%BD%93%E7%B3%BB%E7%BB%9F/"}]},{"title":"ElastAlert-配置","slug":"技术/ELK/ElastAlert-配置","date":"2021-05-31T16:00:00.000Z","updated":"2021-06-18T06:30:20.000Z","comments":true,"path":"2021/06/01/技术/ELK/ElastAlert-配置/","link":"","permalink":"http://www.lights8080.com/2021/06/01/%E6%8A%80%E6%9C%AF/ELK/ElastAlert-%E9%85%8D%E7%BD%AE/","excerpt":"全局配置和规则配置说明","text":"全局配置和规则配置说明 全局配置（Configuration）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051# Elasticsearch集群配置es_host:es_port:use_ssl:verify_certs:es_username:es_password:es_url_prefix:es_conn_timeout:# 设置检索rules和hashes的加载类rules_loader: &#x27;FileRulesLoader&#x27;# 规则配置文件的文件夹的名称，仅rules_loader=FileRulesLoader时有效rules_folder: rules# 是否递归rules目录的子目录配置scan_subdirectories: true# 查询Elasticsearch的时间间隔run_every: minutes: 1# 查询窗口的大小buffer_time: minutes: 15# ElastAlert将存储数据的索引名称writeback_index: elastalert# 单次查询Elasticsearch最大文档数，默认10000max_query_size: 10000# 滚动浏览的最大页面数，默认0（表示不限制）max_scrolling_count: 0# 在滚动浏览上下文中应保持活动状态的最长时间scroll_keepalive: # 汇总在一起的最大警报数max_aggregation:# 两次查询之间的最长时间old_query_limit:# 禁用未捕获异常的规则，默认Truedisable_rules_on_error: # ElastAlert完成执行后会显示“禁用规则”列表show_disabled_rules: true# 通知邮件列表，当前只有未捕获的异常会发送通知电子邮件notify_email:# 警报是否包括规则中描述的元数据，默认Falseadd_metadata_alert: false# 跳过无效的文件而不是退出skip_invalid:# 失败警报的重试窗口alert_time_limit:# 增强模块，与规则一起使用，将其传递给报警器之前对其进行修改或删除match_enhancements:- &quot;elastalert_modules.my_enhancements.MyEnhancement&quot;# 匹配立刻运行增强run_enhancements_first: true 规则配置（Rule Configuration）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119# Elasticsearch配置es_host: 10.188.10.1es_port: 9200es_username: elastices_password: xxxindex: logstash-*# Rule Typetype: &#x27;any&#x27;# 导入公共配置import:# 用于标识警报的利益相关者owner: &#x27;xxx&#x27;# 用于标识警报的相对优先级priority: 2# 用于标识警报的类别catagory: &#x27;&#x27;# 规则描述description: &#x27;&#x27;# 设置请求里查询窗口的范围。当use_count_query或use_terms_query为true时，将忽略此值buffer_time: minutes: 5# 延迟查询query_delay: minutes: 5# 开启timeframe（查询开始时间=now()-timeframe）scan_entire_timeframe: true# 1. 查询开始时间，scan_entire_timeframe开启，use_count_query和use_terms_query未设置时有效# 2. 规则的事件发生窗口期，如：FrequencyRule-EventWindowtimeframe: minutes: 1# Elasticsearch查询过滤器filter:- query: query_string: query: &quot;level: ERROR&quot;# 触发报警的事件数num_events: 5# 传递给规则类型和警报的查询结果字段列表，默认所有字段include: - &quot;username&quot;# 针对每个字段的前X（top_count_number）个最常用的值执行Terms查询top_count_keys: - &quot;username&quot;# 术语的前X个最常用的值，与top_count_keys一同使用top_count_number: 5# 如果为true，top_count_keys中所有字段都会附加.rawraw_count_keys: true# 单次查询获取的最大文档数max_query_size: 10000# 计数查询（count api），而不下载所匹配的文档use_count_query: false# 聚合查询（aggregation），和query_key、doc_type、terms_size一起使用use_terms_query: false# use_terms_query=true时，为每个值单独计数query_key: &#x27;username&#x27;# top_count_keys存在，发送警报时，多个逗号分隔，必须配合compound_query_key使用query_key: &#x27;service_name,username&#x27;# 复合的查询key，必须与query_key一一对应，get_hits_terms时使用compound_query_key: - service_name - username doc_type: _doc# 桶的最大数terms_size: 50# 相关事件一同报警。一个桶触发报警，其他的桶一同触发报警attach_related: false# 将多次匹配汇总到一个警报中，将聚合时间期内发生的所有匹配项一起发送aggregation: # 需要大量匹配并只需要定期报告 hours: 2 # 汇总所有警报并定期发送报警 schedule: &#x27;2 4 * * mon,fri&#x27;# 为不同的字段值创建一个独立的聚合窗口，默认在聚合窗口期中所有事件被分组在一起aggregation_key: &#x27;my_data.username&#x27;# 基于第一个事件的时间创建聚合，默认当前时间aggregate_by_match_time: true# 对于聚合报警，指定摘要表字段summary_table_fields: - my_data.username# 忽略一段时间的重复警报，支持query_keyrealert: minutes: 10# 使realert的值呈指数增加exponential_realert: hours: 1# 是否将时间戳转换为警报中的本地时区use_local_time: true# 时间戳类型（iso, unix, unix_ms, custom）timestamp_type: &#x27;iso&#x27;# 自定义时间戳格式timestamp_format: &#x27;%Y-%m-%dT%H:%M:%SZ&#x27;# 指定时间字段，默认@timestamptimestamp_field: &#x27;@timestamp&#x27;### Metric Aggregation Type or Percentage Match Type# 使用run_every计算度量计算窗口大小，默认使用buffer_timeuse_run_every_query_size: true# 度量计算窗口大小，必须是buffer_time的倍数bucket_interval: # Alertsalert: - command - debugcommand: [&quot;python3&quot;, &quot;/opt/elastalert/weixin.py&quot;, &quot;生产环境报警，报警:&quot;, &quot;接口&#123;orgPathName&#125; 出现状态码&#123;statusCode&#125;频率高！&quot;,&quot;服务 IP: &#123;directBackServer&#125;; 服务端口：&#123;port&#125;&quot;] 不同的规则类型参数不同，详细请看源码文件elastalert/schema.yaml 参考ElastAlert","categories":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/"},{"name":"ELK","slug":"技术/ELK","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/ELK/"}],"tags":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/tags/%E6%8A%80%E6%9C%AF/"},{"name":"ELK","slug":"ELK","permalink":"http://www.lights8080.com/tags/ELK/"}]},{"title":"ElastAlert-介绍","slug":"技术/ELK/ElastAlert-介绍","date":"2021-05-18T16:00:00.000Z","updated":"2021-06-18T11:42:02.000Z","comments":true,"path":"2021/05/19/技术/ELK/ElastAlert-介绍/","link":"","permalink":"http://www.lights8080.com/2021/05/19/%E6%8A%80%E6%9C%AF/ELK/ElastAlert-%E4%BB%8B%E7%BB%8D/","excerpt":"","text":"一、Alerting With Elasticsearch ElastAlert是一个简单的框架，用于从Elasticsearch中的数据中发出异常，尖峰或其他感兴趣的模式的警报。 它通过将Elasticsearch与两种类型的组件（规则类型和警报）结合使用。定期查询Elasticsearch，并将数据传递到规则类型，该规则类型确定找到任何匹配项。发生匹配时，它会发出一个或多个警报，这些警报根据不同的类型采取相应的措施。 ElastAlert由一组规则配置，每个规则定义一个查询，一个规则类型和一组警报。 特性 架构简单，定制灵活 支持多种匹配规则（频率、阈值、数据变化、黑白名单、变化率等） 支持多种警报类型（邮件、HTTP POST、自定义脚本等） 匹配项汇总报警，重复警报抑制，报警失败重试和过期 可用性强，状态信息保存到Elasticsearch的索引中 过程的调试和审计等 可用性（Reliability） ElastAlert 将其状态保存到 Elasticsearch，启动后，将恢复之前停止的状态 如果 Elasticsearch 没有响应，ElastAlert 将等到恢复后才继续 抛出错误的警报可能会在一段时间内自动重试 模块性（Modularity）ElastAlert具有三个主要组件（规则类型、警报、增强），可以作为模块导入和定制。 规则类型（Rule Types）规则类型负责处理从Elasticsearch返回的数据。它会使用规则配置进行初始化，传递通过规则过滤器查询Elasticsearch返回的数据，并根据此数据输出匹配项。 警报（Alerts）警报负责根据匹配采取行动。匹配项通常是一个字典，其中包含Elasticsearch中文档中的值，但可以包含由规则类型添加的任意数据。 增强（Enhancements）增强功能是一种拦截警报并以某种方式对其进行修改或增强的方法。在将其提供给警报器之前，将它们传递给匹配字典。 二、Running ElastAlert 安装、命令、测试规则、运行 安装123456789101112131415161718192021222324# Python3.6安装$ wget https://www.python.org/ftp/python/3.6.9/Python-3.6.9.tgz$ tar -zxvf Python-3.6.9.tgz$ cd Python-3.6.9$ ./configure$ make &amp;&amp; make install# 检查Python版本$ python3 -V# 安装$ git clone https://github.com/Yelp/elastalert.git$ wget https://github.com/daichi703n/elastalert/archive/refs/heads/fix/initialize_alerts_sent.zip$ cd elastalert/$ pip3 install &quot;setuptools&gt;=11.3&quot;$ python3 ./setup.py install# 报错（pip:No module named setuptools_rust）解决办法$ pip3 install setuptools-rust#$ pip3 install &quot;elasticsearch&gt;=5.0.0&quot;$ pip3 install elasticsearch==7.0.0 命令12345678910# 创建索引$ elastalert-create-index# 测试Rule，24小时内以调试模式运行。--config：指定配置文件$ elastalert-test-rule example_rules/example_frequency.yaml# 或$ python3 -m elastalert.elastalert --config ./config.yaml --rule rules/service_exception.yaml --start 2021-05-16T00:00:00+08:00 --debug --es_debug --es_debug_trace trace-20210617.log# 后台运行nohup python3 -m elastalert.elastalert --config ./config.yaml --rule ./your_rule.yaml --verbose &gt;&gt; ./elastalert.log 2&gt;&amp;1 &amp; 测试规则（Testing Rule）可以在调试模式下运行ElastAlert，也可以使用elastalert-test-rule（该脚本可以简化测试的各个方面） 功能： 检查配置文件是否加载成功 检查Elasticsearch过滤器是否解析 与最后的X天(s)运行，显示匹配您的过滤器的点击数 在一个结果中显示可用的术语 保存返回到JSON文件的文档 使用JSON文件或Elasticsearch的实际结果运行ElastAlert 打印调试警报或触发真实警报 如果存在，则检查结果中是否包含primary_key、compare_key和include术语 显示将要写入elastalert_status的元数据文档 参数： –schema-only：只对文件执行验证 –count-only：仅查找匹配文档的数量并列出可用字段 –days N：指定针对最近的N天运行，默认1天 –save-json FILE：将所有下载的文档保存为JSON文件 –data FILE：使用JSON文件代替Elasticsearch作为数据源 –alert：触发实际警报，而不是调试（日志文本）警报 –formatted-output：以格式化的JSON输出结果。 运行（Running ElastAlert）有两种运行ElastAlert的方法。作为守护程序或直接与Python一起使用（$ python3 elastalert/elastalert.py）。 参数： –config：指定要使用的配置文件，默认值为config.yaml –debug：debug模式；1.增加日志记录的详细程度，2.将所有的报警更改为DebugAlerter，抑制它们正常的报警行为，3.跳过写入查询和警报的元数据到Elasticsearch –verbose：将增加日志记录的详细程度，与–debug不兼容 –start ：强制从指定的时间查询，而不是当前时间。如：2021-05-16T00:00:00+08:00 –end ：将强制在指定时间之后停止查询，默认到当前时间 –rule &lt;rule.yaml&gt;：只运行给定的规则 –silence =：将使给定规则的警报静音一段时间。该规则必须使用–rule指定 –es_debug：启用对Elasticsearch进行的所有查询的日志记录。 –es_debug_trace &lt;trace.log&gt;：将启用将对Elasticsearch进行的所有查询的curl命令记录到指定的日志文件 –pin_rules：禁用动态加载规则 三、Rule Types and Configuration Options 规则类型、配置项、报警配合https://elastalert.readthedocs.io/en/stable/ruletypes.html 详细请看源码文件elastalert/schema.yaml Rule Types frequency：频率；在给定时间范围内至少有一定数量的事件时，此规则匹配 num_events：触发警报的事件数 timeframe：事件数必须发生在的此时间段内，触发报警 use_count_query：使用count API轮询Elasticsearch any：任意；过滤器每次匹配都会警报 blacklist：黑名单；将对照黑名单检查某个字段，如果该字段在黑名单中，则进行匹配 compare_key： 用于与黑名单进行比较的字段的名称，如果字段为null，那么这些事件将被忽略 blacklist：黑名单值的列表 whitelist：白名单；与黑名单类似 change：变动；将监视特定字段，并在该字段发生更改时进行匹配 compare_key：要监视更改的字段的名称 ignore_null：如果为true，则没有compare_key字段的事件将不会计为已更改 query_key：对每个query_key的唯一值分别计数。 timeframe: 可选；时间范围，两次更改之间的最长时间。在这段时间之后，ElastAlert将忘记compare_key字段的旧值 spike：突刺；当给定时间段内的事件量是前一时间段内的spike_height倍数时，此规则匹配 spike_height：上一个时间范围内的事件数量与前一个时间范围内的事件数量之比，匹配时触发警报 spike_type：‘up’, ‘down’ or ‘both’ timeframe：当前窗口和参考窗口的时间范围 field_value：可选；使用文档中字段的值而不是匹配文档的数量 threshold_ref：参考窗口中必须存在的最少数量的事件才能触发警报 threshold_cur：当前窗口中必须存在的最小数量的事件才能触发警报 flatline：阈值；当事件总数在一个时间段内低于给定阈值时，此规则匹配 threshold：不触发警报的最小事件数 timeframe：时间范围 new_term：新值；当新值出现在以前从未见过的字段中时，此规则匹配 fields：监视字段列表 cardinality：基数阈值；当时间范围内某个字段的唯一值的总数大于或小于阈值时，此规则匹配 cardinality_field：要计算基数的字段 timeframe：时间范围 metric_aggregation：当计算窗口中的度量值高于或低于阈值时，此规则匹配 metric_agg_key：指标字段 metric_agg_type：指标类型，‘min’, ‘max’, ‘avg’, ‘sum’, ‘cardinality’, ‘value_count’ max_threshold：最大阈值 min_threshold：最小阈值 spike_aggregation：当计算窗口中某个指标的值是spike_height乘以比前一个时间段大或小时，该规则匹配 metric_agg_key：指标字段 metric_agg_type：指标类型，‘min’, ‘max’, ‘avg’, ‘sum’, ‘cardinality’, ‘value_count’ spike_height：上一个时间范围内的事件数量与前一个时间范围内的事件数量之比，匹配时触发警报 spike_type：‘up’, ‘down’ or ‘both’ buffer_time：当前窗口和参考窗口的时间范围 query_key：按字段分组 metric_agg_script：计算指标脚本 threshold_ref：参考窗口中用于触发警报的指标的最小值 threshold_cur：当前窗口中用于触发警报的指标的最小值 min_doc_count：当前窗口中触发警报所需的最小事件数 percentage_match：当计算窗口内匹配桶中文档的百分比高于或低于阈值时，此规则匹配 match_bucket_filter：匹配桶定义了一个过滤器 min_percentage：匹配文档的百分比小于此数字，则会触发警报 max_percentage：匹配文档的百分比大于此数字，则会触发警报 Alerts每个规则都可以附加任何数量的警报。每个警报器的选项既可以定义在yaml文件，也可以嵌套在警报名称中，允许同一警报器的多个不同设置。 Command：命令报警，并从匹配项中传递参数 Email：邮件报警 Http Post：URL报警 … 示例： 12345678910111213141516name: API not 200index: sg-access-*type: frequencynum_events: 20timeframe: minutes: 1filter:- query: query_string: query: &quot;NOT statusCode: 200&quot;alert: - command - debugcommand: [&quot;python3&quot;, &quot;/opt/elastalert/weixin.py&quot;, &quot;生产环境报警，报警:&quot;, &quot;接口&#123;orgPathName&#125; 出现状态码&#123;statusCode&#125;频率高！&quot;,&quot;服务 IP: &#123;directBackServer&#125;; 服务端口：&#123;port&#125;&quot;] 四、ElastAlert Metadata IndexElastAlert使用Elasticsearch来存储有关其状态的各种信息。这不仅可以对ElastAlert的操作进行某种程度的审核和调试，还可以避免在ElastAlert关闭，重新启动或崩溃时丢失数据或重复警报。Elasticsearch群集和索引信息在全局配置文件中使用es_host，es_port和writeback_index进行定义。ElastAlert必须能够写入此索引。脚本elastalert-create-index将为您创建具有正确映射的索引，并可以选择从现有ElastAlert回写索引中复制文档。 ElastAlert将在回写索引（writeback index）中创建三种不同类型的文档。 elastalert_status 记录规则的查询执行日志 elastalert_status是ElastAlert在确定其首次开始时要使用的时间范围，以避免重复查询。对于每个规则，它将从最近的结束时间开始查询。如果ElastAlert在调试模式下运行，它仍将通过查找最近执行的搜索来尝试基于其开始时间，但不会将任何查询的结果写回到Elasticsearch。 elastalert 记录触发的每个警报信息日志 elastalert_error 当ElastAlert中发生错误时，它将同时写入Elasticsearch和stderr silence 记录何时将抑制给定规则的警报的日志 参考ElastAlertelastalert搭建ElastAlert安装与使用Rule Filters说明","categories":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/"},{"name":"ELK","slug":"技术/ELK","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/ELK/"}],"tags":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/tags/%E6%8A%80%E6%9C%AF/"},{"name":"ELK","slug":"ELK","permalink":"http://www.lights8080.com/tags/ELK/"}]},{"title":"Linux [buff/cache]内存缓存占用过高分析和优化","slug":"技术/Linux/Linux [buffcache]内存缓存占用过高分析和优化","date":"2021-05-18T16:00:00.000Z","updated":"2021-06-08T02:15:33.000Z","comments":true,"path":"2021/05/19/技术/Linux/Linux [buffcache]内存缓存占用过高分析和优化/","link":"","permalink":"http://www.lights8080.com/2021/05/19/%E6%8A%80%E6%9C%AF/Linux/Linux%20[buffcache]%E5%86%85%E5%AD%98%E7%BC%93%E5%AD%98%E5%8D%A0%E7%94%A8%E8%BF%87%E9%AB%98%E5%88%86%E6%9E%90%E5%92%8C%E4%BC%98%E5%8C%96/","excerpt":"buff/cache过高问题解决过程。问题现场、问题分析、如何解决、扩展知识","text":"buff/cache过高问题解决过程。问题现场、问题分析、如何解决、扩展知识 问题现场查看系统内存的使用状态 监控报警可用内存空间不足，常规的解决方案如下： 增加内存（增加成本） 增加虚拟内存（影响性能） 定期清理缓存（echo 1 &gt; /proc/sys/vm/drop_caches） 本文将介绍定期清除页面缓存，但是过会儿内存又被占满问题的分析。 问题分析 通过监控系统负载情况（vmstat 1），确定是页面缓存（cache项）占用量大，并且释放页面缓存后从块设备读入数据量（bi项）会马上增加。 通过监控io情况（iostat -x -k 1）也可以看出 基于此可以猜测是有进程在频繁的读取文件导致，监视磁盘I/O使用状况（iotop -oP），释放页面缓存后有几个sed命令读取文件进程占用IO很高。 至此结合业务分析是因为每分钟读取日志统计指标导致 扩展知识/proc/meminfo查看更详细的内存信息：$ cat /proc/meminfo |grep -E &quot;Buffer|Cache|Swap|Mem|Shmem|Slab|SReclaimable|SUnreclaim&quot; MemFree：空闲的物理内存 MemAvailable：可用的物理内存，MemFree+Buffers+Cached Buffers：（Buffer Cache）对磁盘块设备数据的缓存 Cached：（Page Cache）对文件系统上文件数据的缓存，MemFree+SReclaimable SwapTotal：虚拟内存，利用磁盘空间虚拟出的一块逻辑内存 Slab：Linux内存管理机制 SReclaimable：Slab可回收部分 SUnreclaim：Slab不可回收部分 Shmem：进程间共同使用的共享内存 /proc/sys/vm/drop_caches清除缓存策略：1：清除page cache2：清除slab分配器中的对象（包括目录项和inode）3：清除page cache和slab分配器中的对象 参考OOM killer及OvercommitLinux buffer/cache 内存占用过高的原因以及解决办法Linux查看Buffer&amp;Cache被哪些进程占用","categories":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/"},{"name":"Linux","slug":"技术/Linux","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/Linux/"}],"tags":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/tags/%E6%8A%80%E6%9C%AF/"},{"name":"线上问题处理","slug":"线上问题处理","permalink":"http://www.lights8080.com/tags/%E7%BA%BF%E4%B8%8A%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86/"},{"name":"Linux","slug":"Linux","permalink":"http://www.lights8080.com/tags/Linux/"}]},{"title":"OOM killer及Overcommit","slug":"技术/Linux/OOM killer及Overcommit","date":"2021-05-18T16:00:00.000Z","updated":"2021-06-07T01:59:38.000Z","comments":true,"path":"2021/05/19/技术/Linux/OOM killer及Overcommit/","link":"","permalink":"http://www.lights8080.com/2021/05/19/%E6%8A%80%E6%9C%AF/Linux/OOM%20killer%E5%8F%8AOvercommit/","excerpt":"OOM killer(Out Of Memory killer)是Linux内核的一种内存管理机制，该机制在系统物理内存不足时，选择性杀死一些进程以释放内存，以使系统继续运行。","text":"OOM killer(Out Of Memory killer)是Linux内核的一种内存管理机制，该机制在系统物理内存不足时，选择性杀死一些进程以释放内存，以使系统继续运行。 OOM killerOOM killer(Out Of Memory killer)是Linux内核的一种内存管理机制，该机制在系统物理内存不足时，选择性（oom_killer遍历当前所有进程，根据进程的内存使用情况进行打分，然后从中选择一个分数最高的进程）杀死一些进程以释放内存，以使系统继续运行。 Overcommit（过量使用）这个特性出于优化系统考虑，因为进程实际使用到的内存往往比申请的内存少。 按照Linux的算法，物理内存页的分配发生在使用瞬间，而不是在申请瞬间。Overcommit针对的也是内存申请，而不是内存分配。 Linux下允许程序申请比系统可用内存更多的内存。因为不是所有的程序申请了内存就立刻使用的，当实际使用时超过可分配物理内存时，利用OOM机制选择性杀死一些进程以释放内存。 参数调优vm.overcommit_memory 0：OVERCOMMIT_GUESS（默认），内核将检查是否有足够的可用内存供应用进程使用 1：OVERCOMMIT_ALWAYS，允许超过CommitLimit的分配，即允许分配所有的物理内存，而不管当前的内存状态如何 2：OVERCOMMIT_NEVER，拒绝超过CommitLimit的分配，即拒绝等于或者大于CommitLimit指定的物理 RAM 比例的内存请求 CommitLimit 和 Commited_AS CommitLimit：最大能分配的内存 计算公式：(Physical RAM * vm.overcommit_ratio / 100) + Swap Committed_AS：当前已经分配的内存 OVERCOMMIT策略的可用内存判定 OVERCOMMIT_GUESS：判定可用内存 = free + buff/cache - share + Swap + SLAB已标记可回收的内存 - 系统运行预留的内存 - 管理员操作预留内存 OVERCOMMIT_ALWAYS：直接返回成功 OVERCOMMIT_NEVER：判断Committed_AS &lt; CommitLimit 相关命令123456# 查看overcommit策略$ cat /proc/sys/vm/overcommit_memory# 查看进程OOM得分，oom_killer将首先杀死得分最高的进程$ cat /proc/&lt;pid&gt;/oom_score# 查看CommitLimit和Committed_AS$ cat /proc/meminfo |grep -i commit 参考 Linux OOM killer机制介绍","categories":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/"},{"name":"Linux","slug":"技术/Linux","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/Linux/"}],"tags":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/tags/%E6%8A%80%E6%9C%AF/"},{"name":"Linux","slug":"Linux","permalink":"http://www.lights8080.com/tags/Linux/"}]},{"title":"Spring Cloud Gateway与后端服务问题处理总结","slug":"技术/SpringCloud/Spring Cloud Gateway与后端服务问题处理总结","date":"2021-05-18T16:00:00.000Z","updated":"2021-06-08T02:15:46.000Z","comments":true,"path":"2021/05/19/技术/SpringCloud/Spring Cloud Gateway与后端服务问题处理总结/","link":"","permalink":"http://www.lights8080.com/2021/05/19/%E6%8A%80%E6%9C%AF/SpringCloud/Spring%20Cloud%20Gateway%E4%B8%8E%E5%90%8E%E7%AB%AF%E6%9C%8D%E5%8A%A1%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E6%80%BB%E7%BB%93/","excerpt":"Spring Cloud Gateway相关问题分析、解决思路的过程。 Connection prematurely closed BEFORE response 浪涌导致网关报错分析","text":"Spring Cloud Gateway相关问题分析、解决思路的过程。 Connection prematurely closed BEFORE response 浪涌导致网关报错分析 问题1（Connection prematurely closed BEFORE response）后端服务偶尔报错Connection prematurely closed BEFORE response。 这个问题的产生原因和解决办法网上很容易找到。我这里只贴出问题原理图和解决办法。详细说明请参考https://javazhiyin.blog.csdn.net/article/details/112914264 原理图 解决办法 spring cloud gateway增加jvm启动参数后进先出策略，确保获取的连接最大概率是最近刚被用过的 1-Dreactor.netty.pool.leasingStrategy=lifo 后端服务配置后端服务连接超时时长改为10秒（默认20s），超时没有数据交互则关闭连接。 123server: tomcat: connection-timeout: 10000 spring cloud gateway增加配置设置连接的最大空闲时长为5秒（默认NULL：响应完成即可关闭），超时则关闭连接释放资源。这个时长的设置要小于后端服务的连接超时时长，确保网关回收请求在后端服务回收请求之前完成。 123456spring: cloud: gateway: httpclient: pool: max-idle-time: 5000 问题2（浪涌导致网关报错分析） 每天不定时出现响应失败，Nginx响应状态码出现大量的500和504，网关同样出现大量的500和504，后端服务正常。 Nginx、Gateway、Service每小时统计数如下，其中Nginx，0点的数比较少是因为日志文件截取导致缺失 经过分析得到，2点是正常情况，Nginx-&gt;Gateway-&gt;Service数都对的上。 1点的数据显示Service收到的请求数减少，响应时间也正常，Gateway报错分为504：Gateway响应时间超过导致（配置的60s），500：Gateway连接超过导致（配置的3s），说明Gateway请求并未到达Service端。 查看Nginx和Gateway的连接数出现了激增，因为外部流量瞬间涌入导致服务器连接数资源被占用。 优化方案 开启Gateway限流策略 1234567891011spring: cloud: gateway: default-filters: - name: RequestRateLimiter args: redis-rate-limiter.replenishRate: 200 redis-rate-limiter.burstCapacity: 50 redis-rate-limiter.requestedTokens: 1 key-resolver: &quot;#&#123;@userKeyResolver&#125;&quot; deny-empty-key: false Gateway请求Service超时配置的60s，根据业务需要超过10s响应都视作无效，所以配置响应超时时间为10秒 123456spring: cloud: gateway: httpclient: pool: response-timeout: 10s Gateway的连接池使用弹性方式，导致服务器连接数资源被占满，改为固定方式。 12345678910111213spring: cloud: gateway: httpclient: pool: # 线程池类型，ELASTIC：弹性，FIXED：固定 type: FIXED # 超过此时间连接不使用就关闭 max-idle-time: 5000 # 线程池最大连接数，type=FIXED时有效 max-connections: 200 # 从线程池获取线程的最大等待时间，type=FIXED时有效 acquire-timeout: 45000 由于Gateway到不同的Service，响应时间不一样，可以在Service端的元数据信息中修改连接超时时间和响应超时时间 1234567spring: cloud: nacos: discovery: metadata: response-timeout: 10000 connect-timeout: 3000","categories":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/"},{"name":"SpringCloud","slug":"技术/SpringCloud","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/SpringCloud/"}],"tags":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/tags/%E6%8A%80%E6%9C%AF/"},{"name":"线上问题处理","slug":"线上问题处理","permalink":"http://www.lights8080.com/tags/%E7%BA%BF%E4%B8%8A%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://www.lights8080.com/tags/SpringCloud/"}]},{"title":"思维乱撞","slug":"杂谈/思维乱撞","date":"2021-05-12T16:00:00.000Z","updated":"2021-06-07T09:02:43.000Z","comments":true,"path":"2021/05/13/杂谈/思维乱撞/","link":"","permalink":"http://www.lights8080.com/2021/05/13/%E6%9D%82%E8%B0%88/%E6%80%9D%E7%BB%B4%E4%B9%B1%E6%92%9E/","excerpt":"思维局限性、美国个人支付、奋斗一生和及时行乐","text":"思维局限性、美国个人支付、奋斗一生和及时行乐 如果发现一个软件很活跃，但你觉得用另一个产品不是更好吗甚至这个软件还有某些缺陷。那一定是你没有遇到适用场景，当遇到时，你会说这正是我想要的产品。 产品经理，应该从产品角度去思考用怎样的功能满足需求，而不是简单的把需求做成功能。 不懂产品，迎合需求，长期来看就是负债。 开发人员如果更懂产品，会写出更良好的结构化代码，而不是给代码打补丁。 移动支付对我们来说太平常了。随处都可以拿出手机扫码支付。但是在美国个人支票几乎天天都还在用。出门购物刷信用卡/现金，金额较大的大都还用个人支票，比如：缴学费、交房租、还贷、包红包等。 我们看来这太落伍了，但站在系统角度，考虑健壮性和可用性，个人支票支付方式是个很好的方案。支付环境不依赖网络，设备，电力系统。单靠信用体系维护运行，零成本。 有些人奋斗一生，生活水平提高了不少，但迫于社会价值观，内心所想被压抑一生。 有些人及时行乐，生活虽不富裕，但活的简简单单，随心所欲（在不伤害别人的前提下）。 艰苦奋斗还是随遇而安，卸掉社会属性，单从生命个体的角度看，怎样的一生更符合生命的本质呢？ 写完之后我也不知道是怎么把它们联系在一起了。。。","categories":[{"name":"杂谈","slug":"杂谈","permalink":"http://www.lights8080.com/categories/%E6%9D%82%E8%B0%88/"}],"tags":[{"name":"杂谈","slug":"杂谈","permalink":"http://www.lights8080.com/tags/%E6%9D%82%E8%B0%88/"},{"name":"美国个人支票","slug":"美国个人支票","permalink":"http://www.lights8080.com/tags/%E7%BE%8E%E5%9B%BD%E4%B8%AA%E4%BA%BA%E6%94%AF%E7%A5%A8/"}]},{"title":"ELK-实践（架构选择&部署说明）","slug":"技术/ELK/ELK-实践（架构选择&部署说明）","date":"2021-05-09T16:00:00.000Z","updated":"2021-06-07T06:07:28.000Z","comments":true,"path":"2021/05/10/技术/ELK/ELK-实践（架构选择&部署说明）/","link":"","permalink":"http://www.lights8080.com/2021/05/10/%E6%8A%80%E6%9C%AF/ELK/ELK-%E5%AE%9E%E8%B7%B5%EF%BC%88%E6%9E%B6%E6%9E%84%E9%80%89%E6%8B%A9&%E9%83%A8%E7%BD%B2%E8%AF%B4%E6%98%8E%EF%BC%89/","excerpt":"介绍业务规模和架构选择，以及部署说明。基于7.11版本。","text":"介绍业务规模和架构选择，以及部署说明。基于7.11版本。 业务规模业务每天查询量在千万级，采集数据的规模上亿（后续会更大）。单台Logstash，数据延迟并不大，肉眼可见的Logstash的数据处理能力 架构选择ELK架构有很多种，这里简单列出常用的几个： 架构1（最为简单）Logstash -&gt; Elasticsearch -&gt; Kibana 架构2（使用Beats作为日志收集器）Beats -&gt; Logstash -&gt; Elasticsearch -&gt; Kibana 架构3（引入消息队列）Beats -&gt; Logstash -&gt; Kafka -&gt; Logstash -&gt; Elasticsearch -&gt; Kibana 其中架构3可能是被大家积极推荐和最为认可的理想架构。优点是消息队列可以把数据缓存起来避免数据丢失，可以抵挡浪涌削峰填谷，保护下游Logstash。适用于日志规模比较庞大的场景。 但我的实践中采用的架构2，理由如下： 消除不必要的复杂性，较低成本 关于数据丢失，Filebeat至少投递一次和Logstash持久队列可以解决这个问题 日志规模比较大的情况，可以水平扩展Logstash节点，一组Logstash之间实现负载 实践Logstash处理能力很强 部署说明&amp;实践配置介绍服务器环境配置，以及Elasticsearch、Kibana、Logstash、Filebeat的部署和配置参考。 logstash-7.11.2/config/lights.conf filebeat-7.11.2/inputs.d/lights.yml关于业务的这两个配置，不理解的请私信或留言吧 新建用户和修改文件夹权限123456# 新建用户$ groupadd elk$ useradd -m -d /home/elk -s /bin/bash -g elk elk# 修改文件夹所属组$ chown -R elk:elk /opt/elk$ chown -R elk:elk /data/elk 修改系统配置 vim /etc/sysctl.conf 1vm.max_map_count = 262144 vim /etc/security/limits.conf 12elk soft memlock unlimitedelk hard memlock unlimited Elasticsearch vim bin/elasticsearch 12export JAVA_HOME=/opt/elk/elasticsearch-7.11.2/jdkexport PATH=$JAVA_HOME/bin:$PATH vim config/jvm.options 12-Xms8g-Xmx8g vim config/elasticsearch.yml 1234567891011121314151617181920cluster.name: elasticsearchnode.name: node-1node.master: truenode.data: truenode.ingest: truepath.data: /data/elk/elasticsearch/datapath.logs: /data/elk/elasticsearch/logsnetwork.host: &quot;10.88.2.1&quot;http.port: 9200transport.port: 9300discovery.seed_hosts: [&quot;10.88.2.1&quot;]#discovery.type: single-nodecluster.initial_master_nodes: [&quot;10.88.2.1&quot;]http.cors.enabled: truehttp.cors.allow-origin: &quot;*&quot;bootstrap.memory_lock: truebootstrap.system_call_filter: truexpack.security.enabled: true 命令 1234# 启动$ sh ./bin/elasticsearch -d -p es.pid# 初始化内置用户$ bin/elasticsearch-setup-passwords auto Kibana vim config/kibana.yml 12345678910server.port: 5601server.host: &quot;0.0.0.0&quot;server.name: &quot;elk-1&quot;elasticsearch.hosts: [&quot;http://10.88.2.1:9200&quot;]elasticsearch.username: &quot;kibana_system&quot;elasticsearch.password: &quot;xxxxxxx&quot;i18n.locale: &quot;zh-CN&quot;xpack.reporting.encryptionKey: &quot;something_at_least_32_characters&quot;xpack.security.encryptionKey: &quot;something_at_least_32_characters&quot;xpack.encryptedSavedObjects.encryptionKey: &quot;something_at_least_32_characters&quot; 命令 123456# 启动$ nohup sh ./bin/kibana &gt;kibana.log 2&gt;&amp;1 &amp;# 查看端口netstat -napl|grep 5601# 停止kill &lt;port&gt; Logstash vim config/jvm.options 12-Xms4g-Xmx4g vim config/logstash.yml 12pipeline.workers: 4queue.type: persisted vim config/lights.conf 1# 略，请参考实践配置 命令1234# 测试配置$ ./bin/logstash -f config/lights.conf --config.test_and_exit# 启动$ nohup ./bin/logstash -f config/lights.conf --config.reload.automatic &gt; logstash.log &amp; Filebeat vim filebeat.yml 12345678filebeat.config.inputs: enabled: true path: $&#123;path.config&#125;/inputs.d/*.yml reload.enabled: true reload.period: 10soutput.logstash: hosts: [&quot;10.88.2.1:5044&quot;] vim inputs.d/lights.yml 1# 略，请参考实践配置 命令 12# 启动$ nohup ./filebeat -e &gt;filebeat.log 2&gt;&amp;1 &amp; Metricbeat vim metricbeat.yml 123456789101112131415161718192021metricbeat.config.modules: path: $&#123;path.config&#125;/modules.d/*.yml reload.enabled: truesetup.template.settings: index.number_of_shards: 1 index.codec: best_compressionsetup.kibana: host: &quot;10.88.2.1:5601&quot; username: &quot;elastic&quot; password: &quot;xxx&quot;output.elasticsearch: hosts: [&quot;10.88.2.1:9200&quot;] username: &quot;elastic&quot; password: &quot;xxx&quot;processors: - add_host_metadata: ~ vim modules.d/elasticsearch-xpack.yml 123456- module: elasticsearch xpack.enabled: true period: 10s hosts: [&quot;http://10.88.2.1:9200&quot;] username: &quot;elastic&quot; password: &quot;password&quot; 命令 1234# 开启elasticsearch模块$ ./metricbeat modules enable elasticsearch-xpack# 启动$ nohup ./metricbeat -e &gt;metricbeat.log 2&gt;&amp;1 &amp;","categories":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/"},{"name":"ELK","slug":"技术/ELK","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/ELK/"}],"tags":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/tags/%E6%8A%80%E6%9C%AF/"},{"name":"ELK","slug":"ELK","permalink":"http://www.lights8080.com/tags/ELK/"}]},{"title":"Beats-Filebeat命令&配置说明","slug":"技术/ELK/Beats-Filebeat命令&配置说明","date":"2021-04-28T16:00:00.000Z","updated":"2021-06-07T01:59:18.000Z","comments":true,"path":"2021/04/29/技术/ELK/Beats-Filebeat命令&配置说明/","link":"","permalink":"http://www.lights8080.com/2021/04/29/%E6%8A%80%E6%9C%AF/ELK/Beats-Filebeat%E5%91%BD%E4%BB%A4&%E9%85%8D%E7%BD%AE%E8%AF%B4%E6%98%8E/","excerpt":"介绍Filebeat命令、配置以及最佳实战。 基于7.11版本。","text":"介绍Filebeat命令、配置以及最佳实战。 基于7.11版本。 命令 export：导出配置到标准输出（configuration, index template, ILM policy, dashboard） keystore：管理秘钥仓库 modules：管理模块配置 run：运行Filebeat。不知道命令的情况下，默认使用此命令 –modules MODULE_LIST：指定运行的模块 setup：一次性初始化环境。包括索引模板，ILM政策，写别名，Kibana仪表盘等 –dashboards：设置Kibana仪表盘，需配置连接Kibana信息 –pipelines：设置Elasticsearch的ingest pipelines -e：发送输出到标准错误而不是syslog –index-management：设置与Elasticsearch索引管理相关的组件（template, ILM policy, and write alias） test：测试配置文件 全局标记 -E, –E “SETTING_NAME=VALUE”：覆盖指定的配置 -M, –M “VAR_NAME=VALUE”：覆盖默认的模块配置 -c, –c FILE：指定Filebeat的配置文件 -f：指定管道配置文件 -d, –d SELECTORS：调试选择器，”*”：开启所有组件的调试，”publish”：开启调试”publish“相关信息 -e, –e：日志发送到stderr并禁用syslog文件输出 –path.config：设置配置文件路径 示例： 123456789# 一次性设置Elasticsearch索引和Kibana仪表板，-e：发送输出到标准错误而不是syslog./filebeat setup -e# 启用要运行的模块./filebeat modules enable system# 启动sudo chown root filebeat.yml sudo ./filebeat -c filebeat.yml -e 配置说明 filebeat.yml project paths：项目路径 general settings：配置包括Global、General config file loading：允许外部加载inputs和modules配置 modules：一种开始处理常见日志格式的快速方法 inputs：指定Filebeat查找和处理的数据 output：指定输出。如：Logstash、Elasticsearch、Kafka Processors：过滤和增强导出的数据 internal queue：存储事件的内部缓冲队列（内存和磁盘），负责缓冲输入事件并按批次发送到输出。 load balancing：配置输出的负载均衡 logging：Filebeat日志输出选项 http endpoint：Filebeat通过端点查看内部指标 autodiscover：容器运行时，自动发现配置，移动目标的监视系统 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188### project Paths# Filebeat主目录，默认安装路径path.home: path.config: $&#123;path.home&#125;path.data: $&#123;path.home&#125;/datapath.logs: $&#123;path.home&#125;/logs### Global Filebeat configuration options# 注册表的根路径，默认$&#123;path.data&#125;/registryfilebeat.registry.path: registryfilebeat.registry.file_permissions: 0600# 控制何时将注册表项写入磁盘(刷新)的超时值filebeat.registry.flush: 0s# Filebeat 在关闭之前等待发布者完成发送事件的关闭时间filebeat.shutdown_timeout: 5s### General configuration options# Beat的名字，默认使用主机名name: my-service# 标记列表，方便Kibana或Logstash过滤，如服务层，集群名等tags: [&quot;service-X&quot;, &quot;web-tier&quot;]# 属性中添加附加信息的可选字段，如环境信息fields: env: staging service_name: service-X# 将自定义字段作为顶级字段存储到到输出文档中，默认falsefields_under_root: false### Processors configuration# 定义模块的处理器，删除所有DEBUG消息processors: - drop_event: when: regexp: message: &quot;^DBG:&quot;### Logginglogging.level: infologging.to_files: truelogging.files: path: /var/log/filebeat name: filebeat # 日志文件最大大小，默认10M rotateeverybytes: 10485760 # 日志滚动删除旧文件，默认7 keepfiles: 7 # 日志文件滚动周期，默认禁用 interval: 24h # 标准错误记录到日志文件中 redirect_stderr: false# 定期记录内部发生变化的指标，默认开启logging.metrics.enabled: true# 记录内部指标的时间logging.metrics.period: 30s### 外部配置filebeat.config.inputs: enabled: true # 要检查的更改文件路径 path: configs/*.yml # 开启配置动态加载 reload.enabled: true # 指定检查文件更改的频率 reload.period: 10sfilebeat.config.modules: path: $&#123;path.config&#125;/modules.d/*.yml reload.enabled: false### 日志输入filebeat.inputs:- type: log enabled: true paths: - &quot;/var/log/wifi.log&quot; - &quot;/var/log/apache2/*&quot; - &quot;/var/log/*/*.log&quot; # 递归模式，默认false。For example: /foo/** expands to /foo, /foo/*, /foo/*/*, and so on recursive_glob.enabled: false # 文件编码 encoding: plain # 设置标记文件的位置 file_identity.inode_marker.path: /logs/.filebeat-marker # 标记列表，方便Kibana或Logstash过滤 tags: [&quot;service-X&quot;, &quot;web-tier&quot;] # 属性中添加附加信息的可选字段 fields: env: staging # 将自定义字段作为顶级字段存储到到输出文档中 fields_under_root: false # 包含的正则表达式列表，先于exclude_lines执行 include_lines: [&#x27;^ERR&#x27;, &#x27;^WARN&#x27;] # 排除的正则表达式列表 exclude_lines: [&#x27;^DBG&#x27;] # 多行消息匹配,Java 堆栈跟踪的例子（https://www.elastic.co/guide/en/beats/filebeat/7.x/multiline-examples.html） multiline.type: pattern multiline.pattern: &#x27;^[[:space:]]+(at|\\.&#123;3&#125;)[[:space:]]+\\b|^Caused by:&#x27; # 否定模式，true：没有匹配的行作为事件行的连贯行；false：匹配的行作为事件行的连贯行。默认false。 multiline.negate: false # 连贯行组合事件行之前（before）还是之后（after） multiline.match: after # 每个收割机获取文件时使用的缓冲区大小 harvester_buffer_size: 16384 # 单个日志消息的最大字节数，超出部分丢弃（10M） max_bytes: 10485760 # 排除文件 exclude_files: [&#x27;\\.gz$&#x27;] ##### Harvester closing options # 指定的时间段后关闭文件句柄，基于文件的修改，被扫描到后继续进行。建议设置一个大于最少更新频率的值，默认5分钟 close_inactive: 5m # 重命名或移动文件时关闭收割机，默认关闭 close_renamed: false # 删除文件时立马关闭收割机，当文件再次出现时被扫描到后继续进行，默认启用 close_removed: true # 收割机到达文件末尾时立刻关闭，默认禁用 close_eof: false # 指定时间后关闭，按照扫描频路再次开启新的收割机，默认禁用 close_timeout: 0 ##### State options # 指定时间段后文件无更新，则清除注册表中的状态，默认0，表示禁用清除注册表。clean_inactive设置必须大于ignore_older + scan_frequency，否则可能导致不断的重新发送全部内容 clean_inactive: 0 # 重命名或移动的文件，注册表中的状态将被清除。默认开启 clean_removed: true # 扫描频率，默认10秒 scan_frequency: 10s # 扫描顺序，默认禁用，可选值：modtime|filename。如果为此设置指定值，则可以使用scan.order配置文件是按升序还是降序进行扫描 scan.sort: scan.order: asc|desc # Filebeat 将开始在每个文件的结尾而不是开始读取新文件，适用于Filebeat尚未处理的文件。如果已经运行过Filebeat并且文件的状态已经保留，则tail_files配置无效。 tail_files: false # 忽略在指定时间跨度之前修改的所有文件，依赖于文件的修改时间。默认0，不忽略任何文件。必须大于close_inactive ignore_older: 0 # 限制并行启动的收割机数量 harvester_limit: 0 # 根据文件的inode和设备id来区分文件 file_identity.native: ~ # 根据路径来区分文件 file_identity.path: ~### 日志输出output.kafka: # kafka服务器 hosts: [&quot;kafka1:9092&quot;, &quot;kafka2:9092&quot;, &quot;kafka3:9092&quot;] # 动态设置topic topic: &#x27;%&#123;[fields.log_topic]&#125;&#x27; # 事件将仅发布到可用分区 partition.round_robin: reachable_only: false # ACK可靠性级别，默认1。0 = no response，1 = wait for local commit，-1 = wait for all replica to commit required_acks: 1 # gzip压缩级别，0禁用压缩 compression: gzip compression_level: 4 # 消息的最大字节数 max_message_bytes: 1000000# 负载均衡的Logstashoutput.logstash: hosts: [&quot;localhost:5044&quot;, &quot;localhost:5045&quot;] loadbalance: true worker: 2 ### Internal queue# 用于缓冲要发布的事件的内部队列配置。默认mem（内存队列）queue.mem: # 内存队列的最大缓冲事件数 events: 4096 # 发布所需的最小事件数，设置为0则发布事件直接输出使用，无需等待 flush.min_events: 2048 # 达到flush.min_events的最大等待事件，设置为0则无需等待 flush.timeout: 1squeue.disk: # 启用磁盘队列，指定最大大小既使用空间 max_size: 10GB path: $&#123;path.data&#125;/diskqueue # 队列文件以段的形式保存，每个段包含一些待发送到输出的事件，所有事件发送后删除 segment_size: max_size / 10 # 当事件等待输出时，从磁盘读取到内存中的事件数。调高此值可以提高输出速度，但是会占用更多内存 read_ahead: 512 # 队列等待事件写入磁盘时可以存储到内存中的事件数 write_ahead: 2048 # 磁盘错误导致的队列操作失败，重试间隔时间 retry_interval: 1s # 多个连续的写入磁盘错误，队列将重试间隔增加2倍，最大间隔时间 max_retry_interval: 30squeue.spool: 最佳实践调优 文件内容变更延迟发送事件调优默认基于内存缓冲事件，最晚需要11s才会发布事件到输出。filebeat.inputs.type:log.scan_frequency: 10s：文件的扫描频率queue.mem.flush.timeout: 1s：缓冲事件的超时时间queue.mem.flush.min_events: 2048：超时时间内发布事件所需的最小缓冲数 测试时编辑文件导致整个文件内容重新发送不要用vim修改，使用echo &quot;xxx&quot; &gt;&gt; log_file","categories":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/"},{"name":"ELK","slug":"技术/ELK","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/ELK/"}],"tags":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/tags/%E6%8A%80%E6%9C%AF/"},{"name":"ELK","slug":"ELK","permalink":"http://www.lights8080.com/tags/ELK/"},{"name":"Filebeat","slug":"Filebeat","permalink":"http://www.lights8080.com/tags/Filebeat/"}]},{"title":"Kibana-介绍","slug":"技术/ELK/Kibana-介绍","date":"2021-04-28T16:00:00.000Z","updated":"2021-06-10T03:04:32.000Z","comments":true,"path":"2021/04/29/技术/ELK/Kibana-介绍/","link":"","permalink":"http://www.lights8080.com/2021/04/29/%E6%8A%80%E6%9C%AF/ELK/Kibana-%E4%BB%8B%E7%BB%8D/","excerpt":"介绍Kibana的侧边栏、面板类型、配置说明等。基于7.11版本。","text":"介绍Kibana的侧边栏、面板类型、配置说明等。基于7.11版本。 Kibana Kibana是一个开源分析和可视化平台，旨在与Elasticsearch协同工作。您使用Kibana搜索，查看和与存储在Elasticsearch索引中的数据进行交互。您可以轻松执行高级数据分析，并在各种图表，表格和地图中可视化您的数据。https://www.elastic.co/guide/en/kibana/7.11/index.html 侧边栏 Discover（数据探索）：搜索、过滤和展示所选索引模型（Index Pattern）文档数据 Visualize（可视化）：为数据创建可视化控件 Dashboard（仪表盘）：展示保存的可视化结果集合 Canvas（画布）：非常自由灵活对数据进行可视化布局与展现 Maps（地图）：已地图的方式展示聚合信息 Machine Learning（机器学习） Infrastructure（基础设施监控）：通过metricbeat监控基础服务。如：redis、rocketmq Metrics（度量应用）：探索整个生态系统中有关系统和服务的指标 Logs（日志）：实时跟踪相关的日志数据；提供了一个紧凑的，类似控制台的显示器。可以实时日志拖尾 APM（Application Performance Monitoring-应用程序性能监视）：业务跟踪及监控。 Uptime（正常运行时间）：监控应用程序和服务的可用性问题；通过HTTP/S，TCP和ICMP监控网络端点的状态 SIEM（Security Information &amp; Event Management-安全信息与事件管理）：安全分析师的高度交互式工作区 Dev Tools（开发工具）：包括控制台、查询分析和聚合 Stack Monitoring（ELK监控）：可视化监控数据 Management（Kibana管理）：包括索引模式的初始设置和持续配置等 Dashboard（仪表板）仪表板是用于分析数据的面板的集合。在仪表板上，您可以添加各种面板，可以重新排列并讲述关于数据的故事。 编辑仪表板： Add controls（添加控制器） Add markdown（添加说明文档） Arrange panels（面板排版） Clone panels（克隆面板） Customize time ranges（自定义时间范围） 探索仪表板数据： Inspect elements（检查元素）：查看可视化和保存的搜索背后的数据和请求 Explore underlying data（探索面板底层数据）：可以在其中查看和过滤可视化面板中的数据，为了探索仪表板上面板的底层数据，Kibana打开了Discover，可视化的索引模式、筛选器、查询和时间范围将继续应用。仅适用于单个索引模式的面板 自定义仪表板操作： Dashboard drilldowns（仪表盘深度探讨）：能够从另一个仪表板打开仪表板，带有时间范围、过滤器和其他参数，因此上下文保持不变。仪表板钻取可以帮助您从一个新的角度继续分析。 URL drilldowns（URL深度探讨）：能够从仪表板导航到内部或外部URL。目标URL可以是动态的，这取决于仪表板上下文或用户与面板的交互。 共享仪表板： 将代码嵌入网页中，必须具有Kibana访问权限才能查看嵌入式仪表板 直接链接到 Kibana 的控制面板 生成PDF/PNG报告 面板类型 Area（面积图）：使用面积图比较两个或多个类别随时间变化的趋势，并显示趋势的幅度。 Stacked Area（堆积面积图）：使用堆积面积图可视化部分-整体关系，并显示每个类别对累积总数的贡献。 Bar（条形图）：使用条形图对大量类别的数据进行比较，也支持水平条形图。 Stacked bar（堆积条形图）：使用堆叠的条形图可以比较分类值级别之间的数值。 Line（折线图）：使用折线图可以直观地显示一系列值，发现一段时间内的趋势并预测未来值。 Pie（饼图）：使用饼图显示多个类别之间的比较，说明一个类别相对于其他类别的优势，并显示百分比或比例数据。 Donut（甜甜圈图）：与饼形图相似，但删除了中心圆。当您想一次显示多个统计信息时，请使用甜甜圈图。 Tree map（树图）：将数据的不同部分关联到整体，使用树图可以有效利用空间来显示每个类别的总计百分比。 Heat map（热图）：显示数据的图形表示形式，其中各个值由颜色表示。当数据集包含范畴数据时，使用热图。 Goal（进度图）：显示指标如何朝固定目标发展，使用目标显示目标进度状态的易于阅读的视觉效果。 Gauge（计量图）：沿比例尺显示数据，使用计量图来显示度量值与参考阈值的关系。 Metric（度量值）：显示聚合的单个数值。 Data table（表格数据）：以表格格式显示原始数据或聚合结果。 Tag cloud（标签云）：显示单词在出现的频率，使用标签云可以轻松生成大型文档的摘要。 Maps（地图） Lens（透镜）：创建强大的数据可视化效果的最简单、最快捷的方法。可以将任意多的数据字段拖放到可视化构建窗格中。 TSVB（时间序列数据）：TSVB是时间序列数据可视化工具，充分利用Elasticsearch聚合框架的功能。可以组合无数个聚合来显示数据。支持：选择不同的数据展示方式、叠加注释事件等。 Timelion（时间序列数据）：时间序列数据可视化工具，可以在单个可视化文件中组合独立的数据源。在7.0及更高版本中，不建议使用Timelion应用。 Vega（自定义可视化）：使用Vega和Vega-Lite构建自定义可视化，并由一个或多个数据源支持。支持：使用嵌套或父/子映射的聚合、没有索引模式的聚合、自定义时间过滤器查询、复杂的计算、从_source而不是聚合中提取数据等。 Controls（控制器）：可以实时过滤面板上的数据，支持选择列表和范围滑杆 Markdown（文本编辑器）：当您要将上下文（例如重要信息，说明和图像）添加到仪表板上的其他面板时，请使用Markdown。 Alerts and Actions（监控警报） General alert details（警报详细信息）： Name：警报名称，显示在警报列表，帮助识别和查询警报 Tags：警报标签列表，显示在警报列表，有助于查询和组织警报 Check every：检查警报条件的频率 Notify every：限制重复报警的频率 Alert type and conditions（警报类型和条件）：选择不同的警报类型不同的条件表达形式。 Index threshold：索引阈值警报类型 Action type and action details（动作类型和详细信息）：每个操作都必须指定一个连接器实例。 Index：Index data into Elasticsearch Email：Send email from your server Server log：Add a message to a Kibana log Webhook：Send a request to a web service Graph（图形分析）图形分析功能使您能够发现 Elasticsearch 索引中的项目是如何相关的。您可以研究索引词汇之间的连接，并查看哪些连接最有意义。这在各种应用程序中都很有用，从欺诈检测到推荐引擎。 例如，图形浏览可以帮助您发现黑客所针对的网站漏洞，从而可以加固您的网站。或者，您可以向电子商务客户提供基于图的个性化推荐。 图形分析特性为 Kibana 提供了一个简单但强大的图形探索 API 和一个交互式图形可视化工具。两者都可以在现有的 Elasticsearch 索引中使用ー你不需要存储任何额外的数据来使用这些特性。 kibana.yml1234567891011server.port: 5601server.host: &quot;0.0.0.0&quot;server.name: &quot;elk-1&quot;i18n.locale: &quot;zh-CN&quot;elasticsearch.hosts: [&quot;http://your_elasticsearch_host:9200&quot;]elasticsearch.username: &quot;kibana_system&quot;elasticsearch.password: &quot;xxxxxxxxxxxxxxx&quot;# 防止会话在重启时失效xpack.security.encryptionKey: &quot;something_at_least_32_characters&quot;# 防止挂起的报告在重新启动时失败xpack.reporting.encryptionKey: &quot;something_at_least_32_characters&quot; 问题1. 创建索引失败错误信息：POST 403 (forbidden) on create index pattern解决办法： 12345678PUT _settings&#123; &quot;index&quot;: &#123; &quot;blocks&quot;: &#123; &quot;read_only_allow_delete&quot;: &quot;false&quot; &#125; &#125;&#125;","categories":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/"},{"name":"ELK","slug":"技术/ELK","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/ELK/"}],"tags":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/tags/%E6%8A%80%E6%9C%AF/"},{"name":"ELK","slug":"ELK","permalink":"http://www.lights8080.com/tags/ELK/"},{"name":"Kibana","slug":"Kibana","permalink":"http://www.lights8080.com/tags/Kibana/"}]},{"title":"人格分裂","slug":"杂谈/人格分裂","date":"2021-04-27T16:00:00.000Z","updated":"2021-06-07T09:14:34.000Z","comments":true,"path":"2021/04/28/杂谈/人格分裂/","link":"","permalink":"http://www.lights8080.com/2021/04/28/%E6%9D%82%E8%B0%88/%E4%BA%BA%E6%A0%BC%E5%88%86%E8%A3%82/","excerpt":"人格分裂和癌细胞一样，是人类无法驾驭的更强大的存在","text":"人格分裂和癌细胞一样，是人类无法驾驭的更强大的存在 癌细胞为什么是人类无法驾驭的更强大的存在呢？生命的存在是因为细胞分裂，正常的细胞分裂，都会磨损真核细胞染色体末端的端粒酶，端粒酶没有了就无法继续分裂。但是癌细胞却有修复端粒酶的能力，可以无限繁殖下去，这正是永生的破解密码。 人格分裂/多重人格被定义为一种心理疾病，一个生命个体上存在两种或以上不同身份和人格状态。直白点说就是一个身体里住着好几个灵魂。 把这灵魂分为两类：受我们意愿所控制的灵魂定义为主灵魂，那些不受我们意愿控制的灵魂为独立灵魂。 人的一生中应该都会遇到许多次的轻微的人格分裂时刻。比如当你失恋了，你满脑子都是失恋的情景，你明明不想让自己想那个情景，但是就是不受控制的在脑子里闪现。这个失恋的情景就是独立灵魂，不受控制的让你去想。 当大脑进入这样的状态时，有了不受控制的独立意识，我认为就是轻微的人格分裂了。这种状态下，大脑非常疲惫（就好像汽车一直开在160km/h，又无法刹车），无法集中精力做事，甚至会影响你的身体状态。 在这种状态下，喜欢抽烟喝酒，想用外界的干预来抑制或麻醉独立灵魂。 人格分裂对于生命体来说无疑是非常痛苦的，但是对于人脑组织或灵魂来说，是不是进化了呢？ 灵魂是不是更高维度的存在，降维寄宿到人的身体里。想象一下灵魂出窍，其实不是生命体有灵魂，而是灵魂寄宿在生命体当中，人格分裂的人，是多个灵魂共同寄宿在同一个生命体中，生命结束的时候灵魂就会飞走。","categories":[{"name":"杂谈","slug":"杂谈","permalink":"http://www.lights8080.com/categories/%E6%9D%82%E8%B0%88/"}],"tags":[{"name":"杂谈","slug":"杂谈","permalink":"http://www.lights8080.com/tags/%E6%9D%82%E8%B0%88/"}]},{"title":"Beats-Filebeat介绍","slug":"技术/ELK/Beats-Filebeat介绍","date":"2021-04-27T16:00:00.000Z","updated":"2021-06-08T02:23:20.000Z","comments":true,"path":"2021/04/28/技术/ELK/Beats-Filebeat介绍/","link":"","permalink":"http://www.lights8080.com/2021/04/28/%E6%8A%80%E6%9C%AF/ELK/Beats-Filebeat%E4%BB%8B%E7%BB%8D/","excerpt":"Filebeat介绍，包括工作方式、模块、如何避免数据重复、处理器的速查表。 基于7.11版本。","text":"Filebeat介绍，包括工作方式、模块、如何避免数据重复、处理器的速查表。 基于7.11版本。 Beats是一款轻量级数据采集器，你可以将它作为代理程序安装在你的服务器上，然后将操作数据发送到 Elasticsearch。可以直接发送数据到 Elasticsearch 或者通过 Logstash，在那里你可以进一步处理和增强数据。 Filebeat（日志文件） Metricbeat（指标） Heartbeat（可用性监控） Functionbeat（函数计算采集器） Filebeat Filebeat是用于转发集中日志数据的传输工具。作为服务器上的代理安装，收集日志事件，并将它们转发到Elasticsearch或Logstash。https://www.elastic.co/guide/en/beats/filebeat/7.11/index.html 工作方式当启动Filebeat，会根据显示指定的日志数据启动一个或多个输入，每个日志文件都会启动一个收割机（harvester）。每个收割机会读取日志的最新内容，并将日志数据发送到libbeat，libbeat汇总事件并发送到输出。 Filebeat由两个主要部分组成：inputs和harvesters。它们一起工作以尾部文件将事件数据发送到指定的输出。 收割机（harvesters）：一个收割机负责读取单个文件的内容。收割机逐行读取每个文件并将内容发送到输出。每个文件启动一个收割机负责打开和关闭文件，收割机运行时文件描述符保持打开状态。如果文件被删除或重命名，Filebeat将继续读取该文件，副作用是磁盘上的空间将保留到收割机关闭为止。 输入（inputs）：一个输入负责管理收割机并查找所有可读取的资源。日志类型输入检查每个文件，以查看收割机是否需要启动，是否已经运行，或是否需要忽略该文件。自收割机关闭之后，如果文件大小有更改才会获取新行。 Filebeat保持每个文件的状态，并经常将状态刷新到磁盘的注册表文件。该状态用于记录收割机正在读取的最后一个偏移量并确保发送所有的日志行。如果输出不可达，则Filebeat会保持跟踪发送的最后几行，并在输出可用时继续读取文件。Filebeat运行时状态信息也会保持在内存中，当Filebeat重启时，将使用注册文件中的数据重新构建状态，并且在最后一个已知位置继续每个收割机。 对于每个输入，Filebeat会保持每个文件的状态。由于文件可以重命名和移动，因此文件名和路径不能标识一个文件。Filebeat将存储每个文件的唯一标识符以检测文件是否以前被获取过。 Filebeat保证事件将至少一次传递到输出，并且不会丢失数据。因为他在注册文件中存储了每个事件的传递状态。如果输出被阻止或未确认所有事件的情况下，Filebeat将继续尝试发送事件，直到输出确认接收为止。如果Filebeat在发送事件的过程中关闭，则不会等待输出确认所有的事件。重启Filebeat时，将再次发送关闭之前输出未确认的所有事件。这样可以确保每个事件至少发送一次，但是有可能会重复发送。 如何避免Elasticsearch数据重复由于Beats框架确保至少一次交付，又由于Elasticsearch的文档ID通常是接受到数据后才设置的，因此重复事件被索引为新文档。通过在建立索引期间设置，则Elasticsearch会覆盖现有文档而不是新创建一个新文档。 在Beats中设置文档ID。 在Logstash管道设置文档ID。 填充地理位置信息基于IP地址填充地理位置信息。然后可以使用此信息来可视化IP地址在地图中的位置。 Filebeat与Elasticsearch中的GoeIp处理器一起使用 Logstash中使用GeoIP过滤器 模块（Modules） Filebeat模块简化了常见的日志格式的收集，解析和可视化。每个Filebeat模块由一个或多个文件集组成，这些文件集包含摄取节点管道（ingest node pipelines），Elasticsearch模板，Filebeat输入配置和Kibana仪表板。 use ingest pipelines for parsing use Logstash pipelines for parsing 如Nginx日志，由一个或多个文件集组成（access和error）： Filebeat输入配置要查找的日志文件路径，还负责在需要时将多行事件缝合在一起。 Elasticsearch Ingest Node管道定义，用于解析日志行。 定义字段，为每个字段正确的配置到Elasticsearch。 Kibana仪表盘可视化日志文件 处理器（Processors）过滤和增强数据的处理器如果只需要导出的数据的一部分或者需要增强导出数据。Filebeat提供了两个选项来过滤和增强导出的数据。 可以为每个输入指定包含和排除的行或文件，需要为每个输入配置选项。（include_lines, exclude_lines, and exclude_files options） 定义处理器（Processor）可以的导出的所有数据进行全局处理。 可以在配置中定义处理器，在发送到输出之前处理所有事件。libbeat提供的处理器分为： 减少导出字段 增加元数据增强事件 执行其他处理和解码 每个处理器都接收一个事件，对该事件应用已定义的操作，然后返回该事件。如果定义处理器列表，则将按照在Filebeat配置文件中定义的顺序执行它们。执行顺序：event -&gt; processor 1 -&gt; event1 -&gt; processor 2 -&gt; event2 … 123456789101112131415processors: - if: &lt;condition&gt; then: - &lt;processor_name&gt;: &lt;parameters&gt; - &lt;processor_name&gt;: &lt;parameters&gt; ... else: - &lt;processor_name&gt;: &lt;parameters&gt; - &lt;processor_name&gt;: &lt;parameters&gt; ... add_docker_metadata使用来自Docker容器的相关元数据注释每个事件。包括（Container ID、Name、Image、Labels） add_fields将其他字段添加到事件中 add_host_metadata为事件添加主机信息 add_id为事件生成唯一的ID add_labels将一组键值对添加到事件 add_locale通过将机器的时区偏离UTC或时区名称来丰富每个事件 add_tags将标签添加到标签列表中 convert将事件中的字段转换为其他类型，例如将字符串转换为整数。 copy_fields将一个字段复制到另一个字段。 decode_base64_field指定要对base64进行解码的字段 dissect解剖处理器使用定义的模式对传入的字符串进行标记 drop_event如果满足相关条件，则drop_event处理器将丢弃整个事件。条件是强制性的，因为没有一个条件，所有事件都将被丢弃 drop_fields指定在满足特定条件时要删除的字段，条件是可选的。@timestamp和type字段在列表中，也不能删除他们。 fingerprint根据事件字段的指定子集生成事件的指纹。 include_fields指定在满足特定条件时要导出的字段，条件是可选的。@timestamp和type字段，也始终将其导出。 rename指定要重命名的字段的列表。 script执行Javascript代码以处理事件。该处理器使用ECMAScript 5.1的纯Go实现，并且没有外部依赖性。 timestamp时间戳处理器从字段解析时间戳。默认情况下，时间戳处理器将已解析的结果写入@timestamp字段。 truncate_fields将字段截断为给定的大小。如果字段的大小小于限制，则该字段将保持不变。 urldecode指定要从URL编码格式解码的字段列表","categories":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/"},{"name":"ELK","slug":"技术/ELK","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/ELK/"}],"tags":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/tags/%E6%8A%80%E6%9C%AF/"},{"name":"ELK","slug":"ELK","permalink":"http://www.lights8080.com/tags/ELK/"},{"name":"Filebeat","slug":"Filebeat","permalink":"http://www.lights8080.com/tags/Filebeat/"}]},{"title":"ELK-加密通信的说明和配置教程","slug":"技术/ELK/ELK-加密通信的说明和配置教程","date":"2021-04-27T16:00:00.000Z","updated":"2021-06-07T01:58:46.000Z","comments":true,"path":"2021/04/28/技术/ELK/ELK-加密通信的说明和配置教程/","link":"","permalink":"http://www.lights8080.com/2021/04/28/%E6%8A%80%E6%9C%AF/ELK/ELK-%E5%8A%A0%E5%AF%86%E9%80%9A%E4%BF%A1%E7%9A%84%E8%AF%B4%E6%98%8E%E5%92%8C%E9%85%8D%E7%BD%AE%E6%95%99%E7%A8%8B/","excerpt":"介绍Elasticsearch节点之间的加密通信、浏览器与Kibana之间的加密通信、Kibana与Elasticsearch之间的加密通信、操作步骤和配置说明。基于7.11。","text":"介绍Elasticsearch节点之间的加密通信、浏览器与Kibana之间的加密通信、Kibana与Elasticsearch之间的加密通信、操作步骤和配置说明。基于7.11。 1 Elasticsearch加密通信Elastic Stack安全特性能够加密加密往返于Elasticsearch集群以及从其内部的通信。使用传输层安全性(TLS/SSL)保护连接的安全。未启用加密的群集将以纯文本格式（包括密码）发送所有数据。如果启用了Elasticsearch安全功能，除非您具有试用许可证，否则必须配置SSL/TLS进行节点间通信。 1.1 Elasticsearch节点之间的加密通信https://www.elastic.co/guide/en/elasticsearch/reference/7.11/configuring-tls.html#tls-transport Verify that the xpack.security.enabled setting is true.（启用安全功能） Generate a private key and X.509 certificate.（生成私钥和X.509证书） Configure each node to: Required: Enable TLS on the transport layer.（传输层启用TLS） Recommended: Enable TLS on the HTTP layer.（HTTP层启用TLS） 1.2 HTTP客户端的加密通信https://www.elastic.co/guide/en/elasticsearch/reference/7.11/configuring-tls.html#tls-http Generate node certificates.（生成节点证书） Enable TLS and specify the information required to access the node’s certificate.（启用TLS并指定节点证书） Restart Elasticsearch.（重启Elasticsearch） 2 Kibana通信加密传输层安全安全协议(SSL)和传输层安全协议(TLS)为数据传输提供加密。虽然这些术语通常可以互换使用，但 Kibana 只支持 TLS，它取代了旧的 SSL 协议。浏览器将流量发送到 Kibana，Kibana 将流量发送到 Elasticsearch，这些通信通道分别配置为使用 TLS。 2.1 浏览器与Kibana之间的加密通信https://www.elastic.co/guide/en/kibana/7.11/configuring-tls.html#configuring-tls-browser-kib 获得 Kibana 的服务器证书和私钥 配置 Kibana 以访问服务器证书和私钥 将 Kibana 配置为为入站连接启用 TLS 重启 Kibana 2.2 Kibana与Elasticsearch之间的加密通信https://www.elastic.co/guide/en/kibana/7.11/configuring-tls.html#configuring-tls-kib-es Enable TLS on the HTTP layer in Elasticsearch.（在Elasticsearch的HTTP层上启动TLS） Obtain the certificate authority (CA) certificate chain for Elasticsearch.（获取Elasticsearch的证书颁发机构(CA)证书链） used the elasticsearch-certutil http command,include the CA certificate chain in PEM format.（使用elasticsearch-certutil http命令生成CA证书链） extract the CA certificate.（通过PKCS#12文件提取CA证书链） Configure Kibana to trust the Elasticsearch CA certificate chain for the HTTP layer.（配置Kibana以信任HTTP层的Elasticsearch CA证书链） Configure Kibana to enable TLS for outbound connections to Elasticsearch.（配置Kibana与Elasticsearch的连接启用TLS） 3 操作步骤 操作命令 12345678910111213141516# 进入Elasticsearch目录cd /data/elk/elasticsearch-7.11.2# 创建证书颁发机构：获得文件：elastic-stack-ca.p12./bin/elasticsearch-certutil ca# 为每个节点生成证书和私钥，获得文件：elastic-certificates.p12./bin/elasticsearch-certutil cert --ca elastic-stack-ca.p12# 生成专门用于加密HTTP客户端通信的证书，获得文件：elasticsearch-ssl-http.zip./bin/elasticsearch-certutil http# 解压HTTP通信证书，获得文件：elasticsearch/http.p12和kibana/elasticsearch-ca.pemunzip elasticsearch-ssl-http.zip# 在每个Elasticsearch节点的配置目录中创建一个文件夹certs，放置安全证书mkdir /data/elk/elasticsearch-7.11.2/config/certscp elastic-certificates.p12 config/certscp elasticsearch/http.p12 config/certs# 复制HTTP通信证书到Kibana配置目录cp kibana/elasticsearch-ca.pem /data/elk/kibana-7.11.2/config 生成加密HTTP客户端通信证书说明（./bin/elasticsearch-certutil http）参考：https://lights8080.github.io/post/es-an-quan-security 4 参数配置 Elasticsearchelasticsearch-7.11.2/config/elasticsearch.yml 12345678910# 在节点上启用Elasticsearch安全功能xpack.security.enabled: true# 节点间加密通信配置xpack.security.transport.ssl.enabled: truexpack.security.transport.ssl.verification_mode: certificate xpack.security.transport.ssl.keystore.path: elastic-certificates.p12 xpack.security.transport.ssl.truststore.path: elastic-certificates.p12 # HTTP加密通信配置xpack.security.http.ssl.enabled: truexpack.security.http.ssl.keystore.path: &quot;certs/http.p12&quot; Kibanakibana-7.11.2/config/kibana.yml 1234# 配置Kibana与Elasticsearch的连接启用TLSelasticsearch.hosts: [&quot;https://127.0.0.1:9200&quot;]# 配置信任HTTP层的Elasticsearch CA证书链elasticsearch.ssl.certificateAuthorities: [&quot;/data/elk/kibana-7.11.2/config/elasticsearch-ca.pem&quot;] Logstashlogstash-7.11.2/config/logstash-sample.conf 12345678output &#123; elasticsearch &#123; hosts =&gt; [&quot;https://127.0.0.1:9200&quot;] user =&gt; &quot;elastic&quot; password =&gt; &quot;xxxxxx&quot; cacert =&gt; &quot;/data/elk/elasticsearch-7.11.2/config/certs/elasticsearch-ca.pem&quot; &#125;&#125; Metricbeatmetricbeat-7.11.2/modules.d/elasticsearch-xpack.yml 1234567- module: elasticsearch xpack.enabled: true period: 10s hosts: [&quot;https://127.0.0.1:9200&quot;] username: &quot;elastic&quot; password: &quot;xxxxxx&quot; ssl.certificate_authorities: [&quot;/data/elk/elasticsearch-7.11.2/config/certs/elasticsearch-ca.pem&quot;] 其他Elastic产品使用加密通信略","categories":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/"},{"name":"ELK","slug":"技术/ELK","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/ELK/"}],"tags":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/tags/%E6%8A%80%E6%9C%AF/"},{"name":"ELK","slug":"ELK","permalink":"http://www.lights8080.com/tags/ELK/"}]},{"title":"Elasticsearch-安全特性（Security）","slug":"技术/ELK/Elasticsearch-安全特性（Security）","date":"2021-04-26T16:00:00.000Z","updated":"2021-06-07T01:59:15.000Z","comments":true,"path":"2021/04/27/技术/ELK/Elasticsearch-安全特性（Security）/","link":"","permalink":"http://www.lights8080.com/2021/04/27/%E6%8A%80%E6%9C%AF/ELK/Elasticsearch-%E5%AE%89%E5%85%A8%E7%89%B9%E6%80%A7%EF%BC%88Security%EF%BC%89/","excerpt":"Elasticsearch安全特性，介绍加密通讯的基本原理、开启安全特性的操作步骤、如何生成节点证书、用户认证和相关概念等。 基于7.11版本。","text":"Elasticsearch安全特性，介绍加密通讯的基本原理、开启安全特性的操作步骤、如何生成节点证书、用户认证和相关概念等。 基于7.11版本。 一、安全特性Elastic Stack安全功能使您可以轻松保护集群。 Elasticsearch集群保护方式： 通过密码保护，基于角色的访问控制和IP过滤防止未经授权的访问。 使用SSL/TLS加密保留数据的完整性。 维护审计跟踪，知道谁在对集群进行操作 Elasticsearch配置安全的简易步骤： 集群内每个节点设置为xpack.security.enabled: true 为节点间通信配置TLS/SSL【#加密通讯】 启动Elasticsearch 设置内置用户和密码（命令：elasticsearch-setup-passwords auto） 设置角色和用户，控制对Elasticsearch的访问 (可选)启用审计功能xpack.security.audit.enabled: true，并重启集群 1 加密通讯 未启用加密的群集将以纯文本格式（包括密码）发送所有数据。如果启用了Elasticsearch安全功能，除非您具有试用许可证，否则必须配置SSL/TLS进行节点间通信。 Elasticsearch集群节点间通信使用SSL/TLS加密，保护节点安全有助于降低基于网络的攻击的风险 要求节点使用SSL证书添加到集群时进行身份验证，新节点的身份验证有助于防止流氓节点加入群集并通过复制接收数据 Elasticsearch集群配置STL 为每个Elasticsearch节点生成一个私钥和X.509证书【#1.3 生成节点证书】 在集群中配置每个节点，以使用其签名证书标识自己，并在传输层上启用TLS。还可以选择在HTTP层上启用TLS 配置Kibana以加密浏览器和Kibana服务器之间的通信，并通过HTTPS连接到Elasticsearch 配置其他Elastic产品使用加密通信 1.1 加密集群中节点之间的通信 生成节点证书【#1.3 生成节点证书】 启用TLS并制定访问节点证书所需要的信息1234xpack.security.transport.ssl.enabled: truexpack.security.transport.ssl.verification_mode: certificatexpack.security.transport.ssl.keystore.path: elastic-certificates.p12xpack.security.transport.ssl.truststore.path: elastic-certificates.p12 （可选）如果你用密码保护节点的证书，将密码添加到 Elasticsearch 密钥存储库 重启Elasticsearch 1.2 加密HTTP客户端通信 生成HTTP证书【#1.3 生成节点证书】 启用TLS并制定访问节点证书所需要的信息12xpack.security.http.ssl.enabled: truexpack.security.http.ssl.keystore.path: &quot;http.p12&quot; （可选）如果你用密码保护节点的证书，将密码添加到 Elasticsearch 密钥存储库 重启Elasticsearch 1.3 生成节点证书 （可选）为 Elasticsearch 集群创建一个证书颁发机构。 ./bin/elasticsearch-certutil ca输出文件是一个PKCS#12密钥存储库，其中包含证书颁发机构的公共证书和用于签署节点证书的私钥。 为集群中的每个节点生成证书和私钥交互形式：./bin/elasticsearch-certutil cert --ca elastic-stack-ca.p12命令形式：./bin/elasticsearch-certutil cert --ca elastic-stack-ca.p12 --dns localhost --ip 127.0.0.1,::1 --out config/certs/node-1.p12输出是一个包含节点证书、节点密钥和CA证书的PKCS#12密钥存储库。 （可选）生成专门用于加密 HTTP 客户端通信的附加证书。 ./bin/elasticsearch-certutil http命令步骤如下： 123456789101112131415161718192021222324252627282930## Do you wish to generate a Certificate Signing Request (CSR)? - 是否生成证书签名请求(CSR)?Generate a CSR? [y/N]N## Do you have an existing Certificate Authority (CA) key-pair that you wish to use to sign your certificate? -是否有一个现有的证书颁发机构(CA)密钥对，您希望使用它来签署证书?Use an existing CA? [y/N]y## What is the path to your CA? - 你的CA路径在哪里?CA Path: /data/elk/elasticsearch-7.11.2/elastic-stack-ca.p12## How long should your certificates be valid? - 您的证书应该多长时间有效?For how long should your certificate be valid? [5y] 3Y## Do you wish to generate one certificate per node? - 是否希望每个节点生成一个证书?Generate a certificate per node? [y/N]N## Which hostnames will be used to connect to your nodes? - 哪些主机名将用于连接到您的节点?### Enter all the hostnames that you need, one per line. - 输入需要的所有主机名，每行一个。### When you are done, press &lt;ENTER&gt; once more to move on to the next step. - 完成后，再次按&lt;ENTER&gt;继续下一步。Is this correct [Y/n]Y## Which IP addresses will be used to connect to your nodes? - 哪些IP地址将用于连接到您的节点?### Enter all the IP addresses that you need, one per line.### When you are done, press &lt;ENTER&gt; once more to move on to the next step.Is this correct [Y/n]Y## Other certificate options - 其他证书选项Do you wish to change any of these options? [y/N]N输出是一个.zip 文件，包含 Elasticsearch 和 Kibana 各自的一个目录 输出文件elasticsearch-ssl-http.zip 123456789/elasticsearch|_ README.txt|_ http.p12|_ sample-elasticsearch.yml/kibana|_ README.txt|_ elasticsearch-ca.pem|_ sample-kibana.yml 将节点证书复制到适当的位置 在每个Elasticsearch节点上的配置目录中创建文件夹certs。如：/home/es/config/certs。 在每个节点上，将创建的证书复制到certs目录（通常是一个.p12文件） 如果生成了HTTP证书，复制http.p12到certs目录 配置其他Elastic产品，将证书复制到相关目录 2 用户认证安全功能提供了基于角色的访问控制（RBAC）机制，该机制使您可以通过为角色分配特权并将角色分配给用户或组来授权用户。安全功能还提供了基于属性的访问控制（ABAC）机制，使您可以使用属性来限制对搜索查询和聚合中文档的访问。 role-based access control (RBAC) Secured Resource（访问受限的资源）：索引，别名，文档，字段，用户和Elasticsearch群集本身都是受保护对象。 Privilege（特权）：对受保护的资源执行的一个或多个动作的命名组，如read是索引特权，代表所有启用读取已索引/存储的数据的操作。 Permissions（权限）：针对受保护资源的一组一个或多个特权，权限可以很容易地用语言来描述。 Role（角色）：一组命名的权限 User（用户）：经过身份验证的用户 Group（用户组）：用户所属的一个或多个组 内置用户 这些内置用户存储在指定的.security索引中，由Elasticsearch管理。 elasticsearch-setup-passwords工具是首次设置内置用户密码的最简单方法 基于令牌的身份验证 token-service：访问令牌（根据OAuth2规范生成访问令牌和刷新令牌）是短期令牌，默认情况下20分钟后过期。（Authorization: Bearer xxx） api-key-service：API秘钥，默认情况下API密钥不会过期，创建时，可以指定到期时间和权限。（Authorization: ApiKey xxx） 二、相关概念 SSL（Secure Socket Layer)/TLS(Transport Layer Security） 数字证书：互联网通讯中标志通讯各方身份信息的一系列数据 X.509：是一种数字证书（Public Key Certificates）的格式标准，主要定义了证书中应该包含哪些内容。 HTTPS依赖的TLS/SSL证书使用的就是使用的X.509格式。一个X.509 Certificate包含一个Public Key和一个身份信息（a hostname, or an organization, or an individual），它要么是被CA签发的要么是自签发的。 CA（Certificate Authority）：颁发数字证书的权威机构，承担公钥体系中公钥的合法性检验的责任。 编码格式：用来存储和发送公钥/私钥、证书和其他数据的文件格式；分为DER和PEM DER（Distinguished Encoding Rules）：二进制不可读，常用于Windows系统 PEM（Privacy-Enhanced Mail）：内容是BASE64编码，常用于*NIX系统 PKCS（Public Key Cryptography Standards）：公钥密码学标准 PKCS#12：描述个人信息交换语法标准，通常用来存储Private Keys和Public Key Certificates（例如前面提到的X.509）的文件格式，使用基于密码的对称密钥进行保护。 三、参考文档安全集群加密通讯","categories":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/"},{"name":"ELK","slug":"技术/ELK","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/ELK/"}],"tags":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/tags/%E6%8A%80%E6%9C%AF/"},{"name":"ELK","slug":"ELK","permalink":"http://www.lights8080.com/tags/ELK/"},{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://www.lights8080.com/tags/Elasticsearch/"}]},{"title":"Elasticsearch-聚合（Aggregations）","slug":"技术/ELK/Elasticsearch-聚合（Aggregations）","date":"2021-04-24T16:00:00.000Z","updated":"2021-06-23T09:27:26.000Z","comments":true,"path":"2021/04/25/技术/ELK/Elasticsearch-聚合（Aggregations）/","link":"","permalink":"http://www.lights8080.com/2021/04/25/%E6%8A%80%E6%9C%AF/ELK/Elasticsearch-%E8%81%9A%E5%90%88%EF%BC%88Aggregations%EF%BC%89/","excerpt":"Elasticsearch聚合速查表，介绍指标聚合、桶分聚合、管道聚合的分类和聚合示例。 基于7.11版本。","text":"Elasticsearch聚合速查表，介绍指标聚合、桶分聚合、管道聚合的分类和聚合示例。 基于7.11版本。 聚合将数据汇总为指标, 统计, 或其他分析。 聚合分类 Metric：指标聚合，从文档字段值中计算指标，如总和、平均值等 Bucket：桶分聚合，根据字段值、范围或其他条件将文档分组为桶 Pipeline：管道聚合，从其他的聚合结果作为输入 Bucket Adjacency matrix：邻接矩阵，获取矩阵每个组的计数 Auto-interval date histogram：时间柱状图，根据桶的数量自动的选择桶的间隔 Children：子聚合，如：join field Composite：多存储桶聚合，类似于多字段分组 Date histogram：日期柱状图，可以按日历感知时间间隔（如：day，week，houth）和固定时间间隔。 Date range：时间范围聚合，from：从大于等于某个时间，to：到小于某个时间 Filter：过滤器聚合，将当前的聚合的上下文缩小到一组特定文档。在当前聚合上应用过滤，不影响其他聚合器。 Filters：多桶过滤器聚合，每个桶都与一个过滤器相关联 Geo-distance：地理距离聚合，工作在geo_point字段上，定义一个原点或一组距离范围的桶，评估落在每个桶的文档。 Geo hash grid：网格聚合，每个单元格使用自定义精度的geohash进行标记，geohash可以在1~12之间选择精度 Geotile grid：网格聚合，每个单元格对应许多在线地图的图块，使用{zoom}/{x}/{y}标记 Global：在搜索的上下文中定义一个，不受搜索影响的上下文进行聚合。与Filter对应 Histogram：柱状图聚合，指定间隔，返回落在间隔内的文档数 IP range：IP类型字段的范围聚合 Missing：NULL字段聚合 Nested：嵌套文档聚合 Parent：父文档聚合 Range：范围聚合，定义一组范围，每组范围代表一个桶 Rare terms：稀少（长期分布但不频繁的项）的术语聚合 Reverse nested：在嵌套聚合内定义聚合父文档 Sampler：采样器聚合，将聚合的文档限制在得分最高的文档上，降低繁重缓慢的聚合成本。shard_size：限制在每个分片上使用得分最高的文档数 Diversified sampler：多样化采集聚合，采用多样化的设置进行抽样可以提供一种方法来消除内容偏差 Terms：动态桶聚合。结果是近似值，可以通过size、shard_size来控制其精度。对标关系数据库中的group by。size：定义返回桶的数；shard_size：每个分片使用文档样本数 Significant terms：显著的关键词聚合，通过background sets（背景集合）对比聚合数据。通常使用整个索引库内容当做背景集合，可以通过background_filter设置。 Significant text：显著的文本聚合，像Significant terms一样，区别是作用在text字段 Variable width histogram：动态的宽度柱状图聚合，定义桶数，动态确定桶间隔。 Subtleties of bucketing range fields：范围字段导致桶数大于文档数 Metric Avg：计算平均值，单值的指标聚合，提取文档的数值型字段或提供的脚本。 Min：计算最小值，histogram fields时，返回values中的最小值 Max：计算最大值 Sum：计算总和 Boxplot：盒型图，返回最大值、最小值、25%、50%和75%的值。常用语响应时间的分析 Cardinality：去重求和，计算不同值的近似计数，可以从文档中的特定字段提取值，也可以通过脚本 stats：统计信息，多值的指标聚合，可以从文档中的特定字段提取值，也可以通过脚本 status: min, max, sum, count and avg string stats: count, min_length, max_length, avg_length, entropy extended stats: sum_of_squares, variance, std_deviation geo：地图 geo bounds: 地理边界聚合 geo centroid: 地理重心聚合 Median absolute deviation：中位数绝对偏差，更可靠的统计信息，可以减少异常值对于数据集的影响。 Percentile rank：百分比等级，显示低于特定值的百分比。如：显示web服务加载时间的占比 Percentiles：百分位的值，显示出现百分位观察值的点，percents指定返回的百分位。如：显示大于观察值95%的值 Scripted metric：使用脚本执行获取指标 Value count：去重计数 Weighted avg：带权重的平均值 Pipeline Avg bucket：【sibling pipeline aggs】，计算平均值 max bucket：【sibling pipeline aggs】，计算最大值 min bucket：【sibling pipeline aggs】，计算最小值 sum bucket：【sibling pipeline aggs】，计算总和 bucket script：【parent pipeline aggs】，脚本计算 bucket selector：【parent pipeline aggs】，桶过滤 bucket sort：【parent pipeline aggs】，桶排序 cumulative cardinality：累积基数，此值显示自查询时间段开始以来总的计数，也可显示增量的计数。如：每天网站的新访问者新增数量。 cumulative sum：累积总和，此值显示自查询时间段开始以来累积总和。如：月销售额的累积总和。 derivative：柱状图导数计算 stats bucket：【sibling pipeline aggs】，统计信息，包括min, max, sum, count and avg extended stats bucket：【sibling pipeline aggs】扩展的统计信息，包括平方和、标准差等 inference bucket：【parent pipeline aggs】，训练模型推断 moving average：滑动窗口平均值 moving function：滑动窗口上自定义函数 moving percentiles：基于百分位的滑动窗口 normalize：计算标准的数学值 percentiles bucket：计算桶的百分位的值 serial differencing：时间序列差值 示例1：聚合、分组1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465GET /bank/_search&#123; # 仅返回聚合结果，不需要搜索结果的内容 &quot;size&quot;: 0, &quot;aggs&quot;: &#123; # 单列分组统计，sql: select sum(balance) as sum_balance,avg(balance) as avg_balance from bank group by state.keyword limit 10; &quot;group_by_state&quot;: &#123; # 定义桶的类型 &quot;terms&quot;: &#123; &quot;field&quot;: &quot;state.keyword&quot; &#125;, # 添加自定义Mata信息 &quot;meta&quot;: &#123; &quot;my-metadata-field&quot;: &quot;foo&quot; &#125; # 子聚合 &quot;aggs&quot;: &#123; &quot;avg_balance&quot;: &#123; &quot;avg&quot;: &#123; &quot;field&quot;: &quot;balance&quot; &#125; &#125;, &quot;sum_balance&quot;: &#123; &quot;sum&quot;: &#123; &quot;field&quot;: &quot;balance&quot; &#125; &#125; &#125; &#125;, # 多列分组统计 sql: select sum(balance) as sum_balance from bank group by state.keyword, gender.keyword limit 50; &quot;group_by_fields&quot;: &#123; &quot;composite&quot;:&#123; &quot;sources&quot;: [ &#123; &quot;state&quot;: &#123; &quot;terms&quot;: &#123; &quot;field&quot;: &quot;state.keyword&quot; &#125; &#125; &#125;,&#123; &quot;gender&quot;: &#123; &quot;terms&quot;: &#123; &quot;field&quot;: &quot;gender.keyword&quot; &#125; &#125; &#125; ], # 查询记录数，默认10条 &quot;size&quot;: 50 &#125;, # 子聚合 &quot;aggs&quot;: &#123; &quot;sum_balance&quot;: &#123; &quot;sum&quot;: &#123; &quot;field&quot;: &quot;balance&quot; &#125; &#125; &#125; &#125; &#125; # 聚合后置过滤器，对聚合结果无影响 &quot;post_filter&quot;: &#123; &quot;term&quot;: &#123; &quot;color&quot;: &quot;red&quot; &#125; &#125;&#125; 示例2：条件过滤，多列分组、排序、分页123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566GET /lights-order/_search&#123; &quot;size&quot;: 0, &quot;query&quot;: &#123; &quot;range&quot;: &#123; &quot;gmtCreate&quot;: &#123; &quot;gte&quot;: &quot;2021-05-06 00:00:00&quot;, &quot;lte&quot;: &quot;2021-05-06 23:59:59&quot;, &quot;format&quot;: &quot;yyyy-MM-dd HH:mm:ss&quot;, &quot;time_zone&quot;:&quot;+08:00&quot; &#125; &#125; &#125;, &quot;aggs&quot;: &#123; &quot;group_by_fields&quot;: &#123; &quot;composite&quot;:&#123; &quot;sources&quot;: [ &#123; &quot;cid&quot;: &#123; &quot;terms&quot;: &#123; &quot;field&quot;: &quot;cid&quot; &#125; &#125; &#125;,&#123; &quot;ipcc&quot;: &#123; &quot;terms&quot;: &#123; &quot;field&quot;: &quot;ipcc&quot; &#125; &#125; &#125; ], &quot;size&quot;: 50 &#125;, &quot;aggs&quot;: &#123; &quot;sum_totalAmount&quot;: &#123; &quot;sum&quot;: &#123; &quot;field&quot;: &quot;totalAmount&quot; &#125; &#125;, &quot;order_count&quot;: &#123; &quot;value_count&quot;: &#123; &quot;field&quot;: &quot;id&quot; &#125; &#125;, # 按order_count排序 &quot;sales_bucket_sort&quot;: &#123; &quot;bucket_sort&quot;: &#123; &quot;sort&quot;: [ &#123; &quot;order_count&quot;: &#123; &quot;order&quot;: &quot;asc&quot; &#125; &#125; ], &quot;from&quot;: 0, &quot;size&quot;: 10 &#125; &#125;, # 按doc_count排序 &quot;top_bucket_sort&quot;:&#123; &quot;bucket_sort&quot;: &#123; &quot;sort&quot;: [ &#123; &quot;_count&quot;: &#123; &quot;order&quot;: &quot;desc&quot; &#125; &#125; ] &#125; &#125; &#125; &#125; &#125;&#125;","categories":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/"},{"name":"ELK","slug":"技术/ELK","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/ELK/"}],"tags":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/tags/%E6%8A%80%E6%9C%AF/"},{"name":"ELK","slug":"ELK","permalink":"http://www.lights8080.com/tags/ELK/"},{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://www.lights8080.com/tags/Elasticsearch/"}]},{"title":"语录-3","slug":"语录/语录-3","date":"2021-04-15T16:00:00.000Z","updated":"2021-06-07T02:00:19.000Z","comments":true,"path":"2021/04/16/语录/语录-3/","link":"","permalink":"http://www.lights8080.com/2021/04/16/%E8%AF%AD%E5%BD%95/%E8%AF%AD%E5%BD%95-3/","excerpt":"五只猴子的故事 任正非在一次座谈会上谈加强项目财务的有效管理 眼镜蛇效应 能源效率的诅咒","text":"五只猴子的故事 任正非在一次座谈会上谈加强项目财务的有效管理 眼镜蛇效应 能源效率的诅咒 “ 分享几个小故事，都是从“阮一峰的网络日志”中读到。” 1. 五只猴子的故事科学家在笼子里放了五只猴子。笼子中间有一架梯子，梯子上面放着香蕉。每当一只猴子爬上梯子，科学家就用冷水泼洒其余的猴子。过了一阵子，只要一只猴子爬上梯子，其他猴子就会殴打它。一段时间后，所有猴子都不敢爬上梯子。然后，科学家用一只新猴子，替换了原来的一只猴子，并且停止用冷水泼洒猴子。这只新猴子立即爬楼梯去拿香蕉，但随即遭到其他猴子的殴打。经过几次殴打，新猴子学会了不爬梯子，即使它从来不知道为什么。接着，替换了第二只猴子，也发生了同样的事情。刚才放进笼子的那只猴子，同样殴打了新来的猴子。替换了第三只猴子，也是如此。就这样，第四只、第五只猴子也接连被替换了。最终，笼子里面的五只猴子，尽管从未被泼冷水，仍然继续殴打任何试图爬上梯子的猴子。​ 2. 任正非在一次座谈会上谈加强项目财务的有效管理任正非：我在越南提出一个问题，百年一遇的台风，把爱立信的铁塔吹倒了，诺基亚的铁塔也吹倒了，就我们的铁塔没有倒，我请问你这个财务人员，如何评价？ 杜仲夏：这说明对成本管理并没有做好，这说明项目存在过度交付的问题。就像飞利浦的灯泡，只有两年寿命，用了两年刚好坏掉，这就是最好的产品。如果客户只付了两年灯泡的钱，但是我们保证10年的寿命，只能说明我们不懂经营。 任正非：但是我们当年考市场人员和财务人员的时候，每个人都充满了自豪感，你看，诺基亚和爱立信的铁塔都倒了，就我们没倒，华为的水平多高啊！华为公司的铁塔只有一个标准，在永远不会有台风的沙漠里，装的也是这种铁塔。我们僵化地制定了太高的标准，为此我们每年多浪费了10万到20万吨钢铁。所以，我们今天必须加强项目财务的有效管理，我想三五年后我们一定会看到有结果。 3. 眼镜蛇效应眼镜蛇效应一词来自殖民时期的印度：英国政府计划要减少眼镜蛇的数量，因而颁布法令说每打死一条眼镜蛇都可以领取赏金。然而印度人为了赏金反而开始养殖眼镜蛇。当英国政府意识到这种情况而取消赏金后，养殖蛇的人把蛇都放了；放出去的蛇继而大量繁殖，结果眼镜蛇族群数量不減反增。 4. 能源效率的诅咒我们为了降低能源消耗，发明了节省能源的 LED 照明。结果，更高效的照明导致了更多的照明，从而使得社会整体能源消耗增加。很多事情都是这样，为了省电，我们提高了能源效率，结果人们因此买更多的电器，消耗更多的电。","categories":[{"name":"语录","slug":"语录","permalink":"http://www.lights8080.com/categories/%E8%AF%AD%E5%BD%95/"}],"tags":[{"name":"语录","slug":"语录","permalink":"http://www.lights8080.com/tags/%E8%AF%AD%E5%BD%95/"}]},{"title":"Elasticsearch-搜索（Search-DSL）","slug":"技术/ELK/Elasticsearch-搜索（Search-DSL）","date":"2021-04-07T16:00:00.000Z","updated":"2021-06-07T01:59:03.000Z","comments":true,"path":"2021/04/08/技术/ELK/Elasticsearch-搜索（Search-DSL）/","link":"","permalink":"http://www.lights8080.com/2021/04/08/%E6%8A%80%E6%9C%AF/ELK/Elasticsearch-%E6%90%9C%E7%B4%A2%EF%BC%88Search-DSL%EF%BC%89/","excerpt":"Elasticsearch介绍查询搜索请求包含哪些选项，并介绍其中的Query DSL。包括语法说明、查询和过滤上下文、复合查询等和查询示例。基于7.11版本。","text":"Elasticsearch介绍查询搜索请求包含哪些选项，并介绍其中的Query DSL。包括语法说明、查询和过滤上下文、复合查询等和查询示例。基于7.11版本。 搜索请求是对Elasticsearch数据流或索引中的数据信息的请求，包括以下自定义选项： Query DSL（查询语法） Aggregations（分组聚合） Search multiple data streams and indices（多数据流和索引搜索） Paginate search results（分页查询） Retrieve selected fields（查询指定字段） Sort search results（排序） Run an async search（异步搜索） 本文介绍其中的Query DSL。 查询特定语言（Query DSL - Domain Specific Language）Elasticsearch提供了基于JSON的丰富的查询特定语言来定义查询，包含两种类型的子句组成： Leaf query clauses：页查询。在特定的字段中查找特定值，如match、term和range查询 Compound query clauses：复合查询。包装其他的Leaf和Compound子查询，逻辑组合多个查询（bool、dis_max），或更改其行为（constant_score）。 查询和过滤上下文（Query and filter context）相关性得分（relevance scores）：Elasticsearch按相关性得分对匹配的搜索结果进行排序，该得分衡量每个文档与查询的匹配程度。相关性得分是一个正浮点数，在查询API的_score元数据字段中返回，分值越高，文档越相关。不同的查询类型可以计算不同的相关性得分，计算分数还取决于查询子句是运行在查询上下文还是过滤器上下文中。 查询上下文（Query context）：回答的是文档与该查询子句的匹配程度如何，主要用于计算文档相关性得分。 过滤器上下文（Filter context）：回答的是文档与该查询子句是否匹配，主要用于过滤结构化数据，不计算相关性得分。频繁的使用filter context将会被ES自动缓存，以提升性能。 Compound queries：复合查询 boolean：匹配和过滤，满足条件可以获得更高的得分 boosting：降低文档的得分，而不是排除 constant_score：固定值得分 dis_max：提升多个文档具有相同固定值得分 function_score：根据算法修改查询文档得分 1. boolean query用于匹配和筛选文档。bool查询是采用more-matches-is-better的机制，因此满足must和should子句的文档将获得更高的分值。 must：返回的文档必须满足此查询子句，参与分值计算 filter：返回的文档必须满足此查询子句，不参与分值计算，缓存结果 should：返回的文档可能满足此查询子句，参与分值计算 must_not：该查询子句必须不能出现在匹配的文档中，不参与分值计算，缓存结果 minimum_should_match：指定至少匹配几个should子句，若一个bool查询包含至少一个should子句且无must或filter子句，则默认值为1。 boost：提升权重 2. boosting目的是降低某些文档分值，而不是从结果中排除。 boosting计算相关性得分规则： 从符合positive子句的查询中获得原始的相关性得分 得分 乘上 negative_boost系数，获得最终得分 positive：必填，返回的文档必须匹配此查询。 negative：必填，降低匹配文档的分值。 negative_boost：必填，介于0~1.0之间的数 3. constant_score包装filter query并返回分值，分值等于boost参数。 filter：必填，返回索引文档都必须匹配的查询条件 boost：可选，指定分值，默认为1 4. dis_max用于提升多个字段中包含相同术语的文档分配更高的得分。dis_max计算相关性得分规则： 获得匹配子句中最高得分 其他匹配的子句得分 乘上 tie_treaker系数 将最高得分与其他匹配得分相加，获得最终得分 queries：必填，返回的文档必须匹配一个或多个查询条件，匹配的条件越多则分值越高 tie_breaker：可选，介于0~1.0之间的数，用于增加匹配文档的分值。默认为0 5. function_score允许修改查询文档的相关性得分，通过得分函数（function_score）在过滤后的文档集合上计算，获得最终得分。 query：指定查询条件，默认”match_all”: {} score_mode：计算分值的模式。multiply（默认）、sum、avg、first、max、min boost_mode：计算的分值与查询分值合并模式。multiply（默认）、replace（忽略查询分值）、sum、avg、max、min function_score：计算分值的函数。script_score（函数）、weight（权重）、random_score（0~1随机）、field_value_factor（字段因素） Full text queries：全文检索，查询已分析的文本字段 intervals：根据匹配项的顺序和接近程度返回文档 match：标准的全文查询，模糊匹配和短语接近查询 match_bool_prefix：分析其输入解析构造为bool query，最后一个词在前缀查询中使用 match_phrase：分析其输入解析为短语匹配查询 match_phrase_prefix：分析其输入解析为短语匹配查询，最后一个词在前缀查询中使用 multi_match：多个字段匹配查询 query_string：语法解析器查询 simple_query_string：更简单的语法解析器查询 Geo queries：坐标查询 geo_bounding_box：矩形查询 geo_distance：坐标点范围查询 geo_polygon：多边形查询 geo_shape：包括几何图形查询和指定地理形状相交点查询 Shape queries：像geo_shape一样，支持索引任意二维的几何图形功能Joining queries：连接查询 nested：嵌套类型查询 has_child：匹配子文档的字段，返回父文档。前提是同一索引中建立的父子关系 has_parent：匹配父文档的字段，返回所有子文档。前提是同一索引中建立的父子关系 parent_id：查询指定父文档的所有子文档。 Span queries：区间查询。精准控制多个输入词的先后顺序，已经多个关键词在文档中的前后距离 span_containing：区间列表查询 field_masking_span：允许跨越不同字段查询 span_first：跨度查询，匹配项必须出现在该字段的前N个位置 span_multi：Wraps a term, range, prefix, wildcard, regexp, or fuzzy query. span_near：接受多个跨度查询，顺序相同且指定距离之内 span_not：包装其他span query，排除与该文档匹配的所有文档 span_or：返回任意指定查询匹配的文档 span_term：等同于term query，可以和其他span query一起使用 span_within： Specialized queries：专业的查询 distance_feature：基于时间或坐标查询，越接近原点得分越高 more_like_this：按文本、文档和文档的集合查询 percolate：按存储的指定文档匹配查询 rank_feature：通过定义字段的rank_feature或rank_features属性值提高得分 script：脚本过滤文档 script_score：通过脚本自定义得分 wrapper：接受一个base64字符串查询 pinned：提升特定文档的查询 Term-level queries：术语级查询 exists：返回包含字段的任意文档 fuzzy：返回搜索词的相似词的文档 ids：返回指定ID的文档 prefix：返回字段中指定前缀的文档 range：返回范围内的文档 regexp：返回正则匹配的文档 term：返回字段中包含特定术语的文档 terms：返回字段中包含一个或多个术语的文档 terms_set：返回字段中包含最少数目术语的文档 type：返回指定类型的文档 wildcard：返回通配符匹配文档 查询示例1234567891011121314151617181920212223242526272829303132333435363738394041# 多索引同步搜索GET /my-index-000001,my-index-000002/_search&#123; # 指定查询超时时间 &quot;timeout&quot;: &quot;2s&quot;, # 字段匹配，相当于query context &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must&quot;: [ &#123; &quot;match_all&quot;: &#123;&#125;&#125;, &#123; &quot;match&quot;: &#123; &quot;title&quot;: &quot;Search&quot; &#125;&#125; ], # 相当于filter context &quot;filter&quot;: [ &#123; &quot;term&quot;: &#123; &quot;status&quot;: &quot;published&quot; , &quot;_name&quot; : &quot;status_pub&quot;&#125;&#125;, &#123; &quot;range&quot;: &#123; &quot;publish_date&quot;: &#123; &quot;gte&quot;: &quot;2015-01-01&quot; &#125;&#125;&#125; ] &#125; &#125;, # 排序 &quot;sort&quot;: [ &#123; &quot;account_number&quot;: &quot;asc&quot; &#125;, &#123; &quot;post_date&quot; : &#123;&quot;order&quot; : &quot;asc&quot;&#125;&#125;, &quot;_score&quot; ], # 范围搜索 &quot;range&quot;: &#123; &quot;gmtCreate&quot;: &#123; &quot;gte&quot;: &quot;2020-10-01 00:00:00&quot;, &quot;lte&quot;: &quot;2020-10-31 23:59:59&quot;, &quot;format&quot;: &quot;yyyy-MM-dd HH:mm:ss&quot;, &quot;time_zone&quot;:&quot;+08:00&quot; &#125; &#125; # 查询指定字段 &quot;fields&quot;: [&quot;user.id&quot;, &quot;@timestamp&quot;], &quot;_source&quot;: false # 分页 &quot;from&quot;: 10, &quot;size&quot;: 10&#125;","categories":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/"},{"name":"ELK","slug":"技术/ELK","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/ELK/"}],"tags":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/tags/%E6%8A%80%E6%9C%AF/"},{"name":"ELK","slug":"ELK","permalink":"http://www.lights8080.com/tags/ELK/"},{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://www.lights8080.com/tags/Elasticsearch/"}]},{"title":"Elasticsearch-索引（Index）","slug":"技术/ELK/Elasticsearch-索引（Index）","date":"2021-04-06T16:00:00.000Z","updated":"2021-06-07T01:59:00.000Z","comments":true,"path":"2021/04/07/技术/ELK/Elasticsearch-索引（Index）/","link":"","permalink":"http://www.lights8080.com/2021/04/07/%E6%8A%80%E6%9C%AF/ELK/Elasticsearch-%E7%B4%A2%E5%BC%95%EF%BC%88Index%EF%BC%89/","excerpt":"Elasticsearch索引介绍，包括索引设置、索引模板、索引生命周期管理、翻滚索引、索引别名、滚动索引。 基于7.11版本。","text":"Elasticsearch索引介绍，包括索引设置、索引模板、索引生命周期管理、翻滚索引、索引别名、滚动索引。 基于7.11版本。 索引设置（Index Settings）static只能在创建索引时或关闭的索引上设置 index.number_of_shards：主分片数量，默认1 index.number_of_routing_shards：拆分索引的路由分片数量，默认值位于2~1024之间，依赖索引主分片数量 index.shard.check_on_startup：打开前检查分片是否损坏，默认false index.codec：压缩存储算法，默认LZ4 index.routing_partition_size：自定义路由可以到达的分片数量，默认1 dynamic可以使用API实时对索引进行操作 index.number_of_replicas：主分片的副本数，默认1 index.auto_expand_replicas：根据集群中数据节点的数量自动扩展副本的数量，默认false index.search.idle.after：搜索空闲之前不能接收搜索和获取请求的时间，默认30s index.refresh_interval：刷新操作频率，最近对索引的更改既可见，默认1s。-1关闭刷新操作 index.max_result_window：查询索引结果的最大数量，默认10000 index.max_inner_result_window：内部或聚合命中最大数量，默认100 index.max_rescore_window：打分请求的最大索引数量，默认10000（同index.max_result_window） index.max_docvalue_fields_search：查询中允许的最大字段数，默认100 index.max_script_fields：查询中允许的最大脚本字段数，默认32 index.query.default_field：查询返回的默认字段，默认*（表示所有） 索引模板（Index Templates）索引模板是告诉Elasticsearch在创建索引时如何配置索引的一种方法。对于数据流（data stream），索引模板配置是创建他们的后备索引。在创建索引之前先配置模板，模板设置将用作创建索引的基础。 模板有两种类型，索引模板（index templates）和组件模板（component templates）。 组件模板是可重用的构建块，用于配置映射（mappings）、设置（settings）和别名（alias）。使用组件模板来构造索引模板，但它们不会直接应用于索引。索引模板可以包含组件模板的集合，也可以直接指定设置，映射和别名。如果匹配多个模板，优先使用优先级最高的模板。 可以使用模拟API创建索引，确定最终的索引设置。POST /_index_template/_simulate。 注意事项： 如果新数据流或索引与多个索引模板匹配，则使用优先级最高的索引模板。 Elasticsearch内置了许多索引模板（如：metrics--,logs-*-*），每个模板的优先级是100。如果不想使用内置模板，请为您的模板分配更高的优先级。 如果显式设置创建索引，并且该索引与索引模板匹配，则创建索引请求中的设置将优先于索引模板中指定的设置。 索引模板仅在创建索引期间应用。索引模板的更改不会影响现有索引。 当可组合模板匹配给定索引时，它始终优先于旧模板。如果没有可组合模板匹配，则旧版模板可能仍匹配并被应用。 示例12345678910111213141516171819202122232425262728293031323334353637PUT _template/datastream_template&#123; # 1.1 匹配所有&quot;datastream-&quot;开头的索引 &quot;index_patterns&quot;: [&quot;datastream-*&quot;], # 2 指定创建数据流索引模板 &quot;data_stream&quot;: &#123;&#125;, &quot;settings&quot;: &#123; &quot;number_of_shards&quot;: 1, &quot;number_of_replicas&quot;: 0, &quot;refresh_interval&quot;: &quot;15s&quot;, # 指定索引管理策略，索引关联策略 &quot;index.lifecycle.name&quot;: &quot;datastream_policy&quot;, # 指定滚动写别名 &quot;index.lifecycle.rollover_alias&quot;: &quot;datastream&quot;, # 满足策略的索引检查频率 &quot;indices.lifecycle.poll_interval&quot;: &quot;10m&quot;, # 跳过滚动 &quot;index.lifecycle.indexing_complete&quot;: true &#125;, &quot;mappings&quot;: &#123; &quot;dynamic_date_formats&quot;: [ &quot;yyyy-MM-dd HH:mm:ss&quot;, &quot;yyyy-MM-dd HH:mm:ss Z&quot;, &quot;yyyy-MM-dd HH:mm:ss.SSS&quot;, &quot;yyyy-MM-dd HH:mm:ss.SSS Z&quot; ], &quot;_default_&quot;: &#123; &quot;_all&quot;: &#123; &quot;enabled&quot;: false &#125; &#125; &#125;, # 1.2 非数据流索引是使用 &quot;aliases&quot;: &#123; &quot;last_3_months&quot;: &#123;&#125; &#125;&#125; 索引生命周期管理（Index Lifecycle Manager - ILM）配置索引生命周期管理策略，能够随着时间推移根据性能、弹性和保留要求自动的管理索引。 索引生命周期策略可以触发以下操作： 翻转（Rollover）：当现有索引达到一定分片大小，文档数或使用年限时，为翻转目标创建新索引。翻转目标可以是索引别名或数据流。 收缩（Shrink）：减少索引中主碎片的数量。 强制合并（Force merge）：手动触发合并以减少索引每个分片中的段数，并释放已删除文档所使用的空间。 冻结（Freeze）：将索引设为只读，并最大程度地减少其内存占用量。 删除（Delete）：永久删除索引，包括其所有数据和元数据。 使用ILM可以更轻松地管理热-温-冷体系结构中的索引，在使用时间序列数据时很常见（如日志和指标）。 索引生命周期（Index lifecycle）ILM定义了以下四个阶段（Phases） Hot：频繁的写入和查询 Warm：索引不在更新，仍然在查询 Cold：不再更新的索引，很少查询仍然可以搜索，查询较慢也没关系 Delete：不再需要的索引，可以安全的删除 索引的生命周期策略指定了应用于哪些阶段，每个阶段中执行什么操作，以及何时在两个阶段之间进行转换。 创建索引时可以手动应用生命周期策略。对于时间序列索引，需要将生命周期策略与用于在序列中创建新索引的索引模板相关联。当索引滚动时，不会自动将手动应用的策略应用于新索引。 阶段转换（phase transitions）ILM根据其年龄在整个生命周期中移动索引。要控制这些翻转的时间，请为每个阶段设置一个最小年龄。为了使索引移至下一阶段，当前阶段中的所有操作都必须完成，并且索引必须早于下一阶段的最小年龄。 最小年龄默认为0，这会导致ILM在当前阶段中的所有操作完成后立即将索引移至下一阶段。 如果索引具有未分配的分片并且集群运行状况为黄色，则索引仍可以根据其索引生命周期管理策略过渡到下一阶段。但是，由于Elasticsearch只能在绿色集群上执行某些清理任务，因此可能会有意外的副作用。 阶段执行（phase execution）ILM控制阶段中的动作的执行的顺序，以及哪些步骤是执行每个动作的必要索引操作。 当索引进入阶段后，ILM将阶段定义信息缓存在索引元数据中，这样可以确保索引政策更新不会将索引置于永远不退出阶段的状态。 ILM定期运行，检查索引是否符合策略标准，并执行所需的步骤。为了避免竞争情况，ILM可能需要运行多次执行，完成一项动作所需的所有步骤。这意味着即使indexs.lifecycle.poll_interval设置为10分钟并且索引满足翻转条件，也可能需要20分钟才能完成翻转。 阶段动作（phase actions）参考https://www.elastic.co/guide/en/elasticsearch/reference/7.11/ilm-index-lifecycle.html#ilm-phase-actions 索引生命周期动作（Index Lifecycle Actions） Allocate：将分片移动到具有不同性能特征的节点，并减少副本的数量。 Delete：永久删除索引。 Force merge：减少索引段的数量并清除已删除的文档。将索引设为只读。 Freeze：冻结索引以最大程度地减少其内存占用量。 Migrate：将索引分片移动到对应于当前 ILM 阶段的数据层。 Read only：阻止对索引的写操作。 Rollover：移动索引作为滚动别名的写索引，并开始索引到新索引。 Searchable snapshot：为配置库中的管理索引拍摄快照，并将其作为可搜索快照。 Set priority：降低索引在生命周期中的优先级，以确保首先恢复热索引。 Shrink：通过将索引缩小为新索引来减少主碎片的数量。 Unfollow：将关注者索引转换为常规索引。在Rollover、Shrink和Searchable snapshot操作之前自动执行。 Wait for snapshot：删除索引之前，请确保快照已存在。 ILM更新（Lifecycle policy updates）您可以通过修改当前策略或切换到其他策略的方式来更改管理索引或滚动索引集合的生命周期。 为确保策略更新不会将索引置于无法退出当前阶段的状态，进入这个阶段时，阶段定义会缓存在索引元数据中。如果策略更新可以安全的应用，ILM更新缓冲的阶段定义；如果不能，则使用缓冲阶段定义完成该阶段。 Rollover（翻转）在为日志或指标等时间序列数据编制索引时，不能无限期地写入单个索引。为了满足索引和搜索性能要求并管理资源使用，可以写入索引直到达到某个阈值，然后创建一个新索引并开始写入该索引。 使用滚动索引能够： 优化活跃的索引，以在高性能热节点上获得高接收速率。 针对热节点上的搜索性能进行优化。 将较旧的，访问频率较低的数据转移到价格较低的冷节点上。 根据您的保留政策，通过删除整个索引来删除数据。 我们建议使用数据流来管理时间序列数据。数据流自动跟踪写入索引，同时将配置保持在最低水平。数据流设计用于仅追加数据，其中数据流名称可用作操作（读取，写入，翻转，收缩等）目标。如果您的用例需要就地更新数据，则可以使用索引别名来管理时间序列数据。 自动翻转（automatic rollover）：ILM使您能够根据索引大小，文档数或使用年限自动翻转到新索引。触发翻转后，将创建一个新索引，将写入别名更新为指向新索引，并将所有后续更新写入新索引。与基于时间的过渡相比，基于大小，文档数或使用年限翻转至新索引更可取。在任意时间滚动通常会导致许多小的索引，这可能会对性能和资源使用产生负面影响。 示例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# 查看索引所处哪个阶段、应用策略等GET datastream-*/_ilm/explain# 创建索引管理策略PUT _ilm/policy/full_policy&#123; &quot;policy&quot;: &#123; &quot;phases&quot;: &#123; &quot;hot&quot;: &#123; &quot;actions&quot;: &#123; &quot;rollover&quot;: &#123; &quot;max_age&quot;: &quot;7d&quot;, &quot;max_size&quot;: &quot;50G&quot; &#125; &#125; &#125;, &quot;warm&quot;: &#123; &quot;min_age&quot;: &quot;30d&quot;, &quot;actions&quot;: &#123; &quot;forcemerge&quot;: &#123; &quot;max_num_segments&quot;: 1 &#125;, &quot;shrink&quot;: &#123; &quot;number_of_shards&quot;: 1 &#125;, &quot;allocate&quot;: &#123; &quot;number_of_replicas&quot;: 2 &#125; &#125; &#125;, &quot;cold&quot;: &#123; &quot;min_age&quot;: &quot;60d&quot;, &quot;actions&quot;: &#123; &quot;allocate&quot;: &#123; &quot;require&quot;: &#123; &quot;box_type&quot;: &quot;cold&quot; &#125; &#125; &#125; &#125;, &quot;delete&quot;: &#123; &quot;min_age&quot;: &quot;90d&quot;, &quot;actions&quot;: &#123; &quot;delete&quot;: &#123;&#125; &#125; &#125; &#125; &#125;&#125; 数据流（Data streams）数据流用于跨多个索引存储仅追加的时间序列数据，同时提供一个用于请求的数据流名称。可以将索引和搜索请求直接提交到数据流。流自动将请求路由到存储流数据的索引。同样可以使用索引生命周期管理（ILM）来自动管理这些后备索引。数据流非常适合日志，事件，指标和其他连续生成的数据。 索引别名（index alias）Request body actions：必填，要执行的一组动作 add：添加一个索引别名 remove：删除一个索引别名 remove_index：删除索引 actions on alias objects： index：指定索引名称，允许逗号分隔或通配符 alias：指定别名名称，允许逗号分隔或通配符 filter：使用别名查询时，限制条件 is_write_index：标记作为别名的写索引，一个别名同时只能有一个写索引 routing：指定路由到特定分片 search_routing：搜索路由 index_routing：索引路由 示例12345678910111213141516171819202122232425262728293031PUT /&lt;index&gt;/_alias/&lt;alias&gt;DELETE /&lt;index&gt;/_alias/&lt;alias&gt;GET /_aliasGET /_alias/&lt;alias&gt;GET /&lt;index&gt;/_alias/&lt;alias&gt;POST /_aliases&#123; &quot;actions&quot;: [ &#123; &quot;remove&quot;: &#123; &quot;index&quot;: &quot;test1&quot;, &quot;alias&quot;: &quot;alias1&quot; &#125; &#125;, &#123; &quot;add&quot;: &#123; &quot;index&quot;: &quot;test&quot;, &quot;alias&quot;: &quot;alias1&quot;, &quot;is_write_index&quot;: false &#125; &#125;, &#123; &quot;add&quot;: &#123; &quot;index&quot;: &quot;test2&quot;, &quot;alias&quot;: &quot;alias1&quot;, &quot;is_write_index&quot;: true &#125; &#125; ]&#125; 滚动索引（rollover index）当现有的索引满足您提供的条件（a list of conditions）时，滚动索引API会为滚动目标（rollover target）创建一个新的索引。当滚动目标是别名（alias）时，别名会指向新索引（当指向多个索引时，必须有一个索引设置is_write_index=true）当滚动目标是数据流（data stream）时，新索引会成为数据流的写索引，并生成一个增量 Rollover request12POST /&lt;rollover-target&gt;/_rollover/&lt;target-index&gt;POST /&lt;rollover-target&gt;/_rollover/ 滚动索引接受一个滚动目标（rollover target）和一个条件列表（a list of conditions）。可以使用API撤销太大或太旧的索引。 当满足滚动条件，滚动请求在不同的场景下，滚动操作有所不同： 如果滚动目标是别名指向单个索引时： 创建新索引 别名指向新索引 原始索引中移除别名 如果滚动目标是别名指向多个索引时，必须有一个索引设置is_write_index=true： 创建新索引 设置新索引is_write_index=true 设置原始索引is_write_index=false 如果滚动目标是数据流： 创建新索引 在数据流上添加新索引作为支持索引和写索引 增加数据流的generation属性 Path parameters &lt;rollover-target&gt;：必填，现有的分配给目标索引的索引别名或数据流名称。 &lt;target-index&gt;：可选，用于创建和分配索引别名的目标索引名称。如果&lt;rollover-target&gt;是数据流，则不允许使用此参数。如果&lt;rollover-target&gt;是索引别名，则分配给以”-“和数字结尾的索引名称，如logs-000001。 示例1234567891011121314151617PUT /logs-000001&#123; &quot;aliases&quot;: &#123; &quot;logs_write&quot;: &#123;&#125; &#125;&#125;# Add &gt; 1000 documents to logs-000001POST /logs_write/_rollover&#123; &quot;conditions&quot;: &#123; &quot;max_age&quot;: &quot;7d&quot;, &quot;max_docs&quot;: 1000, &quot;max_size&quot;: &quot;5gb&quot; &#125;&#125;","categories":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/"},{"name":"ELK","slug":"技术/ELK","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/ELK/"}],"tags":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/tags/%E6%8A%80%E6%9C%AF/"},{"name":"ELK","slug":"ELK","permalink":"http://www.lights8080.com/tags/ELK/"},{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://www.lights8080.com/tags/Elasticsearch/"}]},{"title":"Elasticsearch-介绍","slug":"技术/ELK/Elasticsearch-介绍","date":"2021-03-31T16:00:00.000Z","updated":"2021-06-07T07:59:03.000Z","comments":true,"path":"2021/04/01/技术/ELK/Elasticsearch-介绍/","link":"","permalink":"http://www.lights8080.com/2021/04/01/%E6%8A%80%E6%9C%AF/ELK/Elasticsearch-%E4%BB%8B%E7%BB%8D/","excerpt":"Elasticsearch介绍，包括文档与索引、倒排索引、搜索和分析、可伸缩和弹性（节点、分片、跨集群复制）、常用场景。 内容大部分源自官方文档第一节“What is Elasticsearch?” 基于7.11版本。","text":"Elasticsearch介绍，包括文档与索引、倒排索引、搜索和分析、可伸缩和弹性（节点、分片、跨集群复制）、常用场景。 内容大部分源自官方文档第一节“What is Elasticsearch?” 基于7.11版本。 Elasticsearch是一个分布式搜索和分析引擎，为所有类型的数据提供了近实时的搜索和分析。不仅可以进行简单的数据探索，还可以汇总信息来发现数据中的趋势和模式。随着数据和查询量的增长，分布式特性可以使部署顺畅的无缝的增长。 1. 文档和索引文档（Document）Elasticsearch是分布式文档存储，它不会将信息存储为“行-列”数据结构，而是存储为JSON文档的数据结构。当一个集群中有多个节点时，存储的文档分布在集群中，并且可以从任何节点访问。 Elasticsearch使用倒排索引的数据结构，支持非常快速的全文本搜索。一个倒排索引由文档中所有不重复词的列表构成，对于其中每个词，有一个包含它的文档列表。 索引（Index）索引是一个逻辑命名空间，可以看作是文档的优化集合，每个文档都是字段的集合。默认Elasticsearch对每个字段中的所有数据建立索引，并且每个索引字段都具有专用的优化数据结构。如：文本字段存储在倒排索引中，数字、地理字段存储在BKD树中。 Elasticsearch还支持动态映射（dynamic mapping），自动检测并向索引添加新字段。可以定义规则来控制动态映射，也可以显式定义映射以完全控制字段的存储和索引方式。 显式定义映射的意义： 区分全文本字符串字段和精确值字符串字段 执行特定语言的文本分析 优化字段进行部分匹配 自定义日期格式 无法自动检测到的数据类型，如地理信息 为不同的目的以不同的方式对同一字段建立索引通常很有用。 倒排索引（inverted index）倒排索引的结构，适用于快速的全文（Text）搜索。一个倒排索引由文档中所有不重复词的列表构成，对于其中每个词，有一个包含它的文档列表。 倒排索引建立的是分词（Term）和文档（Document）之间的映射关系，在倒排索引中，数据是面向词而不是面向文档的。 Term（词）：精准值，foo、Foo是不相同的词 Text（文本）：非结构化文本，默认文本会被解析为词，这是索引中实际存储的内容 Elasticsearch索引存储结构图： 一个索引包含很多分片，一个分片是一个Lucene索引，它本身就是一个完整的搜索引擎，可以独立执行建立索引和搜索任务。 Lucene索引又由很多分段组成，每个分段都是一个倒排索引。 Elasticsearch每次refresh都会生成一个新的分段，其中包含若干文档的数据。 每个分段（Segment）内部，文档的不同字段被单独建立索引。每个字段的值由若干词（Term）组成。 词（Term）是原文本内容经过分词器处理和语言处理后的最终结果。 2. 搜索和分析搜索（Search）Elasticsearch提供了一个简单，一致的REST API，用于管理集群以及建立索引和搜索数据。REST APIs支持结构化查询、全文本查询和结合了两者的复杂查询。 结构化查询：类似于SQL构建的查询，按索引中搜索字段，然后按字段对匹配项进行排序。 全文本查询：查找到所有与查询字符串匹配的文档，按相关性对它们进行排序。 可以使用Elasticsearch的全面JSON风格的查询语言(Query DSL)访问所有这些搜索功能。还可以构造SQL风格的查询来在Elasticsearch内部本地搜索和聚合数据。 分析（Analyze）聚合使您能够构建数据的复杂摘要，并深入了解关键指标，模式和趋势。聚合利用了用于搜索的相同数据结构，速度很快，可以实时分析和可视化数据。聚合操作和搜索的请求在一起运行，可以在单个请求中同一时间相同的数据进行搜索文档，过滤结果并执行分析。 3. 可伸缩和弹性集群（Cluster）一个Elasticsearch集群由一个或多个节点（Node）组成，每个集群都有一个cluster name作为标识。 集群的三种状态： Green：所有主分片和副本分片都准备就绪。数据不会丢失 Yellow：所有主分片准备就绪，但至少一个主分片对应的副本分片没有就绪。意味着高可用和容灾能力下降 Red：至少有一个主分片没有就绪。此时查询的结果会出现数据丢失 Elasticsearch可以根据需要进行扩展，它天生就实现了分布式。你可以向集群添加节点以增加容量，它会自动将数据和查询负载分布到所有可用节点，不需要大改应用程序。 Elasticsearch索引只是一个或多个物理分片的逻辑分组，其中每个分片实际上是一个独立的的索引。通过将文档分布在索引中的多个分片上，并将这些分片分布在多个节点上，当集群增长(或缩小)时，Elasticsearch自动迁移分片以平衡集群。 节点（Node）节点是属于集群的运行实例，测试时可以一个服务器上启动多个节点，线上通常一个服务器只有一个实例。 启动时，节点将使用单播来发现具有相同集群名称的现有集群，并尝试加入。 候选主节点（Master-eligible Node） 主节点（Master Node） 数据节点（Data Node） 协调节点（Coordinating Node） 热节点（Hot Node） 冷节点（Warm Node） 预处理节点（Ingest Node） 分片（Shard）分片是单个Lucene实例。这是一个低级的工作单元，由ElasticSearch自动管理，在节点发生故障或新增时，可以自动的将分片从一个节点移动到另一个节点。分为主分片（primaries）和副本分片（replicas）两种类型。 主分片：建立索引时默认会有一个主分片，每个文档都属于一个主分片，创建索引后，主分片数量是固定的无法更改。 副本分片：每个主分片可以有零个或多个副本，可以随时更改，副本永远不会和主分片在同一节点上启动。副本提供数据的冗余副本，以防止硬件故障，并增加处理像搜索或检索文档这样的读请求的能力。 跨集群复制（Cross-cluster replication）出于性能原因，群集中的节点必须位于同一网络上，跨不同数据中心中的节点在群集中平衡分片的时间太长了。但是这不符合高可用架构的要求，跨群集复制(CCR)可以解决单个集群重大故障问题。 CCR提供了一种将主集群的索引自动同步到次要远程集群的方法，次要远程集群可以作为热备份。如果主集群失败，次要集群可以接管。您还可以使用CCR创建次要集群，以满足用户在地理位置上接近的读请求。主集群上的索引是Leader，负责所有写请求，复制到次要集群上的索引是只读的Follower。 4. 常用场景 根据关键字查询日志详情 监控系统的运行状况 统计分析，比如接口的调用次数、执行时间、成功率等 异常数据自动触发消息通知 基于日志的数据挖掘 参考看完这篇还不会Elasticsearch，我跪搓衣板！一篇文章带你搞定 ElasticSearch 术语","categories":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/"},{"name":"ELK","slug":"技术/ELK","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/ELK/"}],"tags":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/tags/%E6%8A%80%E6%9C%AF/"},{"name":"ELK","slug":"ELK","permalink":"http://www.lights8080.com/tags/ELK/"},{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://www.lights8080.com/tags/Elasticsearch/"}]},{"title":"Elasticsearch-文本分析（Text Analysis）","slug":"技术/ELK/Elasticsearch-文本分析（Text Analysis）","date":"2021-03-31T16:00:00.000Z","updated":"2021-06-07T01:58:54.000Z","comments":true,"path":"2021/04/01/技术/ELK/Elasticsearch-文本分析（Text Analysis）/","link":"","permalink":"http://www.lights8080.com/2021/04/01/%E6%8A%80%E6%9C%AF/ELK/Elasticsearch-%E6%96%87%E6%9C%AC%E5%88%86%E6%9E%90%EF%BC%88Text%20Analysis%EF%BC%89/","excerpt":"","text":"文本分析使Elasticsearch能够执行全文搜索，其中搜索返回所有相关结果，而不仅仅是精确匹配。文本通过标记化（tokenization）使全文搜索成为可能，将文本分解为标记的更小块。在大多数情况下，这些标记是单个单词。 概念分析器（无论是内置的还是自定义的）只是一个包，其中包含三个较低级别的构建块：字符过滤器（character filters），标记生成器（tokenizers）和标记过滤器（token filters）。 索引和搜索分析器：文本分析发生在两次时间，索引时间（index time）和搜索时间（search time）。大多数情况，应在索引和搜索时使用同一台分析器，这样可以确保将字段的值和查询字符串更改为相同形式的标记。 词干化（Stemming）：词干化是将单词还原为词根形式的过程。这样可以确保在搜索过程中单词匹配的变体。如walking和walked的词根是walk。 标记图（Token graphs）：标记生成器将文本转换为标记流时，还会标记位置（position）和标记跨越的位置数（positionLength）。使用这些，可以为流创建有向无环图，称为标记图。 内置解析器 standard analyzer：标准分析器；按照Unicode编码算法，将文本按照单词边界划分为terms，转为小写，支持删除停用词。 simple analyzer：简易分析器；遇到非字母字时，将文本划分terms，转为小写，支持删除停用词。 whitespace analyzer：空格分析器；遇到任意空格是，将文本划分为terms，不会小写。 stop analyzer：同simple analyzer keyword analyzer：无操作解析器；会将文本作为单个term输出。 pattern analyzer：正则表达式解析器；按照正则表达式，将文本分成多个term，支持小写字母和停用词。 language analyzer：特定语言分析器；如：english custom analyzer：自定义解析器","categories":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/"},{"name":"ELK","slug":"技术/ELK","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/ELK/"}],"tags":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/tags/%E6%8A%80%E6%9C%AF/"},{"name":"ELK","slug":"ELK","permalink":"http://www.lights8080.com/tags/ELK/"},{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://www.lights8080.com/tags/Elasticsearch/"}]},{"title":"Elasticsearch-映射（Mapping）","slug":"技术/ELK/Elasticsearch-映射（Mapping）","date":"2021-03-31T16:00:00.000Z","updated":"2021-06-09T09:32:20.000Z","comments":true,"path":"2021/04/01/技术/ELK/Elasticsearch-映射（Mapping）/","link":"","permalink":"http://www.lights8080.com/2021/04/01/%E6%8A%80%E6%9C%AF/ELK/Elasticsearch-%E6%98%A0%E5%B0%84%EF%BC%88Mapping%EF%BC%89/","excerpt":"Elasticsearch映射介绍，包括动态映射、显式映射、字段数据类型、映射参数、映射限制设置。 内容大纲源自官方文档“Mapping”模块 基于7.11版本。","text":"Elasticsearch映射介绍，包括动态映射、显式映射、字段数据类型、映射参数、映射限制设置。 内容大纲源自官方文档“Mapping”模块 基于7.11版本。 映射（Mapping）是定义文档及其包含的字段如何存储和索引的过程。每个文档都是字段的集合，每个字段都有自己的数据类型。为数据创建一个映射定义，包含与文档相关的字段列表。 动态映射（Dynamic mapping）当Elasticsearch在文档中检测到新字段时，会动态将该字段添加到映射中称为动态映射。 动态字段映射：根据数据类型规则应用于动态添加的字段。支持的数据类型包括：boolean、double、integer、object、array、date。 dynamic：开启动态映射的模式 date_detection：开启日期检测 dynamic_date_formats：检测的日期格式 numeric_detection: true：开启数值检测 动态模板：又称自定义映射，根据匹配条件应用于动态添加的字段。 match_mapping_type: Elasticsearch检测到的数据类型进行操作 match and unmatch: 使用模式来匹配字段名称 path_match and path_unmatch: 使用字段的路径来匹配 显式映射（Explicit mapping）显式映射以完全控制字段的存储和索引方式。 显式映射的意义： 区分全文本字符串字段和精确值字符串字段 执行特定语言的文本分析 优化字段进行部分匹配 自定义日期格式 无法自动检测到的数据类型，如地理信息 字段数据类型（Field data types）常见的类型： binary：二进制编码为Base64字符串 boolean：布尔值 Keywords：关键字，通常用于过滤、排序和聚合。包括keyword、constant_keyword和wildcard。 Numbers：数值类型，包括long、integer、short、byte、double、float Dates：日期类型，包括date和date_nanos alias：为现有字段定义别名 对象和关系类型： object：JSON对象。扁平的键-值对列表 flattened：将整个JSON对象作为单个字段值 nested：保留其子字段之间关系的JSON对象，维护每个对象的独立性 join：为同一索引中的文档定义父/子关系 结构化数据类型： Range：范围，包括long_range, double_range, date_range, and ip_range ip：IPv4和IPv6地址 version：软件版本。特殊的关键字，用于处理软件版本值并支持它们的专用优先级规则 murmur3：计算和存储值的散列。提供了在索引时计算字段值的哈希并将其存储在索引中的功能 聚合数据类型： aggregate_metric_double：度量值进行聚合 histogram：柱状图，以直方图形式聚合数值 文本搜索类型： text：非结构化文本。配置分词器 annotated_text：注解文本。带有映射器注释的文本插件提供了索引文本的功能。如WWW与World Wide Web同义 completion：补全提示。是一个导航功能，引导用户在输入时查看相关结果，提高搜索精度 search_as_you_type：自定义搜索。类似文本的字段，经过优化提供开箱即用的按需输入搜索服务。如搜索框 token_count：符号计数。分词分析后对数量进行索引 文档排名类型： rank_feature：记录一个数字特性，以便在查询中增强文档。 空间数据类型： geo_point：经纬度 geo_shape：复杂的形状，如多边形 元数据： _index：文档所属的索引 _id：文档ID _doc_count：桶聚合（Bucket）返回字段，显示桶中已聚合和分区的文档数 _source：原始JSON文档 _size：_source字段的大小 _routing：自定义路由 _meta：元数据信息 映射参数（Mapping parameters） analyzer：text字段文本解析器 boots：增强匹配权重，默认1.0。如：title的匹配权重大于content匹配权重 coerce：强行类型转换，默认true。如：如string（“10”）强制转换为integer（10） copy_to：将多个字段的值复制到同一字段中。如：first_name和last_name，复制到full_name doc_values：开启字段的排序、聚合和脚本中访问字段，支持除了text和annotated_text的所有字段类型，默认true。本质上是列式存储，保持与原始文档字段相同的值，关闭可节省空间 dynamic：新检测到的字段添加到映射，默认true。false表示不建立索引，strict表示拒绝文档 eager_global_ordinals：全局序号映射。文档中字段的值仅存储序号，而不存原始内容，用于聚合时提高性能 enabled：尝试为字段建立索引，仅可应用于顶级映射和object类型下，默认true。如果禁用整个映射，意味着可以对其进行获取，但是不会以任何方式对它的内容建立索引 format：自定义日期格式 ignore_above：超过长度的字符串内容将不会被索引 ignore_malformed：忽略错误的数据类型插入到索引中。默认抛出异常并丢弃文档 index：控制是否对字段值建立索引，默认true。未索引的字段不可查询 index_options：控制哪些信息添加到倒排索引已进行搜索并突出显示，仅使用于文本字段 index_phrases：将两个词的组合词索引到一个单独的字段中。默认false index_prefixes：为字段值的前缀编制索引，以加快前缀搜索速度 meta：附加到字段的元数据 fields：为不同的目的以不同的方式对同一字段建立索引 norms：用于计算查询的文档分数，默认true。对于仅用于过滤或聚合的字段，不需要对字段进行打分排序时设置为false null_value：使用指定的值替换为null值，以便可以进行索引和搜索 position_increment_gap：当为具有多个值的文本字段建立索引时，将在值之间添加“假”间隙，以防止大多数短语查询在值之间进行匹配，默认值为100 properties：类型映射，object字段和nested字段包含子字段叫properties search_analyzer：查询时使用指定的分析器 similarity：字段打分的相似性算法，默认BM25 store：单独存储属性值。默认对字段值进行索引以使其可搜索，但不单独存储它们，但是已存储在_source字段中 term_vector：存储分析过程的词矢量（Term vectors）信息。包括：词、位置、偏移量、有效载荷 映射限制设置（mapping limit settings）索引中定义太多字段会导致映射爆炸，从而导致内存不足错误和难以恢复的情况。在动态映射中，如果每个新插入的文档都引入新字段，每个新字段都添加到索引映射中，随着映射的增长，这会成为一个问题。使用映射限制设置可以限制（手动或动态创建的）字段映射的数量，并防止文档引起映射爆炸。 index.mapping.total_fields.limit: 字段最大数限制，默认1000 index.mapping.depth.limit: 字段的最大深度，默认20 index.mapping.nested_fields.limit: 单个索引中嵌套类型（nested）最大数限制，默认50 index.mapping.nested_objects.limit: 单个文档中嵌套JSON对象的最大数限制，默认10000 其他object与nested区别如果需要为对象数组建立索引并保持数组中每个对象的独立性，应该使用nested类型而不是object类型。 1234567891011121314PUT my_index/_doc/1&#123; &quot;group&quot; : &quot;fans&quot;, &quot;user&quot; : [ &#123; &quot;first&quot; : &quot;John&quot;, &quot;last&quot; : &quot;Smith&quot; &#125;, &#123; &quot;first&quot; : &quot;Alice&quot;, &quot;last&quot; : &quot;White&quot; &#125; ]&#125; ES内部会转换成这样的对象： 12345&#123; &quot;group&quot; : &quot;fans&quot;, &quot;user.first&quot; : [ &quot;alice&quot;, &quot;john&quot; ], &quot;user.last&quot; : [ &quot;smith&quot;, &quot;white&quot; ]&#125; multi-fields（多字段不同的目的）为了不同的目的，以不同的方式对同一个字段进行索引https://www.elastic.co/guide/en/elasticsearch/reference/7.11/multi-fields.htmlhttps://stackoverflow.com/questions/42383341/full-text-search-as-well-as-terms-search-on-same-filed-of-elasticsearch 12PUT my_index&#123;&quot;mappings&quot;:&#123;&quot;properties&quot;:&#123;&quot;city&quot;:&#123;&quot;type&quot;:&quot;text&quot;,&quot;fields&quot;:&#123;&quot;raw&quot;:&#123;&quot;type&quot;:&quot;keyword&quot;&#125;&#125;&#125;&#125;&#125;&#125; 示例12345678910111213141516171819202122232425262728293031323334353637383940414243444546PUT my_index&#123; &quot;mappings&quot;: &#123; &quot;dynamic_templates&quot;: [ &#123; &quot;strings_as_keywords&quot;: &#123; &quot;match_mapping_type&quot;: &quot;string&quot;, &quot;mapping&quot;: &#123; &quot;type&quot;: &quot;keyword&quot;, &quot;ignore_above&quot;: 1024 &#125; &#125; &#125;, &#123; &quot;unindexed_longs&quot;: &#123; &quot;match_mapping_type&quot;: &quot;long&quot;, &quot;mapping&quot;: &#123; &quot;type&quot;: &quot;long&quot;, &quot;index&quot;: false &#125; &#125; &#125; ], &quot;properties&quot;: &#123; &quot;@timestamp&quot;: &#123; &quot;type&quot;: &quot;date&quot; &#125;, &quot;message&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;index&quot;: false &#125;, &quot;log&quot;: &#123; &quot;properties&quot;: &#123; &quot;file&quot;: &#123; &quot;properties&quot;: &#123; &quot;path&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;index&quot;: false &#125; &#125; &#125; &#125; &#125; &#125; &#125;&#125;","categories":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/"},{"name":"ELK","slug":"技术/ELK","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/ELK/"}],"tags":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/tags/%E6%8A%80%E6%9C%AF/"},{"name":"ELK","slug":"ELK","permalink":"http://www.lights8080.com/tags/ELK/"},{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://www.lights8080.com/tags/Elasticsearch/"}]},{"title":"语录-2","slug":"语录/语录-2","date":"2021-03-24T16:00:00.000Z","updated":"2021-06-07T02:00:37.000Z","comments":true,"path":"2021/03/25/语录/语录-2/","link":"","permalink":"http://www.lights8080.com/2021/03/25/%E8%AF%AD%E5%BD%95/%E8%AF%AD%E5%BD%95-2/","excerpt":"如果你像这样全速开上五分钟，就抵得上某些人碌碌无为的活一辈子 少许的牺牲是必须的 上吊的研究","text":"如果你像这样全速开上五分钟，就抵得上某些人碌碌无为的活一辈子 少许的牺牲是必须的 上吊的研究 1. 如果你像这样全速开上五分钟，就抵得上某些人碌碌无为的活一辈子。《世界上最快的印第安摩托》讲述伯特·孟若的真实故事，为了速度与极限，跨越半个地球前往美国犹他州的盐湖城参加世界机车大赛。他的摩托车甚至没有刹车、没有减速伞、没有灭火器，刷新了当时的世界纪录。此后他又多次刷新世界纪录，最后于1967年创下1000CC以下改装摩托车速度记录，至今无人打破。创纪录时他年近七十。 电影中的语录：活到我这把年纪，在世界上的每一天都是最好的一天。做人如果没有梦想，还不如当颗白菜。荣誉永远都不属于评论家，他们一直在等着别人犯错，然后告诉他们如何改进，荣誉只属于那些真正有行动的人。于我而言，驰骋本身就是回报。这是我这辈子最想做的大事，相比于其他家伙，做的更好，更大的事。很多人都想让我们这些老东西，安安静静的一边等死，但是哥们我告诉你，还不到时候。也许我外表上已经老态龙钟，但我的内心永远都是十八岁，年轻人，我依然可以跟你赛车赌钱。你不知道这对我来说意味着什么，为了今天，我已经等了25年。在追梦者眼里，所爱隔山海，山海皆可平。 解说最后总结的非常好：“””对一些人来说，梦想是人生中可有可无的调味品，如果生活不允许，那就放弃。但对另一部分人来说，梦想就是一辈子的事，是绝对无法妥协的事。所以，有些人是为梦想拼了命，有些人只是为梦想踮了踮脚尖。 我们普通人不是没有梦想，而是没有为梦想孤注一掷的信念，我们会计算得失，计算成本，会计算为梦想付出的代价是否值得，当我们在给梦想做这样的计算时，实际上我们已经做好了随时退缩的准备。“”” 2. 少许的牺牲是必须的奥托·利林塔尔，滑翔机之父，从1891年～1896年，飞行试验次数多达2000次。最后一次飞行过程中因为一股风力，失去控制栽向地面，脊椎骨折，第二天逝世。临终前最后的一句话就是”少许的牺牲是必须的”。 但愿所有的人都能忠于自己，拥有一个梦想，并为之努力奋斗。最终实现不了也没关系，因为你就是被上天选中来凑数的。也但愿梦想也不要像下面这位这么疯狂。 3. 《上吊的研究》尼古拉-米诺维奇。为了更好的研究绞刑，自己进行了十几次的上吊实验，每次做完实验清醒后，做的第一件事就是做记录。最终总结出了200多页的权威报告。","categories":[{"name":"语录","slug":"语录","permalink":"http://www.lights8080.com/categories/%E8%AF%AD%E5%BD%95/"}],"tags":[{"name":"语录","slug":"语录","permalink":"http://www.lights8080.com/tags/%E8%AF%AD%E5%BD%95/"}]},{"title":"Logstash-配置","slug":"技术/ELK/Logstash-配置","date":"2021-03-21T16:00:00.000Z","updated":"2021-06-24T03:10:46.000Z","comments":true,"path":"2021/03/22/技术/ELK/Logstash-配置/","link":"","permalink":"http://www.lights8080.com/2021/03/22/%E6%8A%80%E6%9C%AF/ELK/Logstash-%E9%85%8D%E7%BD%AE/","excerpt":"Logstash配置介绍、插件说明、配置说明、高级配置、命令说明基于7.11版本。https://www.elastic.co/guide/en/logstash/7.11/index.html","text":"Logstash配置介绍、插件说明、配置说明、高级配置、命令说明基于7.11版本。https://www.elastic.co/guide/en/logstash/7.11/index.html 一、配置Logstash配置 Logstash，你需要创建一个配置文件来指定想要使用的插件和每个插件的设置。可以引用配置中的事件字段，并在事件满足某些条件时使用条件来处理它们。运行logstash时使用-f指定配置文件。 每种类型的插件都有一个单独的部分，每个部分都包含一个或多个插件的配置选项。如果指定多个过滤器，则会按照它们在配置文件中出现的顺序进行应用。 logstash-simple.conf 12345678910111213input &#123; stdin &#123; &#125; &#125;filter &#123; grok &#123; match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;COMBINEDAPACHELOG&#125;&quot; &#125; &#125; date &#123; match =&gt; [ &quot;timestamp&quot; , &quot;dd/MMM/yyyy:HH:mm:ss Z&quot; ] &#125;&#125;output &#123; elasticsearch &#123; hosts =&gt; [&quot;localhost:9200&quot;] &#125; stdout &#123; codec =&gt; rubydebug &#125;&#125; 1. 在配置中访问事件数据和字段Logstash中的某些配置选项需要使用事件的字段。因为输入会生成事件，所以输入块中没有要评估的字段，因为它们还不存在。 引用事件数据和字段仅在过滤器和输出块内起作用。基本语法是[fieldname]，引用顶级字段时可以去掉[]，引用嵌套字段时，要指定完成整路径[top-level field][nested field]。 sprintf格式化引用事件字段：increment =&gt; “apache.%{[response][status]}”引用事件日期和类型：path =&gt; “/var/log/%{type}.%{+yyyy.MM.dd.HH}” 条件只想在特定条件下过滤或输出事件，这时可以使用条件。 1234567if EXPRESSION &#123; ...&#125; else if EXPRESSION &#123; ...&#125; else &#123; ...&#125; 比较运算符:equality: ==, !=, &lt;, &gt;, &lt;=, &gt;=regexp: =, ! (checks a pattern on the right against a string value on the left)inclusion: in, not in 布尔运算符:and, or, nand, xor 一元运算符：!（取反） 还可以使用(...)，对表达式进行分组。 @metadata字段一个特殊的字段，在输出时不会成为任何事件的一部分。非常适用于做条件，扩展和构建事件字段等 二、插件说明Input plugins beats file kafka Filter plugins aggregate聚合属于同一任务的多个事件（通常是日志行）中的可用信息，最后将聚合的信息推送到最终任务事件中 clone克隆事件，原始事件保持不变。新事件作为正常的事件插入到管道中，并从生成事件的过滤器开始继续执行。 date解析字段中的日期，然后使用该日期或时间戳作为事件的Logstash的时间戳 Grok filter plugin解析任何文本并将其结构化。适用于文本的结构是逐行变化。%{SYNTAX:SEMANTIC}grok-patternsgrokdebug Dissect filter plugin适用于界定符拆分，不使用正则表达式，而且速度非常快。%{id-&gt;} %{function} %{+ts} %&#123;+ts&#125;：表示前面已经捕获到一个ts字段了，而这次捕获的内容，自动添补到之前ts字段内容的后面 -&gt;：表示忽略它右边的填充 %&#123;+key/2&#125;：表示在有多次捕获内容都填到key字段里的时候，拼接字符串的顺序谁前谁后。/2表示排第2位 %&#123;&#125;：表示是一个空的跳过字段 %&#123;?string&#125;：表示这块只是一个占位，并不会实际生成捕获字段存到事件里面 %&#123;?string&#125; %&#123;&amp;string&#125;：表示当同样捕获名称都是string，但是一个?一个&amp;的时候，表示这是一个键值对 drop删除到达此过滤器的所有内容 elapsed跟踪一对开始/结束事件，并使用它们的时间戳来计算它们之间的经过时间 elasticsearch在Elasticsearch中搜索上一个日志事件，并将其中的某些字段复制到当前事件中 fingerprint创建一个或多个字段的一致哈希（指纹），并将结果存储在新字段中 geoip根据来自Maxmind GeoLite2数据库的数据添加有关IP地址地理位置的信息 http提供了与外部Web服务/ REST API的集成。 java_uuid允许您生成UUID并将其作为字段添加到每个已处理事件 uuiduuid过滤器允许您生成UUID并将其作为字段添加到每个已处理事件。 jdbc_static通过从远程数据库预加载的数据来丰富事件 jdbc_streaming执行SQL查询，并将结果集存储在指定为目标的字段中。它会将结果本地缓存到过期的LRU缓存中 json这是一个JSON解析过滤器。它采用一个包含JSON的现有字段，并将其扩展为Logstash事件内的实际数据结构 kv有助于自动解析foo=bar种类的消息（或特定事件字段） metrics对于汇总指标很有用 mutate可以重命名，删除，替换和修改事件中的字段。需要注意的是，一个mutate块中的命令执行是有序的coerce -&gt; ... -&gt; copy，可以使用多个mutate块控制执行顺序。coerce: 设置空字段的默认值replace: 从事件中的其他部分构件一个新值，替换掉已有字段strip: 删除字段的前后空格update: 用新值更新现有字段，该字段不存在不采取任何操作gsub: 正则表达式匹配，将所有的匹配项更新为替换的字符串，只支持字符串和字符串数组，其他类型不采取任何操作join: 用分隔符连接数组，非数组字段不采取任何操作convert: 将字段的值转换为其他类型，如字符串转整数 prune用于根据字段名称或其值的白名单或黑名单从事件中删除字段（名称和值也可以是正则表达式）。如果使用json/kv过滤器解析出来一些不是事先知道的字段，只想保留其中一部分，这个功能很有用 range用于检查某些字段是否在预期的大小/长度范围内。支持的类型是数字和字符串。当在指定范围内时，执行一个操作。 ruby接受嵌入式Ruby代码或Ruby文件 sleep睡眠一定时间。这将导致logstash在给定的时间内停止运行。这对于速率限制等很有用 throttle节流过滤器用于限制事件数量 translate使用配置的哈希或文件确定替换值的常规搜索和替换工具。当前支持的是YAML，JSON和CSV文件。每个字典项目都是一个键值对 truncate允许您截断长度超过给定长度的字段 urldecode解码经过urlencoded的字段 useragentUserAgent过滤器，添加有关用户代理的信息，例如家族，操作系统，版本和设备 xmlXML过滤器。获取一个包含XML的字段，并将其扩展为实际的数据结构 Output plugins elasticsearch file stdout exec 三、配置说明包括：logstash.yaml、pipelines.yml、jvm.options、log4j2.properties、startup.options logstash.yml Logstash配置选项可以控制Logstash的执行。如：指定管道设置、配置文件位置、日志记录选项等。运行Logstash时，大多数配置可以命令行中指定，并覆盖文件的相关配置。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162node.name: `hostname`path.data: LOGSTASH_HOME/datapath.logs: LOGSTASH_HOME/logs# 指定main pipeline的配置文件路径path.config: # 指定main pipeline的配置数据。语法同配置文件config.string: # 开启后，检查配置是否有效，然后退出config.test_and_exit: false# 开启后，修改配置文件自动加载，过程：暂停管道所有输入；创新新管道并检验配置；检查成功切换到新管道，失败则继续使用老的管道。config.reload.automatic: false# 检查配置文件更新的时间间隔config.reload.interval: 3s# 内部队列模型，memory(default)：内存，persisted：磁盘queue.type: memory# 持久队列的数据文件存储路径（queue.type: persisted时启用）path.queue: path.data/queue# 持久队列的页容量，持久化以页为单位queue.page_capacity: 64mb# 开启后，关闭logstash之前等待持久队列消耗完毕queue.drain: false# 队列中允许的最大事件数，默认0表示无限制queue.max_events: 0# 事件缓冲的内部队列的总容量，达到限制时Logstash将不再接受新事件queue.max_bytes: 1024mb# 强制执行检查点之前的最大ACKed事件数queue.checkpoint.acks: 1024# 强制执行检查点之前，可以写入磁盘的最大事件数queue.checkpoint.writes: 1024# 对每次检查点写入失败将重试一次queue.checkpoint.retry: false# metrics REST endpoint绑定的地址和端口http.host: &quot;127.0.0.1&quot;http.port: 9600# 工作线程IDpipeline.id: main# 控制事件排序，auto：如果`pipeline.workers: 1`开启排序。true：如果有多个工作线程，强制对管道进行排序，并防止Logstash启动。false：禁用排序所需的处理，节省处理成本。pipeline.ordered: auto# 管道筛选和输出阶段的工作线程数，CPU没有饱和可以增加此数字更好的利用机器处理能力。pipeline.workers: `number of cpu cores`# 单个工作线程在发送到filters+workers之前，从输入中获取的最大事件数pipeline.batch.size: 125# 将小批量事件派送到filters+outputs之前，轮询下一个事件等待毫秒时间，可以理解为未到达批处理最大事件数时延迟发送时间pipeline.batch.delay: 50# 开启后，每个pipeline分割为不同的日志，使用pipeline.id作为文件名pipeline.separate_logs: false# 开启后，强行退出可能会导致关机期间丢失数据pipeline.unsafe_shutdown: false# 启用死信队列，默认falsedead_letter_queue.enable: falsedead_letter_queue.max_bytes: 1024mbpath.dead_letter_queue: path.data/dead_letter_queue# 指定自定义插件的位置path.plugins: # 配置模块，遵循yaml结构modules: 四、高级配置1. 多管道配置（multiple pipelines configuration）如果需要在同一个进程中运行多个管道，通过配置pipelines.yml文件来处理，必须放在path.settings文件夹中。并遵循以下结构： 1234567# config/pipelines.yml- pipeline.id: my-pipeline_1 path.config: &quot;/etc/path/to/p1.config&quot; pipeline.workers: 3- pipeline.id: my-other-pipeline path.config: &quot;/etc/different/path/p2.cfg&quot; queue.type: persisted 不带任何参数启动Logstash时，将读取pipelines.yml文件并实例化该文件中指定的所有管道。如果使用-e或-f时，Logstash会忽略pipelines.yml文件并记录相关警告。 如果当前的配置中的事件流不共享相同的输入/过滤器和输出，并且使用标签和条件相互分隔，则使用多个管道特别有用。 在单个实例中具有多个管道还可以使这些事件流具有不同的性能和持久性参数（例如，工作线程数和持久队列的不同设置）。 2. 管道到管道的通信（pipeline-to-pipeline Communication）使用Logstash的多管道功能时，可以在同一Logstash实例中连接多个管道。此配置对于隔离这些管道的执行以及有助于打破复杂管道的逻辑很有用。 3. 重新加载配置文件（Reloading the Config File）如果没有开启自动重新加载（–config.reload.automatic），可以强制Logstash重新加载配置文件并重新启动管道。 1kill -SIGHUP 14175 4. 管理多行事件（Managing Multiline Events）5. Glob模式支持（glob pattern support）注意Logstash不会按照glob表达式中编写的文件顺序执行，是按照字母顺序对其进行排序执行的。 6. Logstash到Logstash通讯（Logstash-to-Logstash Communication）7. Ingest Node解析数据转换到Logstash解析数据（Converting Ingest Node Pipelines）8. 集中配置管理（Centralized Pipeline Management）五、命令说明命令行上设置的所有参数都会覆盖logstash.yml中的相应设置。生产环境建议使用logstash.yml控制Logstash执行。 参数： –node.name NAME：指定Logstash实例的名称，默认当前主机名 -f, –path.config CONFIG_PATH：加载Logstash配置的文件或目录 -e, –config.string CONFIG_STRING：Logstash配置数据，如果未指定输入，则使用input &#123; stdin &#123; type =&gt; stdin &#125; &#125;作为默认的输入，如果未指定输出，则使用output &#123; stdout &#123; codec =&gt; rubydebug &#125; &#125;作为默认的输出。 -M “CONFIG_SETTING=VALUE”：覆盖指定的配置 –config.test_and_exit: 检查配置是否有效，然后退出 –config.reload.automatic: 修改配置文件自动加载 –modules MODULE_NAME：指定运行的模块名称 –setup：是一次性设置步骤，在Elasticsearch中创建索引模式并导入Kibana仪表板和可视化文件。 … 示例： 1bin/logstash -f logstash-simple.conf --config.reload.automatic","categories":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/"},{"name":"ELK","slug":"技术/ELK","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/ELK/"}],"tags":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/tags/%E6%8A%80%E6%9C%AF/"},{"name":"ELK","slug":"ELK","permalink":"http://www.lights8080.com/tags/ELK/"},{"name":"Logstash","slug":"Logstash","permalink":"http://www.lights8080.com/tags/Logstash/"}]},{"title":"Logstash-介绍","slug":"技术/ELK/Logstash-介绍","date":"2021-03-18T16:00:00.000Z","updated":"2021-06-07T01:58:39.000Z","comments":true,"path":"2021/03/19/技术/ELK/Logstash-介绍/","link":"","permalink":"http://www.lights8080.com/2021/03/19/%E6%8A%80%E6%9C%AF/ELK/Logstash-%E4%BB%8B%E7%BB%8D/","excerpt":"本文内容是通过官网学习Logstash的一个总结，阅读本文可以对Logstash有个整体的认识。包括Logstash介绍、如何工作、事件模型、工作原理、弹性数据、持久化队列、性能优化、部署和扩展等基于7.11版本。https://www.elastic.co/guide/en/logstash/7.11/index.html","text":"本文内容是通过官网学习Logstash的一个总结，阅读本文可以对Logstash有个整体的认识。包括Logstash介绍、如何工作、事件模型、工作原理、弹性数据、持久化队列、性能优化、部署和扩展等基于7.11版本。https://www.elastic.co/guide/en/logstash/7.11/index.html 介绍Logstash是具有实时流水线能力的开源的数据收集引擎。Logstash可以动态统一不同来源的数据，并将数据标准化到您选择的目标输出。它提供了大量插件，可帮助我们解析，丰富，转换和缓冲任何类型的数据。 如何工作管道（Logstash Pipeline）是Logstash中独立的运行单元，每个管道都包含两个必须的元素输入（input）和输出（output），和一个可选的元素过滤器（filter），事件处理管道负责协调它们的执行。输入和输出支持编解码器，使您可以在数据进入或退出管道时对其进行编码或解码，而不必使用单独的过滤器。如：json、multiline等 inputs（输入阶段）：会生成事件。包括：file、kafka、beats等 filters（过滤器阶段）：可以将过滤器和条件语句结合使用对事件进行处理。包括：grok、mutate等 outputs（输出阶段）：将事件数据发送到特定的目的地，完成了所以输出处理，改事件就完成了执行。如：elasticsearch、file等 Codecs（解码器）：基本上是流过滤器，作为输入和输出的一部分进行操作，可以轻松地将消息的传输与序列化过程分开。 1. 工作原理Logstash管道中每个输入阶段都运行在自己的线程中，输入将事件写入到内存或磁盘的中央队列。每个管道工作线程（pipeline worker）从队列中获取一批事件，通过配置的过滤器运行这批事件，然后将过滤的事件运行到所有输出。批处理的大小和工作线程数可以通过pipeline.batch.size和pipeline.workers进行配置。 默认Logstash在管道各阶段之间使用内存队列来缓存事件，如果发生意外的终止，则内存中的事件都将丢失。为了防止数据丢失，可以启用Logstash配置queue.type: persisted将正在运行的事件持久保存到磁盘。 2. 事件顺序默认Logstash不保证事件顺序，重新排序可以发送在两个地方： 批处理中的事件可以在过滤器处理期间重新排序 当一个或多个批次的处理速度快于其他批次时，可以对批次重新排序 当维护事件顺序非常重要时，排序设置： 设置pipeline.ordered: auto且设置pipeline.workers: 1，则自动启用排序。 设置pipeline.ordered: true，这种方法可以确保批处理是一个一个的执行，并确保确保事件在批处理中保持其顺序。 设置pipeline.ordered: false则禁用排序处理，但可以节省排序所需的成本。 Logstash 模块Logstash Module提供了一种快速的端到端的解决方案，用于提取数据并使用专用仪表盘对其进行可视化。 每个模块都内置了Logstash配置、Kibana仪表盘和其他元文件。使您可以更轻松地为特定用例或数据源设置Elastic Stack。 为了更轻松的上手，Logstash Module提供了三种基本功能，运行模块时将执行以下步骤： 创建ElasticSearch索引 设置Kibana仪表盘和可视化数据所需要的索引模式，搜索和可视化。 使用配置运行Logstash pipeline 弹性数据当数据流过事件处理管道时，Logstash可能会遇到阻止其事件传递到输出的情况。如：意外的数据类型或异常终止。为了防止数据丢失并确保事件不中断的流过管道，Logstash提供了两种功能。 持久队列（persistent queues） 死信队列（dead letter queues-DLQ） 持久队列默认Logstash在管道阶段（inputs-&gt;pipeline worker）之间使用内存中有边界队列来缓冲事件。这些内存队列的大小是固定的，并且不可配置。如果Logstash遇到暂时的计算机故障，那内存队列中的数据将丢失。 为了防止异常终止期间的数据丢失，Logstash具有持久队列功能，该功能将消息队列存储在磁盘上，提供数据的持久性。持久队列对于需要大缓冲区的Logstash部署也很有用，无需部署和管理消息代理（Kafka、Redis等）以促进缓冲的发布-订阅模型，可以启用持久队列在磁盘上缓冲消息并删除消息代理。 使用queue.max_bytes可配置磁盘上队列的总容量，当队列已满时，Logstash向输入施加压力阻止数据流入，不再接受新事件，这种机制有助于在输入阶段控制数据流速，不会压倒性的到输出。 持久队列的好处： Logstash异常终止或重启启动时避免数据丢失，将消息存储在磁盘上，直到传递至少成功一次。 无需使用Kafka外部缓冲消息代理。应对大缓冲区和吸收突发事件。 无法解决的问题： 永久性机器故障（如磁盘损坏），持久队列无法防止数据丢失。具有确认能力的Beats和http之类的插件，将受到持久队列的良好保护。 不使用请求-响应协议的输入插件（如TCP、UDP），持久队列无法防止数据丢失。 工作原理 队列位于输入和过滤器阶段之间：input → queue → filter + output。 当输入阶段可处理事件时将事件写入队列，成功写入后，输入可以向数据源发送确认（acknowledgement）。 处理队列中的事件时，Logstash仅在过滤器和输出已完全处理该事件时，该事件才记录（队列保留管道已处理的事件记录）为已处理（acknowledged/ACKed）- 这意味着该事件已由所有已配置的过滤器和输出处理。 在正常关闭时，Logstash将停止从队列读取数据，并将完成正在由过滤器和输出处理中的事件。重启后，Logstash将恢复处理持久队列中的事件，并接受来自输入的新事件。 如果Logstash异常终止，任何运行中的事件都不会被记录为ACKed，并且在Logstash重新启动时将被过滤器和输出重新处理。Logstash在批处理事件，当发生异常终止时，可能有一些批处理已经成功完成，但没有记录为 ACKed。 页队列本身就是一个页（page）集合，分为头页（head page）和尾页（tail page），仅有一个头页，达到具体大小（queue.page_capacity）时将变成尾页，并创建一个新的头页。尾页是不可变的，头页是仅追加的。每个页都是一个文件，页中的所有事件确认后，将被删除，如果较旧的页中至少有一个未被确认，整个页将保留在磁盘上，直到成功处理该页上的所有事件为止。 检查点启用持久队列功能后，Logstash通过一种称为检查点（checkpoint）的机制提交到磁盘。检查点文件在单独文件中记录有关自身的详细信息（页信息，确认等）。当记录检查点时，Logstash将调用头页的同步操作和以原子的方式将队列的当前状态写入磁盘。检查点的过程是原子的，意味着如果成功，将保存对文件的任何修改。如果Logstash终止，或者出现硬件级别的故障，则持久队列中缓冲但尚未提交检查点的所有数据都将丢失。可以通过设置queue.checkpoint.writes，强制Logstash更频繁地检查点。为了确保最大的持久性避免丢失数据，可以设置queue.checkpoint.writes为1，在每次事件后强制执行检查点。 死信队列死信队列提供了另一层数据弹性。（当前仅对Elasticsearch输出支持死信队列，用于响应码为400和404的文档，二者均表示无法重试的事件。）默认情况，当Logstash遇到由于数据错误而无法处理事件时，会挂起或删除失败的事件。为了防止数据丢失，可以配置将未成功的事件写入死信队列，而不是丢弃。写入死信队列的每个事件包括原始事件、无法处理的原因、写入事件的插入信息以及事件时间戳。要处理死信队列的事件，需要创建一个管道配置，使用dead_letter_queue插件从死信队列中读取数据。 工作原理 Elasticsearch无法访问的HTTP请求失败，Elasticsearch输出插件将无限期的重试整个请求，这些场景中死信队列不会拦截。 部署和扩展从操作日志和指标分析到企业和应用程序搜索，Elastic Stack可用于大量用例。确保将数据可扩展、持久和安全地传输到Elasticsearch极为重要，尤其是对于关键任务环境。本文重点介绍Logstash的常见体系结构模型，以及如何随着部署的增长而有效的扩展。重点放在操作日志、指标、安全分析用例上，因为它们往往需要大规模部署。 Beats to Elasticsearch使用Filebeat Modules，可以快速的收集、解析和索引流行的日志类型和预建的Kibana仪表盘。这种情况下Beats会将数据直接发送到ES，由摄取节点处理并索引数据。 Beats and Logstash to ElasticsearchBeats和Logstash共同提供了可扩展且具有弹性的全面解决方案。Beats运行在数千台边缘主机服务器上，将日志收集、拖尾和传输到Logstash。Logstash是水平可伸缩的，可以形成运行同一管道的节点组。Logstash的自适应缓冲功能即使在吞吐量变化不定的情况下也有助于流畅的传输。如果Logstash成为瓶颈，只需要添加更多节点即可进行横向扩展。以下是一些建议： 扩展： Beats应该在一组Logstash节点之间实现负载均衡 建议至少使用两个Logstash节点已实现高可用性 通常每个Logstash节点仅部署一个Beats输入，但也可以为每个Logstash节点部署多个Beats输入。 弹性： 使用Filebeat/Winlogbeat进行日志收集时，可以保证至少一次交付 从Filebeat/Winlogbeat到Logstash，以及从Logstash到Elasticsearch这两种通讯协议都是同步且支持确认。其他的Beats不支持。 处理： Logstash通常将使用grok或dissect提取字段，增强地理信息，并可以进一步利用文件、数据库或Elasticsearch查找数据集来丰富事件。 处理复杂性会影响整体吞吐量和CPU利用率，确保检查其他可用的过滤器插件。 Integrating with Messaging Queues如果现有的基础架构中有消息队列，那么将数据放入Elastic Stack会很容易。如果仅使用消息队列用于Logstash缓冲数据，建议使用Logstash持久队列，消除不必要的复杂性。 性能调优包括性能故障排除和调优和分析Logstash性能。 JVM 建议堆的大小应不小于4G且不大于8G，太小会导致JVM不断的进行垃圾回收，造成增加CPU利用率 堆的大小不要超过物理内存量的水平，必须保留一些内存以运行OS和其他进程，一般不要超过物理内存的50-75％。 将最小（Xms）和最大（Xmx）堆分配大小设置为相同的值，以防止在运行时调整堆大小，这是一个非常昂贵的过程。 调优和分析Logstash性能Logstash提供了以下选项来优化管道性能，pipeline.workers，pipeline.batch.size和pipeline.batch.delay。 pipeline.workers此设置确定要运行多少个线程以进行过滤和输出处理。如果发现事件正在备份或者CPU没有饱和可以考虑增加此参数以更好的利用可用的处理能力。 pipeline.batch.size此设置定义单个工作线程在尝试执行过滤器和输出之前收集的最大事件数。较大的批处理大小通常更有效，但会增加内存开销。某些硬件配置要求您增加jvm.options配置文件中的JVM堆空间，以避免性能下降。由于频繁的垃圾收集或与内存不足异常相关的JVM崩溃，超出最佳范围的值会导致性能下降。输出插件可以将每个批次作为逻辑单元进行处理。例如，Elasticsearch输出为收到的每个批次发出批量请求。调整pipeline.batch.size设置可调整发送到Elasticsearch的批量请求的大小。 pipeline.batch.delay很少需要调整。此设置调整Logstash管道的延迟。管道批处理延迟是Logstash在当前管道工作线程中接收到事件后等待新消息的最长时间（以毫秒为单位）。经过这段时间后，Logstash开始执行过滤器和输出。Logstash在接收事件和在过滤器中处理该事件之间等待的最长时间是pipeline.batch.delay和pipeline.batch.size设置的乘积。 管道的配置和优化进行中事件的总数由pipeline.workers和pipeline.batch.size设置的乘积确定。注意在间歇地不规则的接收大型事件的管道，需要足够的内存来处理这些峰值。可以将工作线程数设置高于CPU内核数，因为输出通常度过空闲时间在I/O等待条件下。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/"},{"name":"ELK","slug":"技术/ELK","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/ELK/"}],"tags":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/tags/%E6%8A%80%E6%9C%AF/"},{"name":"ELK","slug":"ELK","permalink":"http://www.lights8080.com/tags/ELK/"},{"name":"Logstash","slug":"Logstash","permalink":"http://www.lights8080.com/tags/Logstash/"}]},{"title":"生产环境的一次JVM调优过程","slug":"技术/JVM/生产环境的一次JVM调优过程","date":"2021-02-04T16:00:00.000Z","updated":"2021-06-08T02:16:02.000Z","comments":true,"path":"2021/02/05/技术/JVM/生产环境的一次JVM调优过程/","link":"","permalink":"http://www.lights8080.com/2021/02/05/%E6%8A%80%E6%9C%AF/JVM/%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E7%9A%84%E4%B8%80%E6%AC%A1JVM%E8%B0%83%E4%BC%98%E8%BF%87%E7%A8%8B/","excerpt":"JVM调优过程。问题背景、分析过程、优化思路","text":"JVM调优过程。问题背景、分析过程、优化思路 问题背景机器负载截图： 进程截图： 启动参数： 1java -jar -Xms2048m -Xmx4096m -Xss256k -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=4096m -XX:NewSize=1920m -XX:MaxNewSize=4096m -XX:SurvivorRatio=6 -XX:+UseParNewGC -XX:ParallelGCThreads=8 -XX:MaxTenuringThreshold=9 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=60 分析过程 服务器内存8G，java进程最大分配内存4G。但进程显示内存使用率27.4，实际使用2.1G。进程内存并没有达到最大分配内存，而CPU却使用率很高。初步分析肯定是Full GC导致CPU使用率高。 查看GC情况 jstat -gcutil 545592 S0：幸存区1当前使用比例S1：幸存区2当前使用比例E：伊甸园区使用比例O：老年代使用比例M：元数据区使用比例CCS：压缩使用比例YGC：年轻代垃圾回收次数FGC：老年代垃圾回收次数FGCT：老年代垃圾回收消耗时间GCT：垃圾回收消耗总时 通过查看GC使用情况，得出年轻代使用比例不高，回收次数少，老年代使用比例高，回收次数过多。 查看Heap信息 jmap -heap 545592 结果显示老年代分片空间：OldSize = 65536 (0.0625MB)新生代分片空间：MaxNewSize = 4294901760 (4095.9375MB)频繁对老年代进行Full GC，引起CPU资源占用高。 优化思路问题的根源很简单，没有真正了解JVM的内存模型以及参数控制，不合理的分配新生代和老年代空间导致。 暂时去掉参数-XX:NewSize、-XX:MaxNewSize，默认NewRatio=2（表示老年代:新生代 = 1:2）。跑一段时间检查新生代和老年代占用情况以增长速度和回收次数等，然后酌情合理配置参数-XX:NewSize、-XX:MaxNewSize。 运行一段时间后观察 jstat -gcutil 3239169 jmap -heap 3239169 结果显示FGC没有再发生，YGC的次数也很低。实际新生代Survivor区只使用了2M，老年代只使用了56M且不再明显增长。所以优化方案是降低老年代和新生代Survivor区空间，增加新生代Eden区空间。 优化策略 修改-Xms1024m -Xmx2048m：降低初始堆空间大小，因为业务访问量并不高，新生代增长速度不快，遵循不浪费资源、压榨服务器原则。 修改-XX:NewSize=896m -XX:MaxNewSize=1536m：结果显示老年代占用并不大，增长也较慢，所以提高新生代的空间有助于减少YGC，但是太大YGC的时长会增加 修改-XX:SurvivorRatio=8：结果显示Survivor区的使用率也不高，进一步提高Eden区大小 修改–XX:CMSInitiatingOccupancyFraction=80，提升老年代占比触发垃圾回收的阈值，降低CMS次数 修改-XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=512m，永久代不占用堆大小，占用率并不高，遵循不浪费原则 调整后的启动参数如下： 1java -jar -Xms1024m -Xmx2048m -Xss256k -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=512m -XX:NewSize=896m -XX:MaxNewSize=1536m -XX:SurvivorRatio=8 -XX:+UseParNewGC -XX:MaxTenuringThreshold=9 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=80","categories":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/"},{"name":"JVM","slug":"技术/JVM","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/JVM/"}],"tags":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/tags/%E6%8A%80%E6%9C%AF/"},{"name":"JVM","slug":"JVM","permalink":"http://www.lights8080.com/tags/JVM/"},{"name":"线上问题处理","slug":"线上问题处理","permalink":"http://www.lights8080.com/tags/%E7%BA%BF%E4%B8%8A%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86/"}]},{"title":"spring cloud gateway [DataBufferLimitException: Exceeded limit on max bytes to buffer : 262144]","slug":"技术/JVM/spring cloud gateway [DataBufferLimitException: Exceeded limit on max bytes to buffer : 262144]","date":"2021-02-03T16:00:00.000Z","updated":"2021-06-08T02:15:53.000Z","comments":true,"path":"2021/02/04/技术/JVM/spring cloud gateway [DataBufferLimitException: Exceeded limit on max bytes to buffer : 262144]/","link":"","permalink":"http://www.lights8080.com/2021/02/04/%E6%8A%80%E6%9C%AF/JVM/spring%20cloud%20gateway%20[DataBufferLimitException:%20Exceeded%20limit%20on%20max%20bytes%20to%20buffer%20:%20262144]/","excerpt":"DataBufferLimitException: Exceeded limit on max bytes to buffer : 262144问题背景、分析过程、解决办法","text":"DataBufferLimitException: Exceeded limit on max bytes to buffer : 262144问题背景、分析过程、解决办法 问题背景线上环境spring cloud gateway偶尔遇到如下异常：DataBufferLimitException: Exceeded limit on max bytes to buffer : 262144 问题的产生原因很容易查到，REST API接口请求数据超过256K，被网关拦截。正常我们加大缓冲区的配置即可，-1表示不限制。但是并没有解决问题，下面介绍我的分析过程和解决办法。 123spring: codec: max-in-memory-size: 1048576 环境信息： Spring Boot 2.2.1.RELEASE 异常信息： 12345678910111213141516171819202021-02-04 15:39:33.014 [reactor-http-epoll-2] ERROR org.springframework.boot.autoconfigure.web.reactive.error.AbstractErrorWebExceptionHandler - [1513c08e-1] 500 Server Error for HTTP POST &quot;/x-service/path&quot;org.springframework.core.io.buffer.DataBufferLimitException: Exceeded limit on max bytes to buffer : 262144 at org.springframework.core.io.buffer.LimitedDataBufferList.raiseLimitException(LimitedDataBufferList.java:101) Suppressed: reactor.core.publisher.FluxOnAssembly$OnAssemblyException:Error has been observed at the following site(s): |_ checkpoint ⇢ org.springframework.cloud.gateway.filter.WeightCalculatorWebFilter [DefaultWebFilterChain] |_ checkpoint ⇢ org.springframework.boot.actuate.metrics.web.reactive.server.MetricsWebFilter [DefaultWebFilterChain] |_ checkpoint ⇢ HTTP POST &quot;/x-service/path&quot; [ExceptionHandlingWebHandler]Stack trace: at org.springframework.core.io.buffer.LimitedDataBufferList.raiseLimitException(LimitedDataBufferList.java:101) at org.springframework.core.io.buffer.LimitedDataBufferList.updateCount(LimitedDataBufferList.java:94) at org.springframework.core.io.buffer.LimitedDataBufferList.add(LimitedDataBufferList.java:59) at reactor.core.publisher.MonoCollect$CollectSubscriber.onNext(MonoCollect.java:124) at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:114) at reactor.core.publisher.FluxPeek$PeekSubscriber.onNext(FluxPeek.java:192) at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:114) at reactor.netty.channel.FluxReceive.onInboundNext(FluxReceive.java:331) at reactor.netty.channel.ChannelOperations.onInboundNext(ChannelOperations.java:352) at reactor.netty.http.server.HttpServerOperations.onInboundNext(HttpServerOperations.java:484)... 分析过程 定位异常触发点org.springframework.core.io.buffer.LimitedDataBufferList.java 查找maxByteCount的设置代码org.springframework.http.codec.support.BaseDefaultCodecs.java 经过调试发现，启动时初始化是正常的，配置此参数有效spring.codec.max-in-memory-size 但业务调用的时候此参数接受值为null，配置并未生效 继续查找调用源头发现，我们的自定义拦截器获取body信息，代码如下 1ServerRequest serverRequest = ServerRequest.create(exchange, HandlerStrategies.withDefaults().messageReaders()); 因为HandlerStrategies.withDefaults()是重新创建的对象，并未使用Spring注入的对象，造成配置不生效 查看gateway的ModifyRequestBodyGatewayFilterFactory，使用注入的messageReaders即可org.springframework.cloud.gateway.filter.factory.rewrite.ModifyRequestBodyGatewayFilterFactory.java 解决办法参考ModifyRequestBodyGatewayFilterFactory调整自定义拦截器，使用注入的配置类。代码如下： 123456789101112131415161718192021222324252627282930313233343536373839@Component@Slf4jpublic class XXXFilter implements GlobalFilter, Ordered &#123; @Autowired ServerCodecConfigurer codecConfigurer; @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) &#123; ServerHttpRequest request = exchange.getRequest(); try &#123; if (request.getHeaders().getContentLength() &gt; 0) &#123; ServerRequest serverRequest = ServerRequest.create(exchange, codecConfigurer.getReaders()); Mono&lt;String&gt; bodyToMono = serverRequest.bodyToMono(String.class); return bodyToMono.flatMap(reqBody -&gt; &#123; if (isJson(reqBody)) &#123; String perms = JSONObject.parseObject(reqBody).getString(&quot;perms&quot;); if (StringUtils.isNotEmpty(perms)) &#123; exchange.getAttributes().put(Constants.XXX_REQUEST_PERMS_ATTR, perms); &#125; &#125; ServerHttpRequestDecorator requestDecorator = new ServerHttpRequestDecorator(exchange.getRequest()) &#123; @Override public Flux&lt;DataBuffer&gt; getBody() &#123; NettyDataBufferFactory nettyDataBufferFactory = new NettyDataBufferFactory(ByteBufAllocator.DEFAULT); DataBuffer bodyDataBuffer = nettyDataBufferFactory.wrap(reqBody.getBytes()); return Flux.just(bodyDataBuffer); &#125; &#125;; return chain.filter(exchange.mutate().request(requestDecorator).build()); &#125;); &#125; return chain.filter(exchange); &#125; catch (Exception e) &#123; log.error(&quot;Exception[XXXFilter]:&quot;, e); return chain.filter(exchange); &#125; &#125;","categories":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/"},{"name":"JVM","slug":"技术/JVM","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/JVM/"}],"tags":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/tags/%E6%8A%80%E6%9C%AF/"},{"name":"JVM","slug":"JVM","permalink":"http://www.lights8080.com/tags/JVM/"},{"name":"线上问题处理","slug":"线上问题处理","permalink":"http://www.lights8080.com/tags/%E7%BA%BF%E4%B8%8A%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86/"}]},{"title":"语录-1","slug":"语录/语录-1","date":"2021-01-30T16:00:00.000Z","updated":"2021-06-07T02:00:42.000Z","comments":true,"path":"2021/01/31/语录/语录-1/","link":"","permalink":"http://www.lights8080.com/2021/01/31/%E8%AF%AD%E5%BD%95/%E8%AF%AD%E5%BD%95-1/","excerpt":"我希望这才是35岁危机的真正原因 正确理解“技术” 如何变强","text":"我希望这才是35岁危机的真正原因 正确理解“技术” 如何变强 1. 我希望这才是35岁危机的真正原因当我35岁时，如果我还奋斗在编码的一线，我希望我被劝退的原因是因为技术能力、业务能力比不过年轻人，而不是因为精力和体力跟不上年轻人。 忘记是从哪里看到的这句话了。最近这一年出现了很多贩卖焦虑的文章，这句话可以说是程序员面对中年危机的正面回击了。 人到中年精力和体力跟不上年轻人这是自然规律，但是技术能力和业务能力比不过年轻人，这只能说明你不是一名优秀的程序员。面对变化，终身成长，持续提升自己的核心竞争力，是每个优秀程序员必须要有的特质。 借鉴这句话，我想给一些年轻程序员该如何涨工资提供一点思路。“我希望你涨薪的原因是因为能力提高了，希望承担更多的责任，而不是因为在同一家公司工作了多少年、加了多少班和我同学都已经拿到多少多少了。” 2. 正确理解“技术”进入职场前的面试环节，由于时间有限，主要还是考察的“技”。当你通过面试，进入职场后，“术”比“技”重要一些。 “技”指的是对代码规范性和设计能力的提高，对组件的掌握程度提高和学习最新的前沿技术等。“术”指的是对业务的深度了解，对问题的理解和分析和对工作认真负责的态度等。 当我认识到“技术是为业务而服务”的时候，才是职场中一大进步。 3. 如何变强你解决的问题越多，你的能力就会越强，你就能解决更多难题，这时候你就已经变强了。– 王岩 我们每个人，每个时候，都是在为自己的简历打工。不管公司能够维持多久，这份简历会一直陪着我们。– 薛兆丰 不想当将军的士兵不是好士兵，但当不好一个士兵的将军，一定不是好将军。– 马云 我最讨厌天天抱怨工作，还不辞职的人。– 马云 在任何行业里，混吃等死的人不被开，都对不起那些努力的人。– 李苦李","categories":[{"name":"语录","slug":"语录","permalink":"http://www.lights8080.com/categories/%E8%AF%AD%E5%BD%95/"}],"tags":[{"name":"语录","slug":"语录","permalink":"http://www.lights8080.com/tags/%E8%AF%AD%E5%BD%95/"}]}],"categories":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/"},{"name":"ELK","slug":"技术/ELK","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/ELK/"},{"name":"JAVA","slug":"技术/JAVA","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/JAVA/"},{"name":"Java","slug":"技术/Java","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/Java/"},{"name":"计算机","slug":"计算机","permalink":"http://www.lights8080.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"},{"name":"Linux","slug":"技术/Linux","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/Linux/"},{"name":"工具","slug":"工具","permalink":"http://www.lights8080.com/categories/%E5%B7%A5%E5%85%B7/"},{"name":"前端","slug":"技术/前端","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/%E5%89%8D%E7%AB%AF/"},{"name":"人体系统","slug":"人体系统","permalink":"http://www.lights8080.com/categories/%E4%BA%BA%E4%BD%93%E7%B3%BB%E7%BB%9F/"},{"name":"SpringCloud","slug":"技术/SpringCloud","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/SpringCloud/"},{"name":"杂谈","slug":"杂谈","permalink":"http://www.lights8080.com/categories/%E6%9D%82%E8%B0%88/"},{"name":"语录","slug":"语录","permalink":"http://www.lights8080.com/categories/%E8%AF%AD%E5%BD%95/"},{"name":"JVM","slug":"技术/JVM","permalink":"http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/JVM/"}],"tags":[{"name":"技术","slug":"技术","permalink":"http://www.lights8080.com/tags/%E6%8A%80%E6%9C%AF/"},{"name":"ELK","slug":"ELK","permalink":"http://www.lights8080.com/tags/ELK/"},{"name":"JAVA","slug":"JAVA","permalink":"http://www.lights8080.com/tags/JAVA/"},{"name":"编程思想","slug":"编程思想","permalink":"http://www.lights8080.com/tags/%E7%BC%96%E7%A8%8B%E6%80%9D%E6%83%B3/"},{"name":"Maven","slug":"Maven","permalink":"http://www.lights8080.com/tags/Maven/"},{"name":"计算机","slug":"计算机","permalink":"http://www.lights8080.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"},{"name":"Linux","slug":"Linux","permalink":"http://www.lights8080.com/tags/Linux/"},{"name":"Mysql","slug":"Mysql","permalink":"http://www.lights8080.com/tags/Mysql/"},{"name":"Python","slug":"Python","permalink":"http://www.lights8080.com/tags/Python/"},{"name":"Hexo","slug":"Hexo","permalink":"http://www.lights8080.com/tags/Hexo/"},{"name":"效率","slug":"效率","permalink":"http://www.lights8080.com/tags/%E6%95%88%E7%8E%87/"},{"name":"个人博客","slug":"个人博客","permalink":"http://www.lights8080.com/tags/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"},{"name":"NodeJs","slug":"NodeJs","permalink":"http://www.lights8080.com/tags/NodeJs/"},{"name":"Nginx","slug":"Nginx","permalink":"http://www.lights8080.com/tags/Nginx/"},{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://www.lights8080.com/tags/Elasticsearch/"},{"name":"李永乐老师","slug":"李永乐老师","permalink":"http://www.lights8080.com/tags/%E6%9D%8E%E6%B0%B8%E4%B9%90%E8%80%81%E5%B8%88/"},{"name":"人体系统","slug":"人体系统","permalink":"http://www.lights8080.com/tags/%E4%BA%BA%E4%BD%93%E7%B3%BB%E7%BB%9F/"},{"name":"线上问题处理","slug":"线上问题处理","permalink":"http://www.lights8080.com/tags/%E7%BA%BF%E4%B8%8A%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://www.lights8080.com/tags/SpringCloud/"},{"name":"杂谈","slug":"杂谈","permalink":"http://www.lights8080.com/tags/%E6%9D%82%E8%B0%88/"},{"name":"美国个人支票","slug":"美国个人支票","permalink":"http://www.lights8080.com/tags/%E7%BE%8E%E5%9B%BD%E4%B8%AA%E4%BA%BA%E6%94%AF%E7%A5%A8/"},{"name":"Filebeat","slug":"Filebeat","permalink":"http://www.lights8080.com/tags/Filebeat/"},{"name":"Kibana","slug":"Kibana","permalink":"http://www.lights8080.com/tags/Kibana/"},{"name":"语录","slug":"语录","permalink":"http://www.lights8080.com/tags/%E8%AF%AD%E5%BD%95/"},{"name":"Logstash","slug":"Logstash","permalink":"http://www.lights8080.com/tags/Logstash/"},{"name":"JVM","slug":"JVM","permalink":"http://www.lights8080.com/tags/JVM/"}]}