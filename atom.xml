<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>七路灯</title>
  
  <subtitle>人的一生应当有许多停靠站，但愿每一个站台都有一盏雾中的灯。</subtitle>
  <link href="http://www.lights8080.com/atom.xml" rel="self"/>
  
  <link href="http://www.lights8080.com/"/>
  <updated>2021-06-02T07:36:15.000Z</updated>
  <id>http://www.lights8080.com/</id>
  
  <author>
    <name>七路灯</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title></title>
    <link href="http://www.lights8080.com/2021/06/02/%E4%BA%BA%E4%BD%93%E7%B3%BB%E7%BB%9F/%E8%9B%8B%E7%99%BD%E8%B4%A8/"/>
    <id>http://www.lights8080.com/2021/06/02/%E4%BA%BA%E4%BD%93%E7%B3%BB%E7%BB%9F/%E8%9B%8B%E7%99%BD%E8%B4%A8/</id>
    <published>2021-06-02T07:36:12.000Z</published>
    <updated>2021-06-02T07:36:15.000Z</updated>
    
    
    
    
    
  </entry>
  
  <entry>
    <title>人体系统-糖</title>
    <link href="http://www.lights8080.com/2021/06/02/%E4%BA%BA%E4%BD%93%E7%B3%BB%E7%BB%9F/%E4%BA%BA%E4%BD%93%E7%B3%BB%E7%BB%9F-%E7%B3%96/"/>
    <id>http://www.lights8080.com/2021/06/02/%E4%BA%BA%E4%BD%93%E7%B3%BB%E7%BB%9F/%E4%BA%BA%E4%BD%93%E7%B3%BB%E7%BB%9F-%E7%B3%96/</id>
    <published>2021-06-01T16:00:00.000Z</published>
    <updated>2021-06-02T10:30:52.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="什么是糖"><a href="#什么是糖" class="headerlink" title="什么是糖"></a>什么是糖</h2><p>糖是一大类化学物质，糖类都是由碳氢氧三种元素构成的，最初观察发现其中氢和氧的比例是2:1，好像就是碳原子和几个水分子构成的，所以把糖类叫碳水化合物。后来发现一些糖中的氢和氧的比例不是2:1，所以把糖类叫碳水化合物不严谨。但是这个名字一直流传下来，平时所说的碳水化合物一般指的就是糖。</p><h2 id="糖的作用"><a href="#糖的作用" class="headerlink" title="糖的作用"></a>糖的作用</h2><p>糖是最主要的能源物质，人体进行各项生命活动所消耗的能量主要来自于糖类的氧化分解。分解速度快，提供能量非常迅速，我们的大脑和生理活动都需要糖。</p><p>人体获得能量：<br>葡萄糖 + 氧气 =&gt; 水 + 二氧化碳 + 能量</p><p>葡萄糖在无氧的情况下<br>葡萄糖 =&gt; 乳酸 + 能量(酸奶)<br>葡萄糖 =&gt; 酒精 + 能量(酒)</p><h2 id="糖的分类"><a href="#糖的分类" class="headerlink" title="糖的分类"></a>糖的分类</h2><p>糖不一定是甜的，甜的也不一定是糖。</p><h4 id="单糖"><a href="#单糖" class="headerlink" title="单糖"></a>单糖</h4><p>单糖是构成各种糖分子的基本单位，不能再水解，可以直接被人体吸收。<br>饮食中主要单糖有葡萄糖、果糖、半乳糖，其中葡萄糖是最重要的单糖。<br>所有含碳水化合物的食物进入血液之前，都要分解转化为葡萄糖，到达肠道后，在转运蛋白的帮助下穿过肠壁，最快地为人体提供能量。</p><ul><li>葡萄糖：经过肠道直接被人体吸收，进入到血液，称为血糖</li><li>果糖（水果、蜂蜜）：不直接被人体吸收，进入肝脏转换为葡萄糖或脂肪，因为其运转机制迟滞，没有葡萄糖进入血液得快，果糖更容易变成脂肪</li><li>半乳糖（牛奶）：不直接被人体吸收，进入肝脏转换为葡萄糖</li></ul><h4 id="二糖-双糖"><a href="#二糖-双糖" class="headerlink" title="二糖/双糖"></a>二糖/双糖</h4><p>两个单糖结合在一起组成了双糖，可以水解成单糖，被人体吸收</p><ul><li>麦芽糖（麦芽）：葡萄糖+葡萄糖</li><li>蔗糖（甘蔗）：葡萄糖+果糖</li><li>乳糖（牛奶）：葡萄糖+半乳糖</li></ul><h4 id="多糖"><a href="#多糖" class="headerlink" title="多糖"></a>多糖</h4><p>多糖相对来讲是复合的碳水化合物，由很多单糖通过糖苷链接在一起形成的聚合物，因此多糖结构非常大，经常有分支和很多分子。多糖不溶于水而且没有甜味。</p><ul><li>淀粉（大米、白面）：由葡萄糖连接而成</li><li>糖原（肝脏、肌肉）：肝脏可以把多余的单糖合成糖原储存在肝脏和肌肉里，当身体需要能量时糖原会迅速分解成葡萄糖。</li><li>脂肪（皮下、内脏）：糖原储存不下，更多的单糖会合成脂肪储存在皮下和内脏</li><li>纤维（木头、棉花、蔬菜）：不能消化的碳水化合物被划归为“脂食纤维”或者“不可用碳水化合物”。作用：有饱腹感、促进肠道蠕动、促进粪便形成</li><li>几丁质（虾壳、蟹壳）：人体不能消化的东西</li></ul><h4 id="代糖-甜味剂"><a href="#代糖-甜味剂" class="headerlink" title="代糖/甜味剂"></a>代糖/甜味剂</h4><p>通过人工化学改造或者合成的具有甜味的化学物质。特点是甜度非常高，几乎没有热量，也不具有任何营养价值。</p><ul><li>阿斯巴甜：甜度是等量蔗糖的200倍</li><li>三氯蔗糖：甜度是等量蔗糖的600倍</li></ul><h2 id="葡萄糖的旅程"><a href="#葡萄糖的旅程" class="headerlink" title="葡萄糖的旅程"></a>葡萄糖的旅程</h2><p>食物中的碳水化合物通过分解转换为单糖，其中葡萄糖经过肠壁吸收直接进入血液（此时叫血糖），果糖和半乳糖经过吸收进入到肝脏，被转换为葡萄糖、糖原或脂肪。</p><p>葡萄糖 ==&gt; 糖原/脂肪：胰岛素<br>葡萄糖 &lt;== 糖原/脂肪：胰高血糖素</p><p><img src="https://gitee.com/lights8080/lights8080-oss/raw/master/2021/06/PGbDKQ.png"></p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://www.zhihu.com/question/20714926/answer/73370674">碳水化合物和糖有什么区别？</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;什么是糖&quot;&gt;&lt;a href=&quot;#什么是糖&quot; class=&quot;headerlink&quot; title=&quot;什么是糖&quot;&gt;&lt;/a&gt;什么是糖&lt;/h2&gt;&lt;p&gt;糖是一大类化学物质，糖类都是由碳氢氧三种元素构成的，最初观察发现其中氢和氧的比例是2:1，好像就是碳原子和几个水分子构成的，</summary>
      
    
    
    
    <category term="人体系统" scheme="http://www.lights8080.com/categories/%E4%BA%BA%E4%BD%93%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="李永乐老师" scheme="http://www.lights8080.com/tags/%E6%9D%8E%E6%B0%B8%E4%B9%90%E8%80%81%E5%B8%88/"/>
    
    <category term="人体系统" scheme="http://www.lights8080.com/tags/%E4%BA%BA%E4%BD%93%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>Linux [buff/cache]内存缓存占用过高分析和优化</title>
    <link href="http://www.lights8080.com/2021/05/19/%E6%8A%80%E6%9C%AF/Linux/Linux%20[buffcache]%E5%86%85%E5%AD%98%E7%BC%93%E5%AD%98%E5%8D%A0%E7%94%A8%E8%BF%87%E9%AB%98%E5%88%86%E6%9E%90%E5%92%8C%E4%BC%98%E5%8C%96/"/>
    <id>http://www.lights8080.com/2021/05/19/%E6%8A%80%E6%9C%AF/Linux/Linux%20[buffcache]%E5%86%85%E5%AD%98%E7%BC%93%E5%AD%98%E5%8D%A0%E7%94%A8%E8%BF%87%E9%AB%98%E5%88%86%E6%9E%90%E5%92%8C%E4%BC%98%E5%8C%96/</id>
    <published>2021-05-18T16:00:00.000Z</published>
    <updated>2021-06-01T10:47:46.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="问题现场"><a href="#问题现场" class="headerlink" title="问题现场"></a>问题现场</h2><p>查看系统内存的使用状态<br><img src="https://gitee.com/lights8080/lights8080-oss/raw/master/2021/05/linux-buff-free.jpg"></p><p>监控报警可用内存空间不足，常规的解决方案如下：</p><ol><li>增加内存（增加成本）</li><li>增加虚拟内存（影响性能）</li><li>定期清理缓存（echo 1 &gt; /proc/sys/vm/drop_caches）</li></ol><p>本文将介绍定期清除页面缓存，但是过会儿内存又被占满问题的分析。</p><h2 id="问题分析"><a href="#问题分析" class="headerlink" title="问题分析"></a>问题分析</h2><ol><li><p>通过监控系统负载情况（vmstat 1），确定是页面缓存（cache项）占用量大，并且释放页面缓存后从块设备读入数据量（bi项）会马上增加。<br><img src="https://gitee.com/lights8080/lights8080-oss/raw/master/2021/05/linux-buff-vmstat.jpg"></p></li><li><p>通过监控io情况（iostat -x -k 1）也可以看出<br><img src="https://gitee.com/lights8080/lights8080-oss/raw/master/2021/05/linux-buff-iostat.jpg"></p></li><li><p>基于此可以猜测是有进程在频繁的读取文件导致，监视磁盘I/O使用状况（iotop -oP），释放页面缓存后有几个sed命令读取文件进程占用IO很高。<br><img src="https://gitee.com/lights8080/lights8080-oss/raw/master/2021/05/linux-buff-iotop.jpg"></p></li><li><p>至此结合业务分析是因为每分钟读取日志统计指标导致</p></li></ol><h2 id="扩展知识"><a href="#扩展知识" class="headerlink" title="扩展知识"></a>扩展知识</h2><h3 id="proc-meminfo"><a href="#proc-meminfo" class="headerlink" title="/proc/meminfo"></a>/proc/meminfo</h3><p>查看更详细的内存信息：<br><code>$ cat /proc/meminfo |grep -E &quot;Buffer|Cache|Swap|Mem|Shmem|Slab|SReclaimable|SUnreclaim&quot;</code><br><img src="https://gitee.com/lights8080/lights8080-oss/raw/master/2021/05/linux-buff-meminfo.jpg"></p><ul><li>MemFree：空闲的物理内存</li><li>MemAvailable：可用的物理内存，MemFree+Buffers+Cached</li><li>Buffers：（Buffer Cache）对磁盘块设备数据的缓存</li><li>Cached：（Page Cache）对文件系统上文件数据的缓存，MemFree+SReclaimable</li><li>SwapTotal：虚拟内存，利用磁盘空间虚拟出的一块逻辑内存</li><li>Slab：Linux内存管理机制</li><li>SReclaimable：Slab可回收部分</li><li>SUnreclaim：Slab不可回收部分</li><li>Shmem：进程间共同使用的共享内存</li></ul><h3 id="proc-sys-vm-drop-caches"><a href="#proc-sys-vm-drop-caches" class="headerlink" title="/proc/sys/vm/drop_caches"></a>/proc/sys/vm/drop_caches</h3><p>清除缓存策略：<br>1：清除page cache<br>2：清除slab分配器中的对象（包括目录项和inode）<br>3：清除page cache和slab分配器中的对象</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://lights8080.github.io/post/oom-killer-ji-overcommit/">OOM killer及Overcommit</a><br><a href="https://blog.csdn.net/kunyus/article/details/104617426">Linux buffer/cache 内存占用过高的原因以及解决办法</a><br><a href="https://blog.csdn.net/linxi7/article/details/109078516">Linux查看Buffer&amp;Cache被哪些进程占用</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;问题现场&quot;&gt;&lt;a href=&quot;#问题现场&quot; class=&quot;headerlink&quot; title=&quot;问题现场&quot;&gt;&lt;/a&gt;问题现场&lt;/h2&gt;&lt;p&gt;查看系统内存的使用状态&lt;br&gt;&lt;img src=&quot;https://gitee.com/lights8080/lights80</summary>
      
    
    
    
    <category term="技术" scheme="http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="Linux" scheme="http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/Linux/"/>
    
    
    <category term="技术" scheme="http://www.lights8080.com/tags/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="Linux" scheme="http://www.lights8080.com/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>OOM killer及Overcommit</title>
    <link href="http://www.lights8080.com/2021/05/19/%E6%8A%80%E6%9C%AF/Linux/OOM%20killer%E5%8F%8AOvercommit/"/>
    <id>http://www.lights8080.com/2021/05/19/%E6%8A%80%E6%9C%AF/Linux/OOM%20killer%E5%8F%8AOvercommit/</id>
    <published>2021-05-18T16:00:00.000Z</published>
    <updated>2021-06-01T10:47:46.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="OOM-killer"><a href="#OOM-killer" class="headerlink" title="OOM killer"></a>OOM killer</h2><p>OOM killer(Out Of Memory killer)是Linux内核的一种内存管理机制，该机制在系统物理内存不足时，选择性（oom_killer遍历当前所有进程，根据进程的内存使用情况进行打分，然后从中选择一个分数最高的进程）杀死一些进程以释放内存，以使系统继续运行。</p><h3 id="Overcommit（过量使用）"><a href="#Overcommit（过量使用）" class="headerlink" title="Overcommit（过量使用）"></a>Overcommit（过量使用）</h3><p>这个特性出于优化系统考虑，因为进程实际使用到的内存往往比申请的内存少。</p><p>按照Linux的算法，物理内存页的分配发生在使用瞬间，而不是在申请瞬间。Overcommit针对的也是内存申请，而不是内存分配。</p><p>Linux下允许程序申请比系统可用内存更多的内存。因为不是所有的程序申请了内存就立刻使用的，当实际使用时超过可分配物理内存时，利用OOM机制选择性杀死一些进程以释放内存。</p><h3 id="参数调优"><a href="#参数调优" class="headerlink" title="参数调优"></a>参数调优</h3><p>vm.overcommit_memory</p><ul><li>0：OVERCOMMIT_GUESS（默认），内核将检查是否有足够的可用内存供应用进程使用</li><li>1：OVERCOMMIT_ALWAYS，允许超过CommitLimit的分配，即允许分配所有的物理内存，而不管当前的内存状态如何</li><li>2：OVERCOMMIT_NEVER，拒绝超过CommitLimit的分配，即拒绝等于或者大于CommitLimit指定的物理 RAM 比例的内存请求</li></ul><p>CommitLimit 和 Commited_AS</p><ul><li>CommitLimit：最大能分配的内存<ul><li>计算公式：(Physical RAM * vm.overcommit_ratio / 100) + Swap</li></ul></li><li>Committed_AS：当前已经分配的内存</li></ul><h3 id="OVERCOMMIT策略的可用内存判定"><a href="#OVERCOMMIT策略的可用内存判定" class="headerlink" title="OVERCOMMIT策略的可用内存判定"></a>OVERCOMMIT策略的可用内存判定</h3><ul><li>OVERCOMMIT_GUESS：判定可用内存 = free + buff/cache - share + Swap + SLAB已标记可回收的内存 - 系统运行预留的内存 - 管理员操作预留内存</li><li>OVERCOMMIT_ALWAYS：直接返回成功</li><li>OVERCOMMIT_NEVER：判断Committed_AS &lt; CommitLimit</li></ul><h2 id="相关命令"><a href="#相关命令" class="headerlink" title="相关命令"></a>相关命令</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 查看overcommit策略</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> cat /proc/sys/vm/overcommit_memory</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看进程OOM得分，oom_killer将首先杀死得分最高的进程</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> cat /proc/&lt;pid&gt;/oom_score</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看CommitLimit和Committed_AS</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> cat /proc/meminfo |grep -i commit</span></span><br></pre></td></tr></table></figure><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><a href="https://blog.csdn.net/run_for_belief/article/details/83446344">Linux OOM killer机制介绍</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;OOM-killer&quot;&gt;&lt;a href=&quot;#OOM-killer&quot; class=&quot;headerlink&quot; title=&quot;OOM killer&quot;&gt;&lt;/a&gt;OOM killer&lt;/h2&gt;&lt;p&gt;OOM killer(Out Of Memory killer)是Linux</summary>
      
    
    
    
    <category term="技术" scheme="http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="Linux" scheme="http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/Linux/"/>
    
    
    <category term="技术" scheme="http://www.lights8080.com/tags/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="Linux" scheme="http://www.lights8080.com/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>Spring Cloud Gateway与后端服务问题处理总结</title>
    <link href="http://www.lights8080.com/2021/05/19/%E6%8A%80%E6%9C%AF/SpringCloud/Spring%20Cloud%20Gateway%E4%B8%8E%E5%90%8E%E7%AB%AF%E6%9C%8D%E5%8A%A1%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E6%80%BB%E7%BB%93/"/>
    <id>http://www.lights8080.com/2021/05/19/%E6%8A%80%E6%9C%AF/SpringCloud/Spring%20Cloud%20Gateway%E4%B8%8E%E5%90%8E%E7%AB%AF%E6%9C%8D%E5%8A%A1%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E6%80%BB%E7%BB%93/</id>
    <published>2021-05-18T16:00:00.000Z</published>
    <updated>2021-06-01T10:47:46.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="问题1（Connection-prematurely-closed-BEFORE-response）"><a href="#问题1（Connection-prematurely-closed-BEFORE-response）" class="headerlink" title="问题1（Connection prematurely closed BEFORE response）"></a>问题1（Connection prematurely closed BEFORE response）</h2><p>后端服务偶尔报错Connection prematurely closed BEFORE response。</p><p>这个问题的产生原因和解决办法网上很容易找到。我这里只贴出问题原理图和解决办法。<br>详细说明请参考<a href="https://javazhiyin.blog.csdn.net/article/details/112914264">https://javazhiyin.blog.csdn.net/article/details/112914264</a></p><p><strong>原理图</strong><br><img src="https://img-blog.csdnimg.cn/img_convert/87a7537eb4e30ab56e3f8a3d594ef544.png" alt="file"></p><p><strong>解决办法</strong></p><ol><li><p>spring cloud gateway增加jvm启动参数<br>后进先出策略，确保获取的连接最大概率是最近刚被用过的</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-Dreactor.netty.pool.leasingStrategy=lifo</span><br></pre></td></tr></table></figure></li><li><p>后端服务配置<br>后端服务连接超时时长改为10秒（默认20s），超时没有数据交互则关闭连接。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">server:</span></span><br><span class="line">  <span class="attr">tomcat:</span></span><br><span class="line">    <span class="attr">connection-timeout:</span> <span class="number">10000</span></span><br></pre></td></tr></table></figure></li><li><p>spring cloud gateway增加配置<br>设置连接的最大空闲时长为5秒（默认NULL：响应完成即可关闭），超时则关闭连接释放资源。<br>这个时长的设置要小于后端服务的连接超时时长，确保网关回收请求在后端服务回收请求之前完成。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line">  <span class="attr">cloud:</span></span><br><span class="line">    <span class="attr">gateway:</span></span><br><span class="line">      <span class="attr">httpclient:</span></span><br><span class="line">        <span class="attr">pool:</span></span><br><span class="line">          <span class="attr">max-idle-time:</span> <span class="number">5000</span></span><br></pre></td></tr></table></figure></li></ol><h2 id="问题2（浪涌导致网关报错分析）"><a href="#问题2（浪涌导致网关报错分析）" class="headerlink" title="问题2（浪涌导致网关报错分析）"></a>问题2（浪涌导致网关报错分析）</h2><blockquote><p>每天不定时出现响应失败，Nginx响应状态码出现大量的500和504，网关同样出现大量的500和504，后端服务正常。</p></blockquote><p>Nginx、Gateway、Service每小时统计数如下，其中Nginx，0点的数比较少是因为日志文件截取导致缺失<br><img src="https://img-blog.csdnimg.cn/img_convert/40470233cb556053f82cb6e3c6d1e615.png" alt="file"></p><ul><li>经过分析得到，2点是正常情况，Nginx-&gt;Gateway-&gt;Service数都对的上。</li><li>1点的数据显示Service收到的请求数减少，响应时间也正常，Gateway报错分为504：Gateway响应时间超过导致（配置的60s），500：Gateway连接超过导致（配置的3s），说明Gateway请求并未到达Service端。</li><li>查看Nginx和Gateway的连接数出现了激增，因为外部流量瞬间涌入导致服务器连接数资源被占用。<br><img src="https://img-blog.csdnimg.cn/img_convert/3bf64c40fde06be1e9c1f35e1d35e6f7.png" alt="file"><br><img src="https://img-blog.csdnimg.cn/img_convert/c0ae71367df1d41a1da2d5dd6626d3c2.png" alt="file"></li></ul><p><strong>优化方案</strong></p><ol><li><p>开启Gateway限流策略</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line">  <span class="attr">cloud:</span></span><br><span class="line">    <span class="attr">gateway:</span></span><br><span class="line">      <span class="attr">default-filters:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">RequestRateLimiter</span></span><br><span class="line">          <span class="attr">args:</span></span><br><span class="line">            <span class="attr">redis-rate-limiter.replenishRate:</span> <span class="number">200</span></span><br><span class="line">            <span class="attr">redis-rate-limiter.burstCapacity:</span> <span class="number">50</span></span><br><span class="line">            <span class="attr">redis-rate-limiter.requestedTokens:</span> <span class="number">1</span></span><br><span class="line">            <span class="attr">key-resolver:</span> <span class="string">&quot;#&#123;@userKeyResolver&#125;&quot;</span></span><br><span class="line">            <span class="attr">deny-empty-key:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure></li><li><p>Gateway请求Service超时配置的60s，根据业务需要超过10s响应都视作无效，所以配置响应超时时间为10秒</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line">  <span class="attr">cloud:</span></span><br><span class="line">    <span class="attr">gateway:</span></span><br><span class="line">      <span class="attr">httpclient:</span></span><br><span class="line">        <span class="attr">pool:</span></span><br><span class="line">          <span class="attr">response-timeout:</span> <span class="string">10s</span></span><br></pre></td></tr></table></figure></li><li><p>Gateway的连接池使用弹性方式，导致服务器连接数资源被占满，改为固定方式。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line">  <span class="attr">cloud:</span></span><br><span class="line">    <span class="attr">gateway:</span></span><br><span class="line">      <span class="attr">httpclient:</span></span><br><span class="line">        <span class="attr">pool:</span></span><br><span class="line">          <span class="comment"># 线程池类型，ELASTIC：弹性，FIXED：固定</span></span><br><span class="line">          <span class="attr">type:</span> <span class="string">FIXED</span></span><br><span class="line">          <span class="comment"># 超过此时间连接不使用就关闭</span></span><br><span class="line">          <span class="attr">max-idle-time:</span> <span class="number">5000</span></span><br><span class="line">          <span class="comment"># 线程池最大连接数，type=FIXED时有效</span></span><br><span class="line">          <span class="attr">max-connections:</span> <span class="number">200</span></span><br><span class="line">          <span class="comment"># 从线程池获取线程的最大等待时间，type=FIXED时有效</span></span><br><span class="line">          <span class="attr">acquire-timeout:</span> <span class="number">45000</span></span><br></pre></td></tr></table></figure></li><li><p>由于Gateway到不同的Service，响应时间不一样，可以在Service端的元数据信息中修改连接超时时间和响应超时时间</p></li></ol><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line">  <span class="attr">cloud:</span></span><br><span class="line">    <span class="attr">nacos:</span></span><br><span class="line">      <span class="attr">discovery:</span></span><br><span class="line">        <span class="attr">metadata:</span></span><br><span class="line">          <span class="attr">response-timeout:</span> <span class="number">10000</span></span><br><span class="line">          <span class="attr">connect-timeout:</span> <span class="number">3000</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;问题1（Connection-prematurely-closed-BEFORE-response）&quot;&gt;&lt;a href=&quot;#问题1（Connection-prematurely-closed-BEFORE-response）&quot; class=&quot;headerlink&quot;</summary>
      
    
    
    
    <category term="技术" scheme="http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="SpringCloud" scheme="http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/SpringCloud/"/>
    
    
    <category term="技术" scheme="http://www.lights8080.com/tags/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="SpringCloud" scheme="http://www.lights8080.com/tags/SpringCloud/"/>
    
    <category term="Spring Cloud Gateway" scheme="http://www.lights8080.com/tags/Spring-Cloud-Gateway/"/>
    
  </entry>
  
  <entry>
    <title>ELK-架构&amp;部署&amp;实践总结</title>
    <link href="http://www.lights8080.com/2021/05/10/%E6%8A%80%E6%9C%AF/ELK/ELK-%E6%9E%B6%E6%9E%84&amp;%E9%83%A8%E7%BD%B2&amp;%E5%AE%9E%E8%B7%B5%E6%80%BB%E7%BB%93/"/>
    <id>http://www.lights8080.com/2021/05/10/%E6%8A%80%E6%9C%AF/ELK/ELK-%E6%9E%B6%E6%9E%84&amp;%E9%83%A8%E7%BD%B2&amp;%E5%AE%9E%E8%B7%B5%E6%80%BB%E7%BB%93/</id>
    <published>2021-05-10T03:27:15.000Z</published>
    <updated>2021-06-01T10:47:46.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>介绍业务规模和架构选择，以及部署说明和实践配置。<br>基于7.11版本。</p></blockquote><span id="more"></span><h2 id="业务规模"><a href="#业务规模" class="headerlink" title="业务规模"></a>业务规模</h2><p>业务每天查询量在千万级，采集数据的规模上亿（后续会更大）。单台Logstash，数据延迟并不大，肉眼可见的Logstash的数据处理能力<br><img src="https://gitee.com/lights8080/lights8080-oss/raw/master/2021/05/lmWxyk.jpg" alt="Logstash监控"></p><h2 id="架构选择"><a href="#架构选择" class="headerlink" title="架构选择"></a>架构选择</h2><p>ELK架构有很多种，这里简单列出常用的几个：</p><ul><li>架构1（最为简单）<br>Logstash -&gt; Elasticsearch -&gt; Kibana</li><li>架构2（使用Beats作为日志收集器）<br>Beats -&gt; Logstash -&gt; Elasticsearch -&gt; Kibana</li><li>架构3（引入消息队列）<br>Beats -&gt; Logstash -&gt; Kafka -&gt; Logstash -&gt; Elasticsearch -&gt; Kibana</li></ul><p>其中架构3可能是被大家积极推荐和最为认可的理想架构。优点是消息队列可以把数据缓存起来避免数据丢失，可以抵挡浪涌削峰填谷，保护下游Logstash。适用于日志规模比较庞大的场景。</p><p>但我的实践中采用的架构2，理由如下：</p><ul><li>消除不必要的复杂性，较低成本</li><li>关于数据丢失，Filebeat至少投递一次和Logstash持久队列可以解决这个问题</li><li>日志规模比较大的情况，可以水平扩展Logstash节点，一组Logstash之间实现负载</li><li>实践Logstash处理能力很强</li></ul><p><img src="https://www.elastic.co/guide/en/logstash/7.11/static/images/deploy3.png" alt="架构2"></p><h2 id="部署说明-amp-实践配置"><a href="#部署说明-amp-实践配置" class="headerlink" title="部署说明&amp;实践配置"></a>部署说明&amp;实践配置</h2><p>介绍服务器环境配置，以及Elasticsearch、Kibana、Logstash、Filebeat的部署和配置参考。</p><ul><li>kibana-7.11.2/config/lights.conf</li><li>filebeat-7.11.2/inputs.d/lights.yml<br>关于业务的这两个配置，不理解的请私信或留言吧</li></ul><h4 id="新建用户和修改文件夹权限"><a href="#新建用户和修改文件夹权限" class="headerlink" title="新建用户和修改文件夹权限"></a>新建用户和修改文件夹权限</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 新建用户</span></span><br><span class="line">$ groupadd elk</span><br><span class="line">$ useradd -m -d /home/elk -s /bin/bash -g elk elk</span><br><span class="line"><span class="comment"># 修改文件夹所属组</span></span><br><span class="line">$ chown -R elk:elk /opt/elk</span><br><span class="line">$ chown -R elk:elk /data/elk</span><br></pre></td></tr></table></figure><h4 id="修改系统配置"><a href="#修改系统配置" class="headerlink" title="修改系统配置"></a>修改系统配置</h4><ul><li><p>vim /etc/sysctl.conf</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vm.max_map_count = 262144</span><br></pre></td></tr></table></figure></li><li><p>vim /etc/security/limits.conf</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">elk soft memlock unlimited</span><br><span class="line">elk hard memlock unlimited</span><br></pre></td></tr></table></figure></li></ul><h4 id="Elasticsearch"><a href="#Elasticsearch" class="headerlink" title="Elasticsearch"></a>Elasticsearch</h4><ul><li><p>vim bin/elasticsearch</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> JAVA_HOME=/opt/elk/elasticsearch-7.11.2/jdk</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$JAVA_HOME</span>/bin:<span class="variable">$PATH</span></span><br></pre></td></tr></table></figure></li><li><p>vim config/jvm.options</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-Xms8g</span><br><span class="line">-Xmx8g</span><br></pre></td></tr></table></figure></li><li><p>vim config/elasticsearch.yml</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">cluster.name:</span> <span class="string">elasticsearch</span></span><br><span class="line"><span class="attr">node.name:</span> <span class="string">node-1</span></span><br><span class="line"><span class="attr">node.master:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">node.data:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">node.ingest:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">path.data:</span> <span class="string">/data/elk/elasticsearch/data</span></span><br><span class="line"><span class="attr">path.logs:</span> <span class="string">/data/elk/elasticsearch/logs</span></span><br><span class="line"><span class="attr">network.host:</span> <span class="string">&quot;10.88.2.1&quot;</span></span><br><span class="line"><span class="attr">http.port:</span> <span class="number">9200</span></span><br><span class="line"><span class="attr">transport.port:</span> <span class="number">9300</span></span><br><span class="line"><span class="attr">discovery.seed_hosts:</span> [<span class="string">&quot;10.88.2.1&quot;</span>]</span><br><span class="line"><span class="comment">#discovery.type: single-node</span></span><br><span class="line"><span class="attr">cluster.initial_master_nodes:</span> [<span class="string">&quot;10.88.2.1&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="attr">http.cors.enabled:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">http.cors.allow-origin:</span> <span class="string">&quot;*&quot;</span></span><br><span class="line"><span class="attr">bootstrap.memory_lock:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">bootstrap.system_call_filter:</span> <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="attr">xpack.security.enabled:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure></li><li><p>命令</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动</span></span><br><span class="line">$ sh ./bin/elasticsearch -d -p es.pid</span><br><span class="line"><span class="comment"># 初始化内置用户</span></span><br><span class="line">$ bin/elasticsearch-setup-passwords auto</span><br></pre></td></tr></table></figure></li></ul><h4 id="Kibana"><a href="#Kibana" class="headerlink" title="Kibana"></a>Kibana</h4><ul><li><p>vim config/kibana.yml</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">server.port:</span> <span class="number">5601</span></span><br><span class="line"><span class="attr">server.host:</span> <span class="string">&quot;0.0.0.0&quot;</span></span><br><span class="line"><span class="attr">server.name:</span> <span class="string">&quot;elk-1&quot;</span></span><br><span class="line"><span class="attr">elasticsearch.hosts:</span> [<span class="string">&quot;http://10.88.2.1:9200&quot;</span>]</span><br><span class="line"><span class="attr">elasticsearch.username:</span> <span class="string">&quot;kibana_system&quot;</span></span><br><span class="line"><span class="attr">elasticsearch.password:</span> <span class="string">&quot;xxxxxxx&quot;</span></span><br><span class="line"><span class="attr">i18n.locale:</span> <span class="string">&quot;zh-CN&quot;</span></span><br><span class="line"><span class="attr">xpack.reporting.encryptionKey:</span> <span class="string">&quot;something_at_least_32_characters&quot;</span></span><br><span class="line"><span class="attr">xpack.security.encryptionKey:</span> <span class="string">&quot;something_at_least_32_characters&quot;</span></span><br><span class="line"><span class="attr">xpack.encryptedSavedObjects.encryptionKey:</span> <span class="string">&quot;something_at_least_32_characters&quot;</span></span><br></pre></td></tr></table></figure></li><li><p>命令</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动</span></span><br><span class="line">$ nohup sh ./bin/kibana &gt;kibana.log 2&gt;&amp;1 &amp;</span><br><span class="line"><span class="comment"># 查看端口</span></span><br><span class="line">netstat -napl|grep 5601</span><br><span class="line"><span class="comment"># 停止</span></span><br><span class="line"><span class="built_in">kill</span> &lt;port&gt;</span><br></pre></td></tr></table></figure></li></ul><h4 id="Logstash"><a href="#Logstash" class="headerlink" title="Logstash"></a>Logstash</h4><ul><li><p>vim config/jvm.options</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-Xms4g</span><br><span class="line">-Xmx4g</span><br></pre></td></tr></table></figure></li><li><p>vim config/logstash.yml</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">pipeline.workers:</span> <span class="number">4</span></span><br><span class="line"><span class="attr">queue.type:</span> <span class="string">persisted</span></span><br></pre></td></tr></table></figure></li><li><p>vim config/lights.conf</p><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Sample Logstash configuration for creating a simple</span></span><br><span class="line"><span class="comment"># Beats -&gt; Logstash -&gt; Elasticsearch pipeline.</span></span><br><span class="line"></span><br><span class="line"><span class="attr">input</span> <span class="string">&#123;</span></span><br><span class="line">    <span class="attr">beats</span> <span class="string">&#123;</span></span><br><span class="line">        <span class="attr">port</span> =<span class="string">&gt; 5044</span></span><br><span class="line">        <span class="attr">host</span> =<span class="string">&gt; &quot;0.0.0.0&quot;</span></span><br><span class="line">    <span class="attr">&#125;</span></span><br><span class="line"><span class="attr">&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="attr">filter</span> <span class="string">&#123;</span></span><br><span class="line">    <span class="attr">if</span> <span class="string">&quot;lights-service&quot; in [tags] &#123;</span></span><br><span class="line">        <span class="attr">if</span> <span class="string">!([service_name]) &#123;</span></span><br><span class="line">            <span class="attr">mutate</span> <span class="string">&#123;</span></span><br><span class="line">                <span class="attr">copy</span> =<span class="string">&gt; &#123; &quot;[log][file][path]&quot; =&gt; &quot;log_file_path&quot; &#125;</span></span><br><span class="line">            <span class="attr">&#125;</span></span><br><span class="line">            <span class="attr">mutate</span> <span class="string">&#123;</span></span><br><span class="line">                <span class="attr">split</span> =<span class="string">&gt; [ &quot;log_file_path&quot; , &quot;/&quot; ]</span></span><br><span class="line">                <span class="attr">add_field</span> =<span class="string">&gt; &#123; &quot;service_name&quot; =&gt; &quot;%&#123;[log_file_path][2]&#125;&quot; &#125;</span></span><br><span class="line">                <span class="attr">remove_field</span> =<span class="string">&gt; [&quot;log_file_path&quot;]</span></span><br><span class="line">            <span class="attr">&#125;</span></span><br><span class="line">        <span class="attr">&#125;</span></span><br><span class="line"></span><br><span class="line">        <span class="attr">if</span> <span class="string">[message] =~ &quot; ERROR &quot; and [message] =~ &quot;Exception&quot; &#123;</span></span><br><span class="line">            <span class="attr">truncate</span> <span class="string">&#123;</span></span><br><span class="line">                <span class="attr">fields</span> =<span class="string">&gt; [&quot;message&quot;]</span></span><br><span class="line">                <span class="attr">length_bytes</span> =<span class="string">&gt; 10000</span></span><br><span class="line">            <span class="attr">&#125;</span></span><br><span class="line">            <span class="attr">grok</span> <span class="string">&#123;</span></span><br><span class="line">                <span class="attr">match</span> =<span class="string">&gt; &#123;</span></span><br><span class="line">                    <span class="meta">&quot;message&quot;</span> =<span class="string">&gt; [</span></span><br><span class="line">                        <span class="meta">&quot;%&#123;TIMESTAMP_ISO8601</span>:<span class="string">timestamp&#125; \[%&#123;DATA:thread&#125;\] %&#123;DATA:level&#125; %&#123;DATA:class&#125; - %&#123;DATA:error_message&#125;\n%&#123;GREEDYDATA:throwable&#125;&quot;,</span></span><br><span class="line">                        <span class="meta">&quot;%&#123;TIMESTAMP_ISO8601</span>:<span class="string">timestamp&#125; \[%&#123;DATA:thread&#125;\] %&#123;DATA:level&#125; %&#123;DATA:class&#125; - %&#123;DATA:error_message&#125;&quot;,</span></span><br><span class="line">                        <span class="meta">&quot;%&#123;TIMESTAMP_ISO8601</span>:<span class="string">timestamp&#125; \[%&#123;DATA:thread&#125;\] %&#123;DATA:level&#125; - %&#123;DATA:error_message&#125;\n%&#123;GREEDYDATA:throwable&#125;&quot;,</span></span><br><span class="line">                        <span class="meta">&quot;%&#123;TIMESTAMP_ISO8601</span>:<span class="string">timestamp&#125; \[%&#123;DATA:thread&#125;\] %&#123;DATA:level&#125; - %&#123;DATA:error_message&#125;&quot;</span></span><br><span class="line">                    <span class="attr">]</span></span><br><span class="line">                <span class="attr">&#125;</span></span><br><span class="line">                <span class="attr">id</span> =<span class="string">&gt; &quot;service-exception&quot;</span></span><br><span class="line">            <span class="attr">&#125;</span></span><br><span class="line">            <span class="attr">mutate</span> <span class="string">&#123;</span></span><br><span class="line">                <span class="attr">add_tag</span> =<span class="string">&gt; [ &quot;service-exception&quot; ]</span></span><br><span class="line">            <span class="attr">&#125;</span></span><br><span class="line">            <span class="attr">if</span> <span class="string">[throwable] &#123;</span></span><br><span class="line">                <span class="attr">mutate</span> <span class="string">&#123;</span></span><br><span class="line">                    <span class="attr">remove_field</span> =<span class="string">&gt; [&quot;throwable&quot;]</span></span><br><span class="line">                <span class="attr">&#125;</span></span><br><span class="line">            <span class="attr">&#125;</span></span><br><span class="line">        <span class="meta">&#125;</span> <span class="string">else &#123;</span></span><br><span class="line">            <span class="attr">if</span> <span class="string">[service_name] == &quot;lights-search-service&quot; and [message] =~ &quot;LightSearchServiceImpl&quot; and [message] =~ &quot; INFO &quot; &#123;</span></span><br><span class="line">                <span class="attr">grok</span> <span class="string">&#123;</span></span><br><span class="line">                    <span class="attr">match</span> =<span class="string">&gt; &#123;</span></span><br><span class="line">                        <span class="meta">&quot;message&quot;</span> =<span class="string">&gt; [</span></span><br><span class="line">                            <span class="meta">&quot;%&#123;TIMESTAMP_ISO8601</span>:<span class="string">timestamp&#125; \[%&#123;DATA:thread&#125;\] %&#123;DATA:level&#125; %&#123;DATA:class&#125; - %&#123;GREEDYDATA:response_message&#125;&quot;</span></span><br><span class="line">                        <span class="attr">]</span></span><br><span class="line">                    <span class="attr">&#125;</span></span><br><span class="line">                    <span class="attr">id</span> =<span class="string">&gt; &quot;lights-search-service&quot;</span></span><br><span class="line">                <span class="attr">&#125;</span></span><br><span class="line">                <span class="attr">mutate</span> <span class="string">&#123;</span></span><br><span class="line">                    <span class="attr">add_tag</span> =<span class="string">&gt; [ &quot;lights-search-service&quot; ]</span></span><br><span class="line">                    <span class="attr">remove_field</span> =<span class="string">&gt; [&quot;message&quot;]</span></span><br><span class="line">                <span class="attr">&#125;</span></span><br><span class="line">            <span class="attr">&#125;</span></span><br><span class="line">        <span class="attr">&#125;</span></span><br><span class="line">    <span class="attr">&#125;</span></span><br><span class="line"></span><br><span class="line">    <span class="attr">if</span> <span class="string">&quot;lights-nginx&quot; in [tags] &#123;</span></span><br><span class="line">        <span class="attr">grok</span> <span class="string">&#123;</span></span><br><span class="line">            <span class="attr">match</span> =<span class="string">&gt; &#123;</span></span><br><span class="line">                <span class="meta">&quot;message&quot;</span> =<span class="string">&gt; [</span></span><br><span class="line">                    <span class="meta">&quot;%&#123;IPORHOST</span>:<span class="string">clientip&#125; %&#123;IPORHOST:server_name&#125; %&#123;HTTPDUSER:ident&#125; %&#123;HTTPDUSER:auth&#125; \[%&#123;HTTPDATE:timestamp&#125;\] \&quot;(?:%&#123;WORD:verb&#125; %&#123;DATA:request&#125;(?: HTTP/%&#123;NUMBER:httpversion&#125;)?|%&#123;DATA:rawrequest&#125;)\&quot; (?:-|%&#123;NUMBER:status&#125;) (?:-|%&#123;NUMBER:request_time&#125;) (?:-|%&#123;NUMBER:bytes&#125;) \&quot;%&#123;DATA:http_referer&#125;\&quot; \&quot;%&#123;DATA:http_user_agent&#125;\&quot; \&quot;%&#123;DATA:http_x_forwarded_for&#125;\&quot; \&quot;%&#123;DATA:upstream_addr&#125;\&quot; %&#123;NUMBER:upstream_status&#125; %&#123;NUMBER:upstream_response_time&#125;&quot;</span></span><br><span class="line">                <span class="attr">]</span></span><br><span class="line">            <span class="attr">&#125;</span></span><br><span class="line">        <span class="attr">&#125;</span></span><br><span class="line">        <span class="attr">mutate</span> <span class="string">&#123;</span></span><br><span class="line">            <span class="attr">remove_field</span> =<span class="string">&gt; [&quot;message&quot;]</span></span><br><span class="line">        <span class="attr">&#125;</span></span><br><span class="line">    <span class="attr">&#125;</span></span><br><span class="line">    <span class="attr">date</span> <span class="string">&#123;</span></span><br><span class="line">        <span class="attr">match</span> =<span class="string">&gt; [ &quot;timestamp&quot;, &quot;yyyy-MM-dd HH:mm:ss.SSS&quot;, &quot;dd/MMM/yyyy:HH:mm:ss Z&quot; ]</span></span><br><span class="line">    <span class="attr">&#125;</span></span><br><span class="line">    <span class="attr">mutate</span> <span class="string">&#123;</span></span><br><span class="line">        <span class="attr">remove_field</span> =<span class="string">&gt; [&quot;@version&quot;, &quot;timestamp&quot;, &quot;agent&quot;, &quot;input&quot;]</span></span><br><span class="line">    <span class="attr">&#125;</span></span><br><span class="line"><span class="attr">&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="attr">output</span> <span class="string">&#123;</span></span><br><span class="line"><span class="comment">    #stdout &#123; codec =&gt; rubydebug &#123; metadata =&gt; true &#125; &#125;</span></span><br><span class="line">    <span class="attr">if</span> <span class="string">&quot;_grokparsefailure&quot; in [tags] &#123;</span></span><br><span class="line">        <span class="attr">file</span> <span class="string">&#123;</span></span><br><span class="line">            <span class="attr">path</span> =<span class="string">&gt; &quot;/opt/elk/logstash-7.11.2/_grokparsefailure-%&#123;+yyyy.MM.dd&#125;&quot;</span></span><br><span class="line">        <span class="attr">&#125;</span></span><br><span class="line">    <span class="meta">&#125;</span> <span class="string">else &#123;</span></span><br><span class="line">        <span class="attr">if</span> <span class="string">&quot;service-exception&quot; in [tags] &#123;</span></span><br><span class="line">            <span class="attr">elasticsearch</span> <span class="string">&#123;</span></span><br><span class="line">                <span class="attr">hosts</span> =<span class="string">&gt; [&quot;http://10.88.2.1:9200&quot;]</span></span><br><span class="line">                <span class="attr">index</span> =<span class="string">&gt; &quot;lights-service-exception&quot;</span></span><br><span class="line">                <span class="attr">action</span> =<span class="string">&gt; &quot;create&quot;</span></span><br><span class="line">                <span class="attr">user</span> =<span class="string">&gt; &quot;elastic&quot;</span></span><br><span class="line">                <span class="attr">password</span> =<span class="string">&gt; &quot;xxxxx&quot;</span></span><br><span class="line">            <span class="attr">&#125;</span></span><br><span class="line">        <span class="attr">&#125;</span></span><br><span class="line">        <span class="attr">if</span> <span class="string">&quot;lights-search-service&quot; in [tags] &#123;</span></span><br><span class="line">            <span class="attr">elasticsearch</span> <span class="string">&#123;</span></span><br><span class="line">                <span class="attr">hosts</span> =<span class="string">&gt; [&quot;http://10.88.2.1:9200&quot;]</span></span><br><span class="line">                <span class="attr">index</span> =<span class="string">&gt; &quot;lights-search&quot;</span></span><br><span class="line"><span class="comment">                #document_id =&gt; &quot;%&#123;[@metadata][_id]&#125;&quot;</span></span><br><span class="line">                <span class="attr">action</span> =<span class="string">&gt; &quot;create&quot;</span></span><br><span class="line">                <span class="attr">user</span> =<span class="string">&gt; &quot;elastic&quot;</span></span><br><span class="line">                <span class="attr">password</span> =<span class="string">&gt; &quot;xxxxx&quot;</span></span><br><span class="line">            <span class="attr">&#125;</span></span><br><span class="line">        <span class="attr">&#125;</span></span><br><span class="line">        <span class="attr">if</span> <span class="string">&quot;lights-nginx&quot; in [tags] &#123;</span></span><br><span class="line">            <span class="attr">elasticsearch</span> <span class="string">&#123;</span></span><br><span class="line">                <span class="attr">hosts</span> =<span class="string">&gt; [&quot;http://10.88.2.1:9200&quot;]</span></span><br><span class="line">                <span class="attr">index</span> =<span class="string">&gt; &quot;lights-nginx&quot;</span></span><br><span class="line">                <span class="attr">action</span> =<span class="string">&gt; &quot;create&quot;</span></span><br><span class="line">                <span class="attr">user</span> =<span class="string">&gt; &quot;elastic&quot;</span></span><br><span class="line">                <span class="attr">password</span> =<span class="string">&gt; &quot;xxxxx&quot;</span></span><br><span class="line">            <span class="attr">&#125;</span></span><br><span class="line">        <span class="attr">&#125;</span></span><br><span class="line">    <span class="attr">&#125;</span></span><br><span class="line"><span class="attr">&#125;</span></span><br></pre></td></tr></table></figure></li><li><p>命令</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 测试配置</span></span><br><span class="line">$ ./bin/logstash -f config/lights.conf --config.test_and_exit</span><br><span class="line"><span class="comment"># 启动</span></span><br><span class="line">$ nohup ./bin/logstash -f config/lights.conf --config.reload.automatic &gt; logstash.log &amp;</span><br></pre></td></tr></table></figure></li></ul><h4 id="Filebeat"><a href="#Filebeat" class="headerlink" title="Filebeat"></a>Filebeat</h4><ul><li><p>vim filebeat.yml</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">filebeat.config.inputs:</span></span><br><span class="line">  <span class="attr">enabled:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">path:</span> <span class="string">$&#123;path.config&#125;/inputs.d/*.yml</span></span><br><span class="line">  <span class="attr">reload.enabled:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">reload.period:</span> <span class="string">10s</span></span><br><span class="line"></span><br><span class="line"><span class="attr">output.logstash:</span></span><br><span class="line">  <span class="attr">hosts:</span> [<span class="string">&quot;10.88.2.1:5044&quot;</span>]</span><br></pre></td></tr></table></figure></li><li><p>vim inputs.d/lights.yml</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Nginx日志</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">type:</span> <span class="string">log</span></span><br><span class="line">  <span class="attr">enabled:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">paths:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">/log/nginx/lights.log</span></span><br><span class="line">  <span class="attr">tags:</span> [<span class="string">&quot;lights-nginx&quot;</span>]</span><br><span class="line">  <span class="attr">tail_files:</span> <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Java日志(异常多行合并)</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">type:</span> <span class="string">log</span></span><br><span class="line">  <span class="attr">enabled:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">paths:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">/log/&lt;service-name&gt;/*.log</span></span><br><span class="line">  <span class="attr">exclude_lines:</span> [<span class="string">&#x27;/actuator/&#x27;</span>]</span><br><span class="line">  <span class="attr">exclude_files:</span> [<span class="string">&#x27;.gz$&#x27;</span>]</span><br><span class="line">  <span class="attr">tags:</span> [<span class="string">&quot;lights-service&quot;</span>]</span><br><span class="line">  <span class="attr">multiline.type:</span> <span class="string">pattern</span></span><br><span class="line">  <span class="attr">multiline.pattern:</span> <span class="string">&#x27;^\d&#123;4&#125;-\d&#123;2&#125;-\d&#123;2&#125;&#x27;</span></span><br><span class="line">  <span class="attr">multiline.negate:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">multiline.match:</span> <span class="string">after</span></span><br><span class="line">  <span class="attr">ignore_older:</span> <span class="string">6h</span></span><br></pre></td></tr></table></figure></li><li><p>命令</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动</span></span><br><span class="line">$ nohup ./filebeat -e &gt;filebeat.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;介绍业务规模和架构选择，以及部署说明和实践配置。&lt;br&gt;基于7.11版本。&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="技术" scheme="http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="ELK" scheme="http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/ELK/"/>
    
    
    <category term="技术" scheme="http://www.lights8080.com/tags/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="ELK" scheme="http://www.lights8080.com/tags/ELK/"/>
    
  </entry>
  
  <entry>
    <title>Beats-Filebeat命令&amp;配置说明</title>
    <link href="http://www.lights8080.com/2021/04/29/%E6%8A%80%E6%9C%AF/ELK/Beats-Filebeat%E5%91%BD%E4%BB%A4&amp;%E9%85%8D%E7%BD%AE%E8%AF%B4%E6%98%8E/"/>
    <id>http://www.lights8080.com/2021/04/29/%E6%8A%80%E6%9C%AF/ELK/Beats-Filebeat%E5%91%BD%E4%BB%A4&amp;%E9%85%8D%E7%BD%AE%E8%AF%B4%E6%98%8E/</id>
    <published>2021-04-29T03:27:15.000Z</published>
    <updated>2021-06-01T10:47:46.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>介绍Filebeat命令、配置以及最佳实战。<br> 基于7.11版本。</p></blockquote><span id="more"></span><h2 id="命令"><a href="#命令" class="headerlink" title="命令"></a>命令</h2><ul><li>export：导出配置到标准输出（configuration, index template, ILM policy, dashboard）</li><li>keystore：管理秘钥仓库</li><li>modules：管理模块配置</li><li>run：运行Filebeat。不知道命令的情况下，默认使用此命令<ul><li>–modules MODULE_LIST：指定运行的模块</li></ul></li><li>setup：一次性初始化环境。包括索引模板，ILM政策，写别名，Kibana仪表盘等<ul><li>–dashboards：设置Kibana仪表盘，需配置连接Kibana信息</li><li>–pipelines：设置Elasticsearch的ingest pipelines</li><li>-e：发送输出到标准错误而不是syslog</li><li>–index-management：设置与Elasticsearch索引管理相关的组件（template, ILM policy, and write alias）</li></ul></li><li>test：测试配置文件</li></ul><p>全局标记</p><ul><li>-E, –E “SETTING_NAME=VALUE”：覆盖指定的配置</li><li>-M, –M “VAR_NAME=VALUE”：覆盖默认的模块配置</li><li>-c, –c FILE：指定Filebeat的配置文件</li><li>-f：指定管道配置文件</li><li>-d, –d SELECTORS：调试选择器，”*”：开启所有组件的调试，”publish”：开启调试”publish“相关信息</li><li>-e, –e：日志发送到stderr并禁用syslog文件输出</li><li>–path.config：设置配置文件路径</li></ul><p>示例：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 一次性设置Elasticsearch索引和Kibana仪表板，-e：发送输出到标准错误而不是syslog</span></span><br><span class="line">./filebeat setup -e</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 启用要运行的模块</span></span><br><span class="line">./filebeat modules enable system</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动</span></span><br><span class="line">sudo chown root filebeat.yml </span><br><span class="line">sudo ./filebeat -c filebeat.yml -e</span><br></pre></td></tr></table></figure><h2 id="配置说明-filebeat-yml"><a href="#配置说明-filebeat-yml" class="headerlink" title="配置说明 filebeat.yml"></a>配置说明 filebeat.yml</h2><ul><li>project paths：项目路径</li><li>general settings：配置包括Global、General</li><li>config file loading：允许外部加载inputs和modules配置</li><li>modules：一种开始处理常见日志格式的快速方法</li><li>inputs：指定Filebeat查找和处理的数据</li><li>output：指定输出。如：Logstash、Elasticsearch、Kafka</li><li>Processors：过滤和增强导出的数据</li><li>internal queue：存储事件的内部缓冲队列（内存和磁盘），负责缓冲输入事件并按批次发送到输出。</li><li>load balancing：配置输出的负载均衡</li><li>logging：Filebeat日志输出选项</li><li>http endpoint：Filebeat通过端点查看内部指标</li><li>autodiscover：容器运行时，自动发现配置，移动目标的监视系统</li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">### project Paths</span></span><br><span class="line"><span class="comment"># Filebeat主目录，默认安装路径</span></span><br><span class="line"><span class="attr">path.home:</span> </span><br><span class="line"><span class="attr">path.config:</span> <span class="string">$&#123;path.home&#125;</span></span><br><span class="line"><span class="attr">path.data:</span> <span class="string">$&#123;path.home&#125;/data</span></span><br><span class="line"><span class="attr">path.logs:</span> <span class="string">$&#123;path.home&#125;/logs</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### Global Filebeat configuration options</span></span><br><span class="line"><span class="comment"># 注册表的根路径，默认$&#123;path.data&#125;/registry</span></span><br><span class="line"><span class="attr">filebeat.registry.path:</span> <span class="string">registry</span></span><br><span class="line"><span class="attr">filebeat.registry.file_permissions:</span> <span class="number">0600</span></span><br><span class="line"><span class="comment"># 控制何时将注册表项写入磁盘(刷新)的超时值</span></span><br><span class="line"><span class="attr">filebeat.registry.flush:</span> <span class="string">0s</span></span><br><span class="line"><span class="comment"># Filebeat 在关闭之前等待发布者完成发送事件的关闭时间</span></span><br><span class="line"><span class="attr">filebeat.shutdown_timeout:</span> <span class="string">5s</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### General configuration options</span></span><br><span class="line"><span class="comment"># Beat的名字，默认使用主机名</span></span><br><span class="line"><span class="attr">name:</span> <span class="string">my-service</span></span><br><span class="line"><span class="comment"># 标记列表，方便Kibana或Logstash过滤，如服务层，集群名等</span></span><br><span class="line"><span class="attr">tags:</span> [<span class="string">&quot;service-X&quot;</span>, <span class="string">&quot;web-tier&quot;</span>]</span><br><span class="line"><span class="comment"># 属性中添加附加信息的可选字段，如环境信息</span></span><br><span class="line"><span class="attr">fields:</span></span><br><span class="line">  <span class="attr">env:</span> <span class="string">staging</span></span><br><span class="line">  <span class="attr">service_name:</span> <span class="string">service-X</span></span><br><span class="line"><span class="comment"># 将自定义字段作为顶级字段存储到到输出文档中，默认false</span></span><br><span class="line"><span class="attr">fields_under_root:</span> <span class="literal">false</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### Processors configuration</span></span><br><span class="line"><span class="comment"># 定义模块的处理器，删除所有DEBUG消息</span></span><br><span class="line"><span class="attr">processors:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">drop_event:</span></span><br><span class="line">      <span class="attr">when:</span></span><br><span class="line">        <span class="attr">regexp:</span></span><br><span class="line">          <span class="attr">message:</span> <span class="string">&quot;^DBG:&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### Logging</span></span><br><span class="line"><span class="attr">logging.level:</span> <span class="string">info</span></span><br><span class="line"><span class="attr">logging.to_files:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">logging.files:</span></span><br><span class="line">  <span class="attr">path:</span> <span class="string">/var/log/filebeat</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">filebeat</span></span><br><span class="line">  <span class="comment"># 日志文件最大大小，默认10M</span></span><br><span class="line">  <span class="attr">rotateeverybytes:</span> <span class="number">10485760</span></span><br><span class="line">  <span class="comment"># 日志滚动删除旧文件，默认7</span></span><br><span class="line">  <span class="attr">keepfiles:</span> <span class="number">7</span></span><br><span class="line">  <span class="comment"># 日志文件滚动周期，默认禁用</span></span><br><span class="line">  <span class="attr">interval:</span> <span class="string">24h</span></span><br><span class="line">  <span class="comment"># 标准错误记录到日志文件中</span></span><br><span class="line">  <span class="attr">redirect_stderr:</span> <span class="literal">false</span></span><br><span class="line"><span class="comment"># 定期记录内部发生变化的指标，默认开启</span></span><br><span class="line"><span class="attr">logging.metrics.enabled:</span> <span class="literal">true</span></span><br><span class="line"><span class="comment"># 记录内部指标的时间</span></span><br><span class="line"><span class="attr">logging.metrics.period:</span> <span class="string">30s</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### 外部配置</span></span><br><span class="line"><span class="attr">filebeat.config.inputs:</span></span><br><span class="line">  <span class="attr">enabled:</span> <span class="literal">true</span></span><br><span class="line">  <span class="comment"># 要检查的更改文件路径</span></span><br><span class="line">  <span class="attr">path:</span> <span class="string">configs/*.yml</span></span><br><span class="line">  <span class="comment"># 开启配置动态加载</span></span><br><span class="line">  <span class="attr">reload.enabled:</span> <span class="literal">true</span></span><br><span class="line">  <span class="comment"># 指定检查文件更改的频率</span></span><br><span class="line">  <span class="attr">reload.period:</span> <span class="string">10s</span></span><br><span class="line"><span class="attr">filebeat.config.modules:</span></span><br><span class="line">  <span class="attr">path:</span> <span class="string">$&#123;path.config&#125;/modules.d/*.yml</span></span><br><span class="line">  <span class="attr">reload.enabled:</span> <span class="literal">false</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### 日志输入</span></span><br><span class="line"><span class="attr">filebeat.inputs:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">type:</span> <span class="string">log</span></span><br><span class="line">  <span class="attr">enabled:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">paths:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&quot;/var/log/wifi.log&quot;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&quot;/var/log/apache2/*&quot;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&quot;/var/log/*/*.log&quot;</span></span><br><span class="line">  <span class="comment"># 递归模式，默认false。For example: /foo/** expands to /foo, /foo/*, /foo/*/*, and so on</span></span><br><span class="line">  <span class="attr">recursive_glob.enabled:</span> <span class="literal">false</span></span><br><span class="line">  <span class="comment"># 文件编码</span></span><br><span class="line">  <span class="attr">encoding:</span> <span class="string">plain</span></span><br><span class="line">  <span class="comment"># 设置标记文件的位置</span></span><br><span class="line">  <span class="attr">file_identity.inode_marker.path:</span> <span class="string">/logs/.filebeat-marker</span></span><br><span class="line">  <span class="comment"># 标记列表，方便Kibana或Logstash过滤</span></span><br><span class="line">  <span class="attr">tags:</span> [<span class="string">&quot;service-X&quot;</span>, <span class="string">&quot;web-tier&quot;</span>]</span><br><span class="line">  <span class="comment"># 属性中添加附加信息的可选字段</span></span><br><span class="line">  <span class="attr">fields:</span></span><br><span class="line">    <span class="attr">env:</span> <span class="string">staging</span></span><br><span class="line">  <span class="comment"># 将自定义字段作为顶级字段存储到到输出文档中</span></span><br><span class="line">  <span class="attr">fields_under_root:</span> <span class="literal">false</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment"># 包含的正则表达式列表，先于exclude_lines执行</span></span><br><span class="line">  <span class="attr">include_lines:</span> [<span class="string">&#x27;^ERR&#x27;</span>, <span class="string">&#x27;^WARN&#x27;</span>]</span><br><span class="line">  <span class="comment"># 排除的正则表达式列表</span></span><br><span class="line">  <span class="attr">exclude_lines:</span> [<span class="string">&#x27;^DBG&#x27;</span>]</span><br><span class="line">  <span class="comment"># 多行消息匹配,Java 堆栈跟踪的例子（https://www.elastic.co/guide/en/beats/filebeat/7.x/multiline-examples.html）</span></span><br><span class="line">  <span class="attr">multiline.type:</span> <span class="string">pattern</span></span><br><span class="line">  <span class="attr">multiline.pattern:</span> <span class="string">&#x27;^[[:space:]]+(at|\.&#123;3&#125;)[[:space:]]+\b|^Caused by:&#x27;</span></span><br><span class="line">  <span class="comment"># 否定模式，true：没有匹配的行作为事件行的连贯行；false：匹配的行作为事件行的连贯行。默认false。</span></span><br><span class="line">  <span class="attr">multiline.negate:</span> <span class="literal">false</span></span><br><span class="line">  <span class="comment"># 连贯行组合事件行之前（before）还是之后（after）</span></span><br><span class="line">  <span class="attr">multiline.match:</span> <span class="string">after</span></span><br><span class="line">  <span class="comment"># 每个收割机获取文件时使用的缓冲区大小</span></span><br><span class="line">  <span class="attr">harvester_buffer_size:</span> <span class="number">16384</span></span><br><span class="line">  <span class="comment"># 单个日志消息的最大字节数，超出部分丢弃（10M）</span></span><br><span class="line">  <span class="attr">max_bytes:</span> <span class="number">10485760</span></span><br><span class="line">  <span class="comment"># 排除文件</span></span><br><span class="line">  <span class="attr">exclude_files:</span> [<span class="string">&#x27;\.gz$&#x27;</span>]</span><br><span class="line">  </span><br><span class="line">  <span class="comment">##### Harvester closing options</span></span><br><span class="line">  <span class="comment"># 指定的时间段后关闭文件句柄，基于文件的修改，被扫描到后继续进行。建议设置一个大于最少更新频率的值，默认5分钟</span></span><br><span class="line">  <span class="attr">close_inactive:</span> <span class="string">5m</span></span><br><span class="line">  <span class="comment"># 重命名或移动文件时关闭收割机，默认关闭</span></span><br><span class="line">  <span class="attr">close_renamed:</span> <span class="literal">false</span></span><br><span class="line">  <span class="comment"># 删除文件时立马关闭收割机，当文件再次出现时被扫描到后继续进行，默认启用</span></span><br><span class="line">  <span class="attr">close_removed:</span> <span class="literal">true</span></span><br><span class="line">  <span class="comment"># 收割机到达文件末尾时立刻关闭，默认禁用</span></span><br><span class="line">  <span class="attr">close_eof:</span> <span class="literal">false</span></span><br><span class="line">  <span class="comment"># 指定时间后关闭，按照扫描频路再次开启新的收割机，默认禁用</span></span><br><span class="line">  <span class="attr">close_timeout:</span> <span class="number">0</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">##### State options</span></span><br><span class="line">  <span class="comment"># 指定时间段后文件无更新，则清除注册表中的状态，默认0，表示禁用清除注册表。clean_inactive设置必须大于ignore_older + scan_frequency，否则可能导致不断的重新发送全部内容</span></span><br><span class="line">  <span class="attr">clean_inactive:</span> <span class="number">0</span></span><br><span class="line">  <span class="comment"># 重命名或移动的文件，注册表中的状态将被清除。默认开启</span></span><br><span class="line">  <span class="attr">clean_removed:</span> <span class="literal">true</span></span><br><span class="line">  <span class="comment"># 扫描频率，默认10秒</span></span><br><span class="line">  <span class="attr">scan_frequency:</span> <span class="string">10s</span></span><br><span class="line">  <span class="comment"># 扫描顺序，默认禁用，可选值：modtime|filename。如果为此设置指定值，则可以使用scan.order配置文件是按升序还是降序进行扫描</span></span><br><span class="line">  <span class="attr">scan.sort:</span> </span><br><span class="line">  <span class="attr">scan.order:</span> <span class="string">asc|desc</span></span><br><span class="line">  <span class="comment"># Filebeat 将开始在每个文件的结尾而不是开始读取新文件，适用于Filebeat尚未处理的文件。如果已经运行过Filebeat并且文件的状态已经保留，则tail_files配置无效。</span></span><br><span class="line">  <span class="attr">tail_files:</span> <span class="literal">false</span></span><br><span class="line">  <span class="comment"># 忽略在指定时间跨度之前修改的所有文件，依赖于文件的修改时间。默认0，不忽略任何文件。必须大于close_inactive</span></span><br><span class="line">  <span class="attr">ignore_older:</span> <span class="number">0</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment"># 限制并行启动的收割机数量</span></span><br><span class="line">  <span class="attr">harvester_limit:</span> <span class="number">0</span></span><br><span class="line">  <span class="comment"># 根据文件的inode和设备id来区分文件</span></span><br><span class="line">  <span class="attr">file_identity.native:</span> <span class="string">~</span></span><br><span class="line">  <span class="comment"># 根据路径来区分文件</span></span><br><span class="line">  <span class="attr">file_identity.path:</span> <span class="string">~</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### 日志输出</span></span><br><span class="line"><span class="attr">output.kafka:</span></span><br><span class="line">  <span class="comment"># kafka服务器</span></span><br><span class="line">  <span class="attr">hosts:</span> [<span class="string">&quot;kafka1:9092&quot;</span>, <span class="string">&quot;kafka2:9092&quot;</span>, <span class="string">&quot;kafka3:9092&quot;</span>]</span><br><span class="line">  <span class="comment"># 动态设置topic</span></span><br><span class="line">  <span class="attr">topic:</span> <span class="string">&#x27;<span class="template-variable">%&#123;[fields.log_topic]&#125;</span>&#x27;</span></span><br><span class="line">  <span class="comment"># 事件将仅发布到可用分区</span></span><br><span class="line">  <span class="attr">partition.round_robin:</span></span><br><span class="line">    <span class="attr">reachable_only:</span> <span class="literal">false</span></span><br><span class="line">  <span class="comment"># ACK可靠性级别，默认1。0 = no response，1 = wait for local commit，-1 = wait for all replica to commit</span></span><br><span class="line">  <span class="attr">required_acks:</span> <span class="number">1</span></span><br><span class="line">  <span class="comment"># gzip压缩级别，0禁用压缩</span></span><br><span class="line">  <span class="attr">compression:</span> <span class="string">gzip</span></span><br><span class="line">  <span class="attr">compression_level:</span> <span class="number">4</span></span><br><span class="line">  <span class="comment"># 消息的最大字节数</span></span><br><span class="line">  <span class="attr">max_message_bytes:</span> <span class="number">1000000</span></span><br><span class="line"><span class="comment"># 负载均衡的Logstash</span></span><br><span class="line"><span class="attr">output.logstash:</span></span><br><span class="line">  <span class="attr">hosts:</span> [<span class="string">&quot;localhost:5044&quot;</span>, <span class="string">&quot;localhost:5045&quot;</span>]</span><br><span class="line">  <span class="attr">loadbalance:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">worker:</span> <span class="number">2</span></span><br><span class="line">  </span><br><span class="line"><span class="comment">### Internal queue</span></span><br><span class="line"><span class="comment"># 用于缓冲要发布的事件的内部队列配置。默认mem（内存队列）</span></span><br><span class="line"><span class="attr">queue.mem:</span></span><br><span class="line">  <span class="comment"># 内存队列的最大缓冲事件数</span></span><br><span class="line">  <span class="attr">events:</span> <span class="number">4096</span></span><br><span class="line">  <span class="comment"># 发布所需的最小事件数，设置为0则发布事件直接输出使用，无需等待</span></span><br><span class="line">  <span class="attr">flush.min_events:</span> <span class="number">2048</span></span><br><span class="line">  <span class="comment"># 达到flush.min_events的最大等待事件，设置为0则无需等待</span></span><br><span class="line">  <span class="attr">flush.timeout:</span> <span class="string">1s</span></span><br><span class="line"><span class="attr">queue.disk:</span></span><br><span class="line">  <span class="comment"># 启用磁盘队列，指定最大大小既使用空间</span></span><br><span class="line">  <span class="attr">max_size:</span> <span class="string">10GB</span></span><br><span class="line">  <span class="attr">path:</span> <span class="string">$&#123;path.data&#125;/diskqueue</span></span><br><span class="line">  <span class="comment"># 队列文件以段的形式保存，每个段包含一些待发送到输出的事件，所有事件发送后删除</span></span><br><span class="line">  <span class="attr">segment_size:</span> <span class="string">max_size</span> <span class="string">/</span> <span class="number">10</span></span><br><span class="line">  <span class="comment"># 当事件等待输出时，从磁盘读取到内存中的事件数。调高此值可以提高输出速度，但是会占用更多内存</span></span><br><span class="line">  <span class="attr">read_ahead:</span> <span class="number">512</span></span><br><span class="line">  <span class="comment"># 队列等待事件写入磁盘时可以存储到内存中的事件数</span></span><br><span class="line">  <span class="attr">write_ahead:</span> <span class="number">2048</span></span><br><span class="line">  <span class="comment"># 磁盘错误导致的队列操作失败，重试间隔时间</span></span><br><span class="line">  <span class="attr">retry_interval:</span> <span class="string">1s</span></span><br><span class="line">  <span class="comment"># 多个连续的写入磁盘错误，队列将重试间隔增加2倍，最大间隔时间</span></span><br><span class="line">  <span class="attr">max_retry_interval:</span> <span class="string">30s</span></span><br><span class="line"><span class="attr">queue.spool:</span></span><br></pre></td></tr></table></figure><h2 id="最佳实践调优"><a href="#最佳实践调优" class="headerlink" title="最佳实践调优"></a>最佳实践调优</h2><ul><li><p>文件内容变更延迟发送事件调优<br>默认基于内存缓冲事件，最晚需要11s才会发布事件到输出。<br><code>filebeat.inputs.type:log.scan_frequency: 10s</code>：文件的扫描频率<br><code>queue.mem.flush.timeout: 1s</code>：缓冲事件的超时时间<br><code>queue.mem.flush.min_events: 2048</code>：超时时间内发布事件所需的最小缓冲数</p></li><li><p>测试时编辑文件导致整个文件内容重新发送<br>不要用vim修改，使用<code>echo &quot;xxx&quot; &gt;&gt; log_file</code></p></li></ul>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;介绍Filebeat命令、配置以及最佳实战。&lt;br&gt; 基于7.11版本。&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="技术" scheme="http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="ELK" scheme="http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/ELK/"/>
    
    
    <category term="技术" scheme="http://www.lights8080.com/tags/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="ELK" scheme="http://www.lights8080.com/tags/ELK/"/>
    
    <category term="Filebeat" scheme="http://www.lights8080.com/tags/Filebeat/"/>
    
  </entry>
  
  <entry>
    <title>Kibana-介绍</title>
    <link href="http://www.lights8080.com/2021/04/29/%E6%8A%80%E6%9C%AF/ELK/Kibana-%E4%BB%8B%E7%BB%8D/"/>
    <id>http://www.lights8080.com/2021/04/29/%E6%8A%80%E6%9C%AF/ELK/Kibana-%E4%BB%8B%E7%BB%8D/</id>
    <published>2021-04-29T03:27:15.000Z</published>
    <updated>2021-06-01T10:47:46.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>介绍Kibana的侧边栏、面板类型、配置说明等。<br> 基于7.11版本。</p></blockquote><span id="more"></span><h1 id="Kibana"><a href="#Kibana" class="headerlink" title="Kibana"></a>Kibana</h1><blockquote><p>Kibana是一个开源分析和可视化平台，旨在与Elasticsearch协同工作。您使用Kibana搜索，查看和与存储在Elasticsearch索引中的数据进行交互。您可以轻松执行高级数据分析，并在各种图表，表格和地图中可视化您的数据。<br><a href="https://www.elastic.co/guide/en/kibana/7.11/index.html">https://www.elastic.co/guide/en/kibana/7.11/index.html</a></p></blockquote><h2 id="侧边栏"><a href="#侧边栏" class="headerlink" title="侧边栏"></a>侧边栏</h2><ul><li>Discover（数据探索）：搜索、过滤和展示所选索引模型（Index Pattern）文档数据</li><li>Visualize（可视化）：为数据创建可视化控件</li><li>Dashboard（仪表盘）：展示保存的可视化结果集合</li><li>Canvas（画布）：非常自由灵活对数据进行可视化布局与展现</li><li>Maps（地图）：已地图的方式展示聚合信息</li><li>Machine Learning（机器学习）</li><li>Infrastructure（基础设施监控）：通过metricbeat监控基础服务。如：redis、rocketmq</li><li>Metrics（度量应用）：探索整个生态系统中有关系统和服务的指标</li><li>Logs（日志）：实时跟踪相关的日志数据；提供了一个紧凑的，类似控制台的显示器。可以实时日志拖尾</li><li>APM（Application Performance Monitoring-应用程序性能监视）：业务跟踪及监控。</li><li>Uptime（正常运行时间）：监控应用程序和服务的可用性问题；通过HTTP/S，TCP和ICMP监控网络端点的状态</li><li>SIEM（Security Information &amp; Event Management-安全信息与事件管理）：安全分析师的高度交互式工作区</li><li>Dev Tools（开发工具）：包括控制台、查询分析和聚合</li><li>Stack Monitoring（ELK监控）：可视化监控数据</li><li>Management（Kibana管理）：包括索引模式的初始设置和持续配置等</li></ul><h3 id="Dashboard（仪表板）"><a href="#Dashboard（仪表板）" class="headerlink" title="Dashboard（仪表板）"></a>Dashboard（仪表板）</h3><p>仪表板是用于分析数据的面板的集合。在仪表板上，您可以添加各种面板，可以重新排列并讲述关于数据的故事。</p><p>编辑仪表板：</p><ul><li>Add controls（添加控制器）</li><li>Add markdown（添加说明文档）</li><li>Arrange panels（面板排版）</li><li>Clone panels（克隆面板）</li><li>Customize time ranges（自定义时间范围）</li></ul><p>探索仪表板数据：</p><ul><li>Inspect elements（检查元素）：查看可视化和保存的搜索背后的数据和请求</li><li>Explore underlying data（探索面板底层数据）：可以在其中查看和过滤可视化面板中的数据，为了探索仪表板上面板的底层数据，Kibana打开了Discover，可视化的索引模式、筛选器、查询和时间范围将继续应用。仅适用于单个索引模式的面板</li></ul><p>自定义仪表板操作：</p><ul><li>Dashboard drilldowns（仪表盘深度探讨）：能够从另一个仪表板打开仪表板，带有时间范围、过滤器和其他参数，因此上下文保持不变。仪表板钻取可以帮助您从一个新的角度继续分析。</li><li>URL drilldowns（URL深度探讨）：能够从仪表板导航到内部或外部URL。目标URL可以是动态的，这取决于仪表板上下文或用户与面板的交互。</li></ul><p>共享仪表板：</p><ul><li>将代码嵌入网页中，必须具有Kibana访问权限才能查看嵌入式仪表板</li><li>直接链接到 Kibana 的控制面板</li><li>生成PDF/PNG报告</li></ul><h4 id="面板类型"><a href="#面板类型" class="headerlink" title="面板类型"></a>面板类型</h4><ul><li>Area（面积图）：使用面积图比较两个或多个类别随时间变化的趋势，并显示趋势的幅度。</li><li>Stacked Area（堆积面积图）：使用堆积面积图可视化部分-整体关系，并显示每个类别对累积总数的贡献。</li><li>Bar（条形图）：使用条形图对大量类别的数据进行比较，也支持水平条形图。</li><li>Stacked bar（堆积条形图）：使用堆叠的条形图可以比较分类值级别之间的数值。</li><li>Line（折线图）：使用折线图可以直观地显示一系列值，发现一段时间内的趋势并预测未来值。</li><li>Pie（饼图）：使用饼图显示多个类别之间的比较，说明一个类别相对于其他类别的优势，并显示百分比或比例数据。</li><li>Donut（甜甜圈图）：与饼形图相似，但删除了中心圆。当您想一次显示多个统计信息时，请使用甜甜圈图。</li><li>Tree map（树图）：将数据的不同部分关联到整体，使用树图可以有效利用空间来显示每个类别的总计百分比。</li><li>Heat map（热图）：显示数据的图形表示形式，其中各个值由颜色表示。当数据集包含范畴数据时，使用热图。</li><li>Goal（进度图）：显示指标如何朝固定目标发展，使用目标显示目标进度状态的易于阅读的视觉效果。</li><li>Gauge（计量图）：沿比例尺显示数据，使用计量图来显示度量值与参考阈值的关系。</li><li>Metric（度量值）：显示聚合的单个数值。</li><li>Data table（表格数据）：以表格格式显示原始数据或聚合结果。</li><li>Tag cloud（标签云）：显示单词在出现的频率，使用标签云可以轻松生成大型文档的摘要。</li><li>Maps（地图）</li><li>Lens（透镜）：创建强大的数据可视化效果的最简单、最快捷的方法。可以将任意多的数据字段拖放到可视化构建窗格中。</li><li>TSVB（时间序列数据）：TSVB是时间序列数据可视化工具，充分利用Elasticsearch聚合框架的功能。可以组合无数个聚合来显示数据。支持：选择不同的数据展示方式、叠加注释事件等。</li><li>Timelion（时间序列数据）：时间序列数据可视化工具，可以在单个可视化文件中组合独立的数据源。在7.0及更高版本中，不建议使用Timelion应用。</li><li>Vega（自定义可视化）：使用Vega和Vega-Lite构建自定义可视化，并由一个或多个数据源支持。支持：使用嵌套或父/子映射的聚合、没有索引模式的聚合、自定义时间过滤器查询、复杂的计算、从_source而不是聚合中提取数据等。</li><li>Controls（控制器）：可以实时过滤面板上的数据，支持选择列表和范围滑杆</li><li>Markdown（文本编辑器）：当您要将上下文（例如重要信息，说明和图像）添加到仪表板上的其他面板时，请使用Markdown。</li></ul><h3 id="Alerts-and-Actions（监控警报）"><a href="#Alerts-and-Actions（监控警报）" class="headerlink" title="Alerts and Actions（监控警报）"></a>Alerts and Actions（监控警报）</h3><ul><li>General alert details（警报详细信息）：<ul><li>Name：警报名称，显示在警报列表，帮助识别和查询警报</li><li>Tags：警报标签列表，显示在警报列表，有助于查询和组织警报</li><li>Check every：检查警报条件的频率</li><li>Notify every：限制重复报警的频率</li></ul></li><li>Alert type and conditions（警报类型和条件）：选择不同的警报类型不同的条件表达形式。<ul><li>Index threshold：索引阈值警报类型</li></ul></li><li>Action type and action details（动作类型和详细信息）：每个操作都必须指定一个连接器实例。<ul><li>Index：Index data into Elasticsearch</li><li>Email：Send email from your server</li><li>Server log：Add a message to a Kibana log</li><li>Webhook：Send a request to a web service</li></ul></li></ul><h3 id="Graph（图形分析）"><a href="#Graph（图形分析）" class="headerlink" title="Graph（图形分析）"></a>Graph（图形分析）</h3><p>图形分析功能使您能够发现 Elasticsearch 索引中的项目是如何相关的。您可以研究索引词汇之间的连接，并查看哪些连接最有意义。这在各种应用程序中都很有用，从欺诈检测到推荐引擎。</p><p>例如，图形浏览可以帮助您发现黑客所针对的网站漏洞，从而可以加固您的网站。或者，您可以向电子商务客户提供基于图的个性化推荐。</p><p>图形分析特性为 Kibana 提供了一个简单但强大的图形探索 API 和一个交互式图形可视化工具。两者都可以在现有的 Elasticsearch 索引中使用ー你不需要存储任何额外的数据来使用这些特性。</p><h2 id="kibana-yml"><a href="#kibana-yml" class="headerlink" title="kibana.yml"></a>kibana.yml</h2><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">server.port:</span> <span class="number">5601</span></span><br><span class="line"><span class="attr">server.host:</span> <span class="string">&quot;0.0.0.0&quot;</span></span><br><span class="line"><span class="attr">server.name:</span> <span class="string">&quot;elk-1&quot;</span></span><br><span class="line"><span class="attr">i18n.locale:</span> <span class="string">&quot;zh-CN&quot;</span></span><br><span class="line"><span class="attr">elasticsearch.hosts:</span> [<span class="string">&quot;http://your_elasticsearch_host:9200&quot;</span>]</span><br><span class="line"><span class="attr">elasticsearch.username:</span> <span class="string">&quot;kibana_system&quot;</span></span><br><span class="line"><span class="attr">elasticsearch.password:</span> <span class="string">&quot;xxxxxxxxxxxxxxx&quot;</span></span><br><span class="line"><span class="comment"># 防止会话在重启时失效</span></span><br><span class="line"><span class="attr">xpack.security.encryptionKey:</span> <span class="string">&quot;something_at_least_32_characters&quot;</span></span><br><span class="line"><span class="comment"># 防止挂起的报告在重新启动时失败</span></span><br><span class="line"><span class="attr">xpack.reporting.encryptionKey:</span> <span class="string">&quot;something_at_least_32_characters&quot;</span></span><br></pre></td></tr></table></figure><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><h3 id="1-创建索引失败"><a href="#1-创建索引失败" class="headerlink" title="1. 创建索引失败"></a>1. 创建索引失败</h3><p>错误信息：POST 403 (forbidden) on create index pattern<br>解决办法：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">PUT _settings</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">&quot;index&quot;</span>: &#123;</span><br><span class="line">    <span class="attr">&quot;blocks&quot;</span>: &#123;</span><br><span class="line">      <span class="attr">&quot;read_only_allow_delete&quot;</span>: <span class="string">&quot;false&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;介绍Kibana的侧边栏、面板类型、配置说明等。&lt;br&gt; 基于7.11版本。&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="技术" scheme="http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="ELK" scheme="http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/ELK/"/>
    
    
    <category term="技术" scheme="http://www.lights8080.com/tags/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="ELK" scheme="http://www.lights8080.com/tags/ELK/"/>
    
    <category term="Kibana" scheme="http://www.lights8080.com/tags/Kibana/"/>
    
  </entry>
  
  <entry>
    <title>Beats-Filebeat介绍</title>
    <link href="http://www.lights8080.com/2021/04/28/%E6%8A%80%E6%9C%AF/ELK/Beats-Filebeat%E4%BB%8B%E7%BB%8D/"/>
    <id>http://www.lights8080.com/2021/04/28/%E6%8A%80%E6%9C%AF/ELK/Beats-Filebeat%E4%BB%8B%E7%BB%8D/</id>
    <published>2021-04-28T03:27:15.000Z</published>
    <updated>2021-06-01T10:47:46.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Filebeat介绍，包括工作方式、模块、如何避免数据重复、处理器的速查表。<br> 基于7.11版本。</p></blockquote><span id="more"></span><p>Beats是一款轻量级数据采集器，你可以将它作为代理程序安装在你的服务器上，然后将操作数据发送到 Elasticsearch。可以直接发送数据到 Elasticsearch 或者通过 Logstash，在那里你可以进一步处理和增强数据。</p><ul><li>Filebeat（日志文件）</li><li>Metricbeat（指标）</li><li>Heartbeat（可用性监控）</li><li>Functionbeat（函数计算采集器）</li></ul><h2 id="Filebeat"><a href="#Filebeat" class="headerlink" title="Filebeat"></a>Filebeat</h2><blockquote><p>Filebeat是用于转发集中日志数据的传输工具。作为服务器上的代理安装，收集日志事件，并将它们转发到Elasticsearch或Logstash。<br><a href="https://www.elastic.co/guide/en/beats/filebeat/7.11/index.html">https://www.elastic.co/guide/en/beats/filebeat/7.11/index.html</a></p></blockquote><h3 id="工作方式"><a href="#工作方式" class="headerlink" title="工作方式"></a>工作方式</h3><p>当启动Filebeat，会根据显示指定的日志数据启动一个或多个输入，每个日志文件都会启动一个收割机（harvester）。每个收割机会读取日志的最新内容，并将日志数据发送到libbeat，libbeat汇总事件并发送到输出。</p><img src="https://gitee.com/lights8080/lights8080-oss/raw/master/uPic/StbFBm.jpg" alt="IMAGE"/><p>Filebeat由两个主要部分组成：inputs和harvesters。它们一起工作以尾部文件将事件数据发送到指定的输出。</p><p>收割机（harvesters）：一个收割机负责读取单个文件的内容。收割机逐行读取每个文件并将内容发送到输出。每个文件启动一个收割机负责打开和关闭文件，收割机运行时文件描述符保持打开状态。如果文件被删除或重命名，Filebeat将继续读取该文件，副作用是磁盘上的空间将保留到收割机关闭为止。</p><p>输入（inputs）：一个输入负责管理收割机并查找所有可读取的资源。日志类型输入检查每个文件，以查看收割机是否需要启动，是否已经运行，或是否需要忽略该文件。自收割机关闭之后，如果文件大小有更改才会获取新行。</p><p>Filebeat保持每个文件的状态，并经常将状态刷新到磁盘的注册表文件。该状态用于记录收割机正在读取的最后一个偏移量并确保发送所有的日志行。如果输出不可达，则Filebeat会保持跟踪发送的最后几行，并在输出可用时继续读取文件。Filebeat运行时状态信息也会保持在内存中，当Filebeat重启时，将使用注册文件中的数据重新构建状态，并且在最后一个已知位置继续每个收割机。</p><p>对于每个输入，Filebeat会保持每个文件的状态。由于文件可以重命名和移动，因此文件名和路径不能标识一个文件。Filebeat将存储每个文件的唯一标识符以检测文件是否以前被获取过。</p><p>Filebeat保证事件将至少一次传递到输出，并且不会丢失数据。因为他在注册文件中存储了每个事件的传递状态。如果输出被阻止或未确认所有事件的情况下，Filebeat将继续尝试发送事件，直到输出确认接收为止。如果Filebeat在发送事件的过程中关闭，则不会等待输出确认所有的事件。重启Filebeat时，将再次发送关闭之前输出未确认的所有事件。这样可以确保每个事件至少发送一次，但是有可能会重复发送。</p><h3 id="如何避免Elasticsearch数据重复"><a href="#如何避免Elasticsearch数据重复" class="headerlink" title="如何避免Elasticsearch数据重复"></a>如何避免Elasticsearch数据重复</h3><p>由于Beats框架确保至少一次交付，又由于Elasticsearch的文档ID通常是接受到数据后才设置的，因此重复事件被索引为新文档。通过在建立索引期间设置，则Elasticsearch会覆盖现有文档而不是新创建一个新文档。</p><ol><li>在Beats中设置文档ID。</li><li>在Logstash管道设置文档ID。</li></ol><h3 id="填充地理位置信息"><a href="#填充地理位置信息" class="headerlink" title="填充地理位置信息"></a>填充地理位置信息</h3><p>基于IP地址填充地理位置信息。然后可以使用此信息来可视化IP地址在地图中的位置。</p><ol><li>Filebeat与Elasticsearch中的GoeIp处理器一起使用</li><li>Logstash中使用GeoIP过滤器</li></ol><h3 id="模块（Modules）"><a href="#模块（Modules）" class="headerlink" title="模块（Modules）"></a>模块（Modules）</h3><blockquote><p>Filebeat模块简化了常见的日志格式的收集，解析和可视化。每个Filebeat模块由一个或多个文件集组成，这些文件集包含摄取节点管道（ingest node pipelines），Elasticsearch模板，Filebeat输入配置和Kibana仪表板。</p></blockquote><ul><li>use ingest pipelines for parsing</li><li>use Logstash pipelines for parsing</li></ul><p>如Nginx日志，由一个或多个文件集组成（access和error）：</p><ul><li>Filebeat输入配置要查找的日志文件路径，还负责在需要时将多行事件缝合在一起。</li><li>Elasticsearch Ingest Node管道定义，用于解析日志行。</li><li>定义字段，为每个字段正确的配置到Elasticsearch。</li><li>Kibana仪表盘可视化日志文件</li></ul><h3 id="处理器（Processors）"><a href="#处理器（Processors）" class="headerlink" title="处理器（Processors）"></a>处理器（Processors）</h3><h4 id="过滤和增强数据的处理器"><a href="#过滤和增强数据的处理器" class="headerlink" title="过滤和增强数据的处理器"></a>过滤和增强数据的处理器</h4><p>如果只需要导出的数据的一部分或者需要增强导出数据。Filebeat提供了两个选项来过滤和增强导出的数据。</p><ol><li>可以为每个输入指定包含和排除的行或文件，需要为每个输入配置选项。（include_lines, exclude_lines, and exclude_files options）</li><li>定义处理器（Processor）可以的导出的所有数据进行全局处理。</li></ol><p>可以在配置中定义处理器，在发送到输出之前处理所有事件。libbeat提供的处理器分为：</p><ul><li>减少导出字段</li><li>增加元数据增强事件</li><li>执行其他处理和解码</li></ul><p>每个处理器都接收一个事件，对该事件应用已定义的操作，然后返回该事件。如果定义处理器列表，则将按照在Filebeat配置文件中定义的顺序执行它们。<br>执行顺序：event -&gt; processor 1 -&gt; event1 -&gt; processor 2 -&gt; event2 …</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">processors:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">if:</span></span><br><span class="line">      <span class="string">&lt;condition&gt;</span></span><br><span class="line">    <span class="attr">then:</span> </span><br><span class="line">      <span class="bullet">-</span> <span class="string">&lt;processor_name&gt;:</span></span><br><span class="line">          <span class="string">&lt;parameters&gt;</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&lt;processor_name&gt;:</span></span><br><span class="line">          <span class="string">&lt;parameters&gt;</span></span><br><span class="line">      <span class="string">...</span></span><br><span class="line">    <span class="attr">else:</span> </span><br><span class="line">      <span class="bullet">-</span> <span class="string">&lt;processor_name&gt;:</span></span><br><span class="line">          <span class="string">&lt;parameters&gt;</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&lt;processor_name&gt;:</span></span><br><span class="line">          <span class="string">&lt;parameters&gt;</span></span><br><span class="line">      <span class="string">...</span></span><br></pre></td></tr></table></figure><ul><li><p>add_docker_metadata<br>使用来自Docker容器的相关元数据注释每个事件。包括（Container ID、Name、Image、Labels）</p></li><li><p>add_fields<br>将其他字段添加到事件中</p></li><li><p>add_host_metadata<br>为事件添加主机信息</p></li><li><p>add_id<br>为事件生成唯一的ID</p></li><li><p>add_labels<br>将一组键值对添加到事件</p></li><li><p>add_locale<br>通过将机器的时区偏离UTC或时区名称来丰富每个事件</p></li><li><p>add_tags<br>将标签添加到标签列表中</p></li><li><p>convert<br>将事件中的字段转换为其他类型，例如将字符串转换为整数。</p></li><li><p>copy_fields<br>将一个字段复制到另一个字段。</p></li><li><p>decode_base64_field<br>指定要对base64进行解码的字段</p></li><li><p>dissect<br>解剖处理器使用定义的模式对传入的字符串进行标记</p></li><li><p>drop_event<br>如果满足相关条件，则drop_event处理器将丢弃整个事件。条件是强制性的，因为没有一个条件，所有事件都将被丢弃</p></li><li><p>drop_fields<br>指定在满足特定条件时要删除的字段，条件是可选的。@timestamp和type字段在列表中，也不能删除他们。</p></li><li><p>fingerprint<br>根据事件字段的指定子集生成事件的指纹。</p></li><li><p>include_fields<br>指定在满足特定条件时要导出的字段，条件是可选的。@timestamp和type字段，也始终将其导出。</p></li><li><p>rename<br>指定要重命名的字段的列表。</p></li><li><p>script<br>执行Javascript代码以处理事件。该处理器使用ECMAScript 5.1的纯Go实现，并且没有外部依赖性。</p></li><li><p>timestamp<br>时间戳处理器从字段解析时间戳。默认情况下，时间戳处理器将已解析的结果写入@timestamp字段。</p></li><li><p>truncate_fields<br>将字段截断为给定的大小。如果字段的大小小于限制，则该字段将保持不变。</p></li><li><p>urldecode<br>指定要从URL编码格式解码的字段列表</p></li></ul>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;Filebeat介绍，包括工作方式、模块、如何避免数据重复、处理器的速查表。&lt;br&gt; 基于7.11版本。&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="技术" scheme="http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="ELK" scheme="http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/ELK/"/>
    
    
    <category term="技术" scheme="http://www.lights8080.com/tags/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="ELK" scheme="http://www.lights8080.com/tags/ELK/"/>
    
    <category term="Filebeat" scheme="http://www.lights8080.com/tags/Filebeat/"/>
    
  </entry>
  
  <entry>
    <title>ELK-加密通信的说明和配置教程</title>
    <link href="http://www.lights8080.com/2021/04/28/%E6%8A%80%E6%9C%AF/ELK/ELK-%E5%8A%A0%E5%AF%86%E9%80%9A%E4%BF%A1%E7%9A%84%E8%AF%B4%E6%98%8E%E5%92%8C%E9%85%8D%E7%BD%AE%E6%95%99%E7%A8%8B/"/>
    <id>http://www.lights8080.com/2021/04/28/%E6%8A%80%E6%9C%AF/ELK/ELK-%E5%8A%A0%E5%AF%86%E9%80%9A%E4%BF%A1%E7%9A%84%E8%AF%B4%E6%98%8E%E5%92%8C%E9%85%8D%E7%BD%AE%E6%95%99%E7%A8%8B/</id>
    <published>2021-04-28T03:27:15.000Z</published>
    <updated>2021-06-01T10:47:46.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>介绍Elasticsearch节点之间的加密通信、浏览器与Kibana之间的加密通信、Kibana与Elasticsearch之间的加密通信、操作步骤和配置说明。<br>基于7.11。</p></blockquote><span id="more"></span><h2 id="1-Elasticsearch加密通信"><a href="#1-Elasticsearch加密通信" class="headerlink" title="1 Elasticsearch加密通信"></a>1 Elasticsearch加密通信</h2><p>Elastic Stack安全特性能够加密加密往返于Elasticsearch集群以及从其内部的通信。使用传输层安全性(TLS/SSL)保护连接的安全。<br>未启用加密的群集将以纯文本格式（包括密码）发送所有数据。如果启用了Elasticsearch安全功能，除非您具有试用许可证，否则必须配置SSL/TLS进行节点间通信。</p><h3 id="1-1-Elasticsearch节点之间的加密通信"><a href="#1-1-Elasticsearch节点之间的加密通信" class="headerlink" title="1.1 Elasticsearch节点之间的加密通信"></a>1.1 Elasticsearch节点之间的加密通信</h3><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.11/configuring-tls.html#tls-transport">https://www.elastic.co/guide/en/elasticsearch/reference/7.11/configuring-tls.html#tls-transport</a></p><ul><li>Verify that the xpack.security.enabled setting is true.（启用安全功能）</li><li>Generate a private key and X.509 certificate.（生成私钥和X.509证书）</li><li>Configure each node to:<ul><li>Required: Enable TLS on the transport layer.（传输层启用TLS）</li><li>Recommended: Enable TLS on the HTTP layer.（HTTP层启用TLS）</li></ul></li></ul><h3 id="1-2-HTTP客户端的加密通信"><a href="#1-2-HTTP客户端的加密通信" class="headerlink" title="1.2 HTTP客户端的加密通信"></a>1.2 HTTP客户端的加密通信</h3><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.11/configuring-tls.html#tls-http">https://www.elastic.co/guide/en/elasticsearch/reference/7.11/configuring-tls.html#tls-http</a></p><ul><li>Generate node certificates.（生成节点证书）</li><li>Enable TLS and specify the information required to access the node’s certificate.（启用TLS并指定节点证书）</li><li>Restart Elasticsearch.（重启Elasticsearch）</li></ul><h2 id="2-Kibana通信加密"><a href="#2-Kibana通信加密" class="headerlink" title="2 Kibana通信加密"></a>2 Kibana通信加密</h2><p>传输层安全安全协议(SSL)和传输层安全协议(TLS)为数据传输提供加密。虽然这些术语通常可以互换使用，但 Kibana 只支持 TLS，它取代了旧的 SSL 协议。<br>浏览器将流量发送到 Kibana，Kibana 将流量发送到 Elasticsearch，这些通信通道分别配置为使用 TLS。</p><h3 id="2-1-浏览器与Kibana之间的加密通信"><a href="#2-1-浏览器与Kibana之间的加密通信" class="headerlink" title="2.1 浏览器与Kibana之间的加密通信"></a>2.1 浏览器与Kibana之间的加密通信</h3><p><a href="https://www.elastic.co/guide/en/kibana/7.11/configuring-tls.html#configuring-tls-browser-kib">https://www.elastic.co/guide/en/kibana/7.11/configuring-tls.html#configuring-tls-browser-kib</a></p><ol><li>获得 Kibana 的服务器证书和私钥</li><li>配置 Kibana 以访问服务器证书和私钥</li><li>将 Kibana 配置为为入站连接启用 TLS</li><li>重启 Kibana</li></ol><h3 id="2-2-Kibana与Elasticsearch之间的加密通信"><a href="#2-2-Kibana与Elasticsearch之间的加密通信" class="headerlink" title="2.2 Kibana与Elasticsearch之间的加密通信"></a>2.2 Kibana与Elasticsearch之间的加密通信</h3><p><a href="https://www.elastic.co/guide/en/kibana/7.11/configuring-tls.html#configuring-tls-kib-es">https://www.elastic.co/guide/en/kibana/7.11/configuring-tls.html#configuring-tls-kib-es</a></p><ul><li>Enable TLS on the HTTP layer in Elasticsearch.（在Elasticsearch的HTTP层上启动TLS）</li><li>Obtain the certificate authority (CA) certificate chain for Elasticsearch.（获取Elasticsearch的证书颁发机构(CA)证书链）<ul><li>used the elasticsearch-certutil http command,include the CA certificate chain in PEM format.（使用elasticsearch-certutil http命令生成CA证书链）</li><li>extract the CA certificate.（通过PKCS#12文件提取CA证书链）</li></ul></li><li>Configure Kibana to trust the Elasticsearch CA certificate chain for the HTTP layer.（配置Kibana以信任HTTP层的Elasticsearch CA证书链）</li><li>Configure Kibana to enable TLS for outbound connections to Elasticsearch.（配置Kibana与Elasticsearch的连接启用TLS）</li></ul><h2 id="3-操作步骤"><a href="#3-操作步骤" class="headerlink" title="3 操作步骤"></a>3 操作步骤</h2><ol><li><p>操作命令</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 进入Elasticsearch目录</span></span><br><span class="line">cd /data/elk/elasticsearch-7.11.2</span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建证书颁发机构：获得文件：elastic-stack-ca.p12</span></span><br><span class="line">./bin/elasticsearch-certutil ca</span><br><span class="line"><span class="meta">#</span><span class="bash"> 为每个节点生成证书和私钥，获得文件：elastic-certificates.p12</span></span><br><span class="line">./bin/elasticsearch-certutil cert --ca elastic-stack-ca.p12</span><br><span class="line"><span class="meta">#</span><span class="bash"> 生成专门用于加密HTTP客户端通信的证书，获得文件：elasticsearch-ssl-http.zip</span></span><br><span class="line">./bin/elasticsearch-certutil http</span><br><span class="line"><span class="meta">#</span><span class="bash"> 解压HTTP通信证书，获得文件：elasticsearch/http.p12和kibana/elasticsearch-ca.pem</span></span><br><span class="line">unzip elasticsearch-ssl-http.zip</span><br><span class="line"><span class="meta">#</span><span class="bash"> 在每个Elasticsearch节点的配置目录中创建一个文件夹certs，放置安全证书</span></span><br><span class="line">mkdir /data/elk/elasticsearch-7.11.2/config/certs</span><br><span class="line">cp elastic-certificates.p12 config/certs</span><br><span class="line">cp elasticsearch/http.p12 config/certs</span><br><span class="line"><span class="meta">#</span><span class="bash"> 复制HTTP通信证书到Kibana配置目录</span></span><br><span class="line">cp kibana/elasticsearch-ca.pem /data/elk/kibana-7.11.2/config</span><br></pre></td></tr></table></figure></li><li><p>生成加密HTTP客户端通信证书说明（./bin/elasticsearch-certutil http）<br>参考：<a href="https://lights8080.github.io/post/es-an-quan-security">https://lights8080.github.io/post/es-an-quan-security</a></p></li></ol><h2 id="4-参数配置"><a href="#4-参数配置" class="headerlink" title="4 参数配置"></a>4 参数配置</h2><ol><li><p>Elasticsearch<br>elasticsearch-7.11.2/config/elasticsearch.yml</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在节点上启用Elasticsearch安全功能</span></span><br><span class="line"><span class="attr">xpack.security.enabled:</span> <span class="literal">true</span></span><br><span class="line"><span class="comment"># 节点间加密通信配置</span></span><br><span class="line"><span class="attr">xpack.security.transport.ssl.enabled:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">xpack.security.transport.ssl.verification_mode:</span> <span class="string">certificate</span> </span><br><span class="line"><span class="attr">xpack.security.transport.ssl.keystore.path:</span> <span class="string">elastic-certificates.p12</span> </span><br><span class="line"><span class="attr">xpack.security.transport.ssl.truststore.path:</span> <span class="string">elastic-certificates.p12</span> </span><br><span class="line"><span class="comment"># HTTP加密通信配置</span></span><br><span class="line"><span class="attr">xpack.security.http.ssl.enabled:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">xpack.security.http.ssl.keystore.path:</span> <span class="string">&quot;certs/http.p12&quot;</span></span><br></pre></td></tr></table></figure></li><li><p>Kibana<br>kibana-7.11.2/config/kibana.yml</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 配置Kibana与Elasticsearch的连接启用TLS</span></span><br><span class="line"><span class="attr">elasticsearch.hosts:</span> [<span class="string">&quot;https://127.0.0.1:9200&quot;</span>]</span><br><span class="line"><span class="comment"># 配置信任HTTP层的Elasticsearch CA证书链</span></span><br><span class="line"><span class="attr">elasticsearch.ssl.certificateAuthorities:</span> [<span class="string">&quot;/data/elk/kibana-7.11.2/config/elasticsearch-ca.pem&quot;</span>]</span><br></pre></td></tr></table></figure></li><li><p>Logstash<br>logstash-7.11.2/config/logstash-sample.conf</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">output &#123;</span><br><span class="line">    elasticsearch &#123;</span><br><span class="line">            hosts =&gt; [&quot;https://127.0.0.1:9200&quot;]</span><br><span class="line">            user =&gt; &quot;elastic&quot;</span><br><span class="line">            password =&gt; &quot;xxxxxx&quot;</span><br><span class="line">            cacert =&gt; &quot;/data/elk/elasticsearch-7.11.2/config/certs/elasticsearch-ca.pem&quot;</span><br><span class="line">     &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Metricbeat<br>metricbeat-7.11.2/modules.d/elasticsearch-xpack.yml</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">- module: elasticsearch</span><br><span class="line">  xpack.enabled: true</span><br><span class="line">  period: 10s</span><br><span class="line">  hosts: [&quot;https://127.0.0.1:9200&quot;]</span><br><span class="line">  username: &quot;elastic&quot;</span><br><span class="line">  password: &quot;xxxxxx&quot;</span><br><span class="line">  ssl.certificate_authorities: [&quot;/data/elk/elasticsearch-7.11.2/config/certs/elasticsearch-ca.pem&quot;]</span><br></pre></td></tr></table></figure></li><li><p>其他Elastic产品使用加密通信<br>略</p></li></ol>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;介绍Elasticsearch节点之间的加密通信、浏览器与Kibana之间的加密通信、Kibana与Elasticsearch之间的加密通信、操作步骤和配置说明。&lt;br&gt;基于7.11。&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="技术" scheme="http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="ELK" scheme="http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/ELK/"/>
    
    
    <category term="技术" scheme="http://www.lights8080.com/tags/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="ELK" scheme="http://www.lights8080.com/tags/ELK/"/>
    
  </entry>
  
  <entry>
    <title>Elasticsearch-安全特性（Security）</title>
    <link href="http://www.lights8080.com/2021/04/27/%E6%8A%80%E6%9C%AF/ELK/Elasticsearch-%E5%AE%89%E5%85%A8%E7%89%B9%E6%80%A7%EF%BC%88Security%EF%BC%89/"/>
    <id>http://www.lights8080.com/2021/04/27/%E6%8A%80%E6%9C%AF/ELK/Elasticsearch-%E5%AE%89%E5%85%A8%E7%89%B9%E6%80%A7%EF%BC%88Security%EF%BC%89/</id>
    <published>2021-04-27T03:27:15.000Z</published>
    <updated>2021-06-01T10:47:46.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Elasticsearch安全特性，介绍加密通讯的基本原理、开启安全特性的操作步骤、如何生成节点证书、用户认证和相关概念等。<br> 基于7.11版本。</p></blockquote><span id="more"></span><h2 id="一、安全特性"><a href="#一、安全特性" class="headerlink" title="一、安全特性"></a>一、安全特性</h2><p>Elastic Stack安全功能使您可以轻松保护集群。</p><p>Elasticsearch集群保护方式：</p><ul><li>通过密码保护，基于角色的访问控制和IP过滤防止未经授权的访问。</li><li>使用SSL/TLS加密保留数据的完整性。</li><li>维护审计跟踪，知道谁在对集群进行操作</li></ul><p>Elasticsearch配置安全的简易步骤：</p><ol><li>集群内每个节点设置为<code>xpack.security.enabled: true</code></li><li>为节点间通信配置TLS/SSL【#加密通讯】</li><li>启动Elasticsearch</li><li>设置内置用户和密码（命令：<code>elasticsearch-setup-passwords auto</code>）</li><li>设置角色和用户，控制对Elasticsearch的访问</li><li>(可选)启用审计功能<code>xpack.security.audit.enabled: true</code>，并重启集群</li></ol><h3 id="1-加密通讯"><a href="#1-加密通讯" class="headerlink" title="1 加密通讯"></a>1 加密通讯</h3><blockquote><p>未启用加密的群集将以纯文本格式（包括密码）发送所有数据。如果启用了Elasticsearch安全功能，除非您具有试用许可证，否则必须配置SSL/TLS进行节点间通信。</p></blockquote><ul><li>Elasticsearch集群节点间通信使用SSL/TLS加密，保护节点安全有助于降低基于网络的攻击的风险</li><li>要求节点使用SSL证书添加到集群时进行身份验证，新节点的身份验证有助于防止流氓节点加入群集并通过复制接收数据</li></ul><p>Elasticsearch集群配置STL</p><ol><li>为每个Elasticsearch节点生成一个私钥和X.509证书【#1.3 生成节点证书】</li><li>在集群中配置每个节点，以使用其签名证书标识自己，并在传输层上启用TLS。还可以选择在HTTP层上启用TLS</li><li>配置Kibana以加密浏览器和Kibana服务器之间的通信，并通过HTTPS连接到Elasticsearch</li><li>配置其他Elastic产品使用加密通信</li></ol><h4 id="1-1-加密集群中节点之间的通信"><a href="#1-1-加密集群中节点之间的通信" class="headerlink" title="1.1 加密集群中节点之间的通信"></a>1.1 加密集群中节点之间的通信</h4><ol><li>生成节点证书【#1.3 生成节点证书】</li><li>启用TLS并制定访问节点证书所需要的信息<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">xpack.security.transport.ssl.enabled:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">xpack.security.transport.ssl.verification_mode:</span> <span class="string">certificate</span></span><br><span class="line"><span class="attr">xpack.security.transport.ssl.keystore.path:</span> <span class="string">elastic-certificates.p12</span></span><br><span class="line"><span class="attr">xpack.security.transport.ssl.truststore.path:</span> <span class="string">elastic-certificates.p12</span></span><br></pre></td></tr></table></figure></li><li>（可选）如果你用密码保护节点的证书，将密码添加到 Elasticsearch 密钥存储库</li><li>重启Elasticsearch</li></ol><h4 id="1-2-加密HTTP客户端通信"><a href="#1-2-加密HTTP客户端通信" class="headerlink" title="1.2 加密HTTP客户端通信"></a>1.2 加密HTTP客户端通信</h4><ol><li>生成HTTP证书【#1.3 生成节点证书】</li><li>启用TLS并制定访问节点证书所需要的信息<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">xpack.security.http.ssl.enabled:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">xpack.security.http.ssl.keystore.path:</span> <span class="string">&quot;http.p12&quot;</span></span><br></pre></td></tr></table></figure></li><li>（可选）如果你用密码保护节点的证书，将密码添加到 Elasticsearch 密钥存储库</li><li>重启Elasticsearch</li></ol><h4 id="1-3-生成节点证书"><a href="#1-3-生成节点证书" class="headerlink" title="1.3 生成节点证书"></a>1.3 生成节点证书</h4><ol><li>（可选）为 Elasticsearch 集群创建一个证书颁发机构。</li></ol><p><code>./bin/elasticsearch-certutil ca</code><br>输出文件是一个PKCS#12密钥存储库，其中包含证书颁发机构的公共证书和用于签署节点证书的私钥。</p><ol start="2"><li><p>为集群中的每个节点生成证书和私钥<br>交互形式：<br><code>./bin/elasticsearch-certutil cert --ca elastic-stack-ca.p12</code><br>命令形式：<br><code>./bin/elasticsearch-certutil cert --ca elastic-stack-ca.p12 --dns localhost --ip 127.0.0.1,::1 --out config/certs/node-1.p12</code><br>输出是一个包含节点证书、节点密钥和CA证书的PKCS#12密钥存储库。</p></li><li><p>（可选）生成专门用于加密 HTTP 客户端通信的附加证书。</p></li></ol><p><code>./bin/elasticsearch-certutil http</code><br>命令步骤如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># Do you wish to generate a Certificate Signing Request (CSR)? - 是否生成证书签名请求(CSR)?</span></span></span><br><span class="line">Generate a CSR? [y/N]N</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># Do you have an existing Certificate Authority (CA) key-pair that you wish to use to sign your certificate? -是否有一个现有的证书颁发机构(CA)密钥对，您希望使用它来签署证书?</span></span></span><br><span class="line">Use an existing CA? [y/N]y</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># What is the path to your CA? - 你的CA路径在哪里?</span></span></span><br><span class="line">CA Path: /data/elk/elasticsearch-7.11.2/elastic-stack-ca.p12</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># How long should your certificates be valid? - 您的证书应该多长时间有效?</span></span></span><br><span class="line">For how long should your certificate be valid? [5y] 3Y</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># Do you wish to generate one certificate per node? - 是否希望每个节点生成一个证书?</span></span></span><br><span class="line">Generate a certificate per node? [y/N]N</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># Which hostnames will be used to connect to your nodes? - 哪些主机名将用于连接到您的节点?</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">## Enter all the hostnames that you need, one per line. - 输入需要的所有主机名，每行一个。</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">## When you are done, press &lt;ENTER&gt; once more to move on to the next step. - 完成后，再次按&lt;ENTER&gt;继续下一步。</span></span></span><br><span class="line"></span><br><span class="line">Is this correct [Y/n]Y</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># Which IP addresses will be used to connect to your nodes? - 哪些IP地址将用于连接到您的节点?</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">## Enter all the IP addresses that you need, one per line.</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">## When you are done, press &lt;ENTER&gt; once more to move on to the next step.</span></span></span><br><span class="line"></span><br><span class="line">Is this correct [Y/n]Y</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># Other certificate options - 其他证书选项</span></span></span><br><span class="line">Do you wish to change any of these options? [y/N]N</span><br><span class="line">输出是一个.zip 文件，包含 Elasticsearch 和 Kibana 各自的一个目录</span><br></pre></td></tr></table></figure><p>输出文件elasticsearch-ssl-http.zip</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">/elasticsearch</span><br><span class="line">|_ README.txt</span><br><span class="line">|_ http.p12</span><br><span class="line">|_ sample-elasticsearch.yml</span><br><span class="line"></span><br><span class="line">/kibana</span><br><span class="line">|_ README.txt</span><br><span class="line">|_ elasticsearch-ca.pem</span><br><span class="line">|_ sample-kibana.yml</span><br></pre></td></tr></table></figure><ol start="4"><li>将节点证书复制到适当的位置</li></ol><ul><li>在每个Elasticsearch节点上的配置目录中创建文件夹certs。如：/home/es/config/certs。</li><li>在每个节点上，将创建的证书复制到certs目录（通常是一个.p12文件）</li><li>如果生成了HTTP证书，复制http.p12到certs目录</li><li>配置其他Elastic产品，将证书复制到相关目录</li></ul><h3 id="2-用户认证"><a href="#2-用户认证" class="headerlink" title="2 用户认证"></a>2 用户认证</h3><p>安全功能提供了基于角色的访问控制（RBAC）机制，该机制使您可以通过为角色分配特权并将角色分配给用户或组来授权用户。<br>安全功能还提供了基于属性的访问控制（ABAC）机制，使您可以使用属性来限制对搜索查询和聚合中文档的访问。</p><p>role-based access control (RBAC) </p><ul><li>Secured Resource（访问受限的资源）：索引，别名，文档，字段，用户和Elasticsearch群集本身都是受保护对象。</li><li>Privilege（特权）：对受保护的资源执行的一个或多个动作的命名组，如read是索引特权，代表所有启用读取已索引/存储的数据的操作。</li><li>Permissions（权限）：针对受保护资源的一组一个或多个特权，权限可以很容易地用语言来描述。</li><li>Role（角色）：一组命名的权限</li><li>User（用户）：经过身份验证的用户</li><li>Group（用户组）：用户所属的一个或多个组</li></ul><p>内置用户</p><ul><li>这些内置用户存储在指定的.security索引中，由Elasticsearch管理。</li><li>elasticsearch-setup-passwords工具是首次设置内置用户密码的最简单方法</li></ul><p>基于令牌的身份验证</p><ul><li>token-service：访问令牌（根据OAuth2规范生成访问令牌和刷新令牌）是短期令牌，默认情况下20分钟后过期。（Authorization: Bearer xxx）</li><li>api-key-service：API秘钥，默认情况下API密钥不会过期，创建时，可以指定到期时间和权限。（Authorization: ApiKey xxx）</li></ul><h2 id="二、相关概念"><a href="#二、相关概念" class="headerlink" title="二、相关概念"></a>二、相关概念</h2><ul><li>SSL（Secure Socket Layer)/TLS(Transport Layer Security）</li><li>数字证书：互联网通讯中标志通讯各方身份信息的一系列数据</li><li>X.509：是一种数字证书（Public Key Certificates）的格式标准，主要定义了证书中应该包含哪些内容。<ul><li>HTTPS依赖的TLS/SSL证书使用的就是使用的X.509格式。一个X.509 Certificate包含一个Public Key和一个身份信息（a hostname, or an organization, or an individual），它要么是被CA签发的要么是自签发的。</li></ul></li><li>CA（Certificate Authority）：颁发数字证书的权威机构，承担公钥体系中公钥的合法性检验的责任。</li><li>编码格式：用来存储和发送公钥/私钥、证书和其他数据的文件格式；分为DER和PEM<ul><li>DER（Distinguished Encoding Rules）：二进制不可读，常用于Windows系统</li><li>PEM（Privacy-Enhanced Mail）：内容是BASE64编码，常用于*NIX系统</li></ul></li><li>PKCS（Public Key Cryptography Standards）：公钥密码学标准<ul><li>PKCS#12：描述个人信息交换语法标准，通常用来存储Private Keys和Public Key Certificates（例如前面提到的X.509）的文件格式，使用基于密码的对称密钥进行保护。</li></ul></li></ul><h2 id="三、参考文档"><a href="#三、参考文档" class="headerlink" title="三、参考文档"></a>三、参考文档</h2><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.11/secure-cluster.html">安全集群</a><br><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.11/configuring-tls.html#configuring-tls">加密通讯</a></p>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;Elasticsearch安全特性，介绍加密通讯的基本原理、开启安全特性的操作步骤、如何生成节点证书、用户认证和相关概念等。&lt;br&gt; 基于7.11版本。&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="技术" scheme="http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="ELK" scheme="http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/ELK/"/>
    
    
    <category term="技术" scheme="http://www.lights8080.com/tags/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="ELK" scheme="http://www.lights8080.com/tags/ELK/"/>
    
    <category term="Elasticsearch" scheme="http://www.lights8080.com/tags/Elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>Elasticsearch-聚合（Aggregations）</title>
    <link href="http://www.lights8080.com/2021/04/25/%E6%8A%80%E6%9C%AF/ELK/Elasticsearch-%E8%81%9A%E5%90%88%EF%BC%88Aggregations%EF%BC%89/"/>
    <id>http://www.lights8080.com/2021/04/25/%E6%8A%80%E6%9C%AF/ELK/Elasticsearch-%E8%81%9A%E5%90%88%EF%BC%88Aggregations%EF%BC%89/</id>
    <published>2021-04-25T03:27:15.000Z</published>
    <updated>2021-06-01T10:47:46.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Elasticsearch聚合速查表，介绍指标聚合、桶分聚合、管道聚合的分类和聚合示例。<br> 基于7.11版本。</p></blockquote><span id="more"></span><p>聚合将数据汇总为指标, 统计, 或其他分析。</p><h2 id="聚合分类"><a href="#聚合分类" class="headerlink" title="聚合分类"></a>聚合分类</h2><ul><li>Metric：指标聚合，从文档字段值中计算指标，如总和、平均值等</li><li>Bucket：桶分聚合，根据字段值、范围或其他条件将文档分组为桶</li><li>Pipeline：管道聚合，从其他的聚合结果作为输入</li></ul><h3 id="Bucket"><a href="#Bucket" class="headerlink" title="Bucket"></a>Bucket</h3><ul><li>Adjacency matrix：邻接矩阵，获取矩阵每个组的计数</li><li>Auto-interval date histogram：时间柱状图，根据桶的数量自动的选择桶的间隔</li><li>Children：子聚合，如：join field</li><li>Composite：多存储桶聚合，类似于多字段分组</li><li>Date histogram：日期柱状图，可以按日历感知时间间隔（如：day，week，houth）和固定时间间隔。</li><li>Date range：时间范围聚合，from：从大于等于某个时间，to：到小于某个时间</li><li>Filter：过滤器聚合，将当前的聚合的上下文缩小到一组特定文档。在当前聚合上应用过滤，不影响其他聚合器。</li><li>Filters：多桶过滤器聚合，每个桶都与一个过滤器相关联</li><li>Geo-distance：地理距离聚合，工作在geo_point字段上，定义一个原点或一组距离范围的桶，评估落在每个桶的文档。</li><li>Geo hash grid：网格聚合，每个单元格使用自定义精度的geohash进行标记，geohash可以在1~12之间选择精度</li><li>Geotile grid：网格聚合，每个单元格对应许多在线地图的图块，使用{zoom}/{x}/{y}标记</li><li>Global：在搜索的上下文中定义一个，不受搜索影响的上下文进行聚合。与Filter对应</li><li>Histogram：柱状图聚合，指定间隔，返回落在间隔内的文档数</li><li>IP range：IP类型字段的范围聚合</li><li>Missing：NULL字段聚合</li><li>Nested：嵌套文档聚合</li><li>Parent：父文档聚合</li><li>Range：范围聚合，定义一组范围，每组范围代表一个桶</li><li>Rare terms：稀少（长期分布但不频繁的项）的术语聚合</li><li>Reverse nested：在嵌套聚合内定义聚合父文档</li><li>Sampler：采样器聚合，将聚合的文档限制在得分最高的文档上，降低繁重缓慢的聚合成本。shard_size：限制在每个分片上使用得分最高的文档数</li><li>Diversified sampler：多样化采集聚合，采用多样化的设置进行抽样可以提供一种方法来消除内容偏差</li><li>Terms：动态桶聚合。结果是近似值，可以通过size、shard_size来控制其精度。对标关系数据库中的group by。size：定义返回桶的数；shard_size：每个分片使用文档样本数</li><li>Significant terms：显著的关键词聚合，通过background sets（背景集合）对比聚合数据。通常使用整个索引库内容当做背景集合，可以通过background_filter设置。</li><li>Significant text：显著的文本聚合，像Significant terms一样，区别是作用在text字段</li><li>Variable width histogram：动态的宽度柱状图聚合，定义桶数，动态确定桶间隔。</li><li>Subtleties of bucketing range fields：范围字段导致桶数大于文档数</li></ul><h3 id="Metric"><a href="#Metric" class="headerlink" title="Metric"></a>Metric</h3><ul><li>Avg：计算平均值，单值的指标聚合，提取文档的数值型字段或提供的脚本。</li><li>Min：计算最小值，histogram fields时，返回values中的最小值</li><li>Max：计算最大值</li><li>Sum：计算总和</li><li>Boxplot：盒型图，返回最大值、最小值、25%、50%和75%的值。常用语响应时间的分析</li><li>Cardinality：去重求和，计算不同值的近似计数，可以从文档中的特定字段提取值，也可以通过脚本</li><li>stats：统计信息，多值的指标聚合，可以从文档中的特定字段提取值，也可以通过脚本<ul><li>status: min, max, sum, count and avg</li><li>string stats: count, min_length, max_length, avg_length, entropy</li><li>extended stats: sum_of_squares, variance, std_deviation</li></ul></li><li>geo：地图<ul><li>geo bounds: 地理边界聚合</li><li>geo centroid: 地理重心聚合</li></ul></li><li>Median absolute deviation：中位数绝对偏差，更可靠的统计信息，可以减少异常值对于数据集的影响。</li><li>Percentile rank：百分比等级，显示低于特定值的百分比。如：显示web服务加载时间的占比</li><li>Percentiles：百分位的值，显示出现百分位观察值的点，percents指定返回的百分位。如：显示大于观察值95%的值</li><li>Scripted metric：使用脚本执行获取指标</li><li>Value count：去重计数</li><li>Weighted avg：带权重的平均值</li></ul><h3 id="Pipeline"><a href="#Pipeline" class="headerlink" title="Pipeline"></a>Pipeline</h3><ul><li>Avg bucket：【sibling pipeline aggs】，计算平均值</li><li>max bucket：【sibling pipeline aggs】，计算最大值</li><li>min bucket：【sibling pipeline aggs】，计算最小值</li><li>sum bucket：【sibling pipeline aggs】，计算总和</li><li>bucket script：【parent pipeline aggs】，脚本计算</li><li>bucket selector：【parent pipeline aggs】，桶过滤</li><li>bucket sort：【parent pipeline aggs】，桶排序</li><li>cumulative cardinality：累积基数，此值显示自查询时间段开始以来总的计数，也可显示增量的计数。如：每天网站的新访问者新增数量。</li><li>cumulative sum：累积总和，此值显示自查询时间段开始以来累积总和。如：月销售额的累积总和。</li><li>derivative：柱状图导数计算</li><li>stats bucket：【sibling pipeline aggs】，统计信息，包括min, max, sum, count and avg</li><li>extended stats bucket：【sibling pipeline aggs】扩展的统计信息，包括平方和、标准差等</li><li>inference bucket：【parent pipeline aggs】，训练模型推断</li><li>moving average：滑动窗口平均值</li><li>moving function：滑动窗口上自定义函数</li><li>moving percentiles：基于百分位的滑动窗口</li><li>normalize：计算标准的数学值</li><li>percentiles bucket：计算桶的百分位的值</li><li>serial differencing：时间序列差值</li></ul><h3 id="示例1：聚合、分组"><a href="#示例1：聚合、分组" class="headerlink" title="示例1：聚合、分组"></a>示例1：聚合、分组</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line">GET /bank/_search</span><br><span class="line">&#123;</span><br><span class="line">  # 仅返回聚合结果，不需要搜索结果的内容</span><br><span class="line">  &quot;size&quot;: 0,</span><br><span class="line">  &quot;aggs&quot;: &#123;</span><br><span class="line">    # 单列分组统计，sql: select sum(balance) as sum_balance,avg(balance) as avg_balance from bank group by state.keyword limit 10;</span><br><span class="line">    &quot;group_by_state&quot;: &#123;</span><br><span class="line">      # 定义桶的类型</span><br><span class="line">      &quot;terms&quot;: &#123;</span><br><span class="line">        &quot;field&quot;: &quot;state.keyword&quot;</span><br><span class="line">      &#125;,</span><br><span class="line">      # 添加自定义Mata信息</span><br><span class="line">      &quot;meta&quot;: &#123;</span><br><span class="line">        &quot;my-metadata-field&quot;: &quot;foo&quot;</span><br><span class="line">      &#125;</span><br><span class="line">      # 子聚合</span><br><span class="line">      &quot;aggs&quot;: &#123;</span><br><span class="line">        &quot;avg_balance&quot;: &#123;</span><br><span class="line">          &quot;avg&quot;: &#123;</span><br><span class="line">            &quot;field&quot;: &quot;balance&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;sum_balance&quot;: &#123;</span><br><span class="line">          &quot;sum&quot;: &#123;</span><br><span class="line">            &quot;field&quot;: &quot;balance&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    # 多列分组统计 sql: select sum(balance) as sum_balance from bank group by state.keyword, gender.keyword limit 50;</span><br><span class="line">    &quot;group_by_fields&quot;: &#123;</span><br><span class="line">      &quot;composite&quot;:&#123;</span><br><span class="line">        &quot;sources&quot;: [</span><br><span class="line">          &#123;</span><br><span class="line">            &quot;state&quot;: &#123;</span><br><span class="line">              &quot;terms&quot;: &#123;</span><br><span class="line">                &quot;field&quot;: &quot;state.keyword&quot;</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;,&#123;</span><br><span class="line">            &quot;gender&quot;: &#123;</span><br><span class="line">              &quot;terms&quot;: &#123;</span><br><span class="line">                &quot;field&quot;: &quot;gender.keyword&quot;</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        ],</span><br><span class="line">        # 查询记录数，默认10条</span><br><span class="line">        &quot;size&quot;: 50</span><br><span class="line">      &#125;,</span><br><span class="line">      # 子聚合</span><br><span class="line">      &quot;aggs&quot;: &#123;</span><br><span class="line">        &quot;sum_balance&quot;: &#123;</span><br><span class="line">          &quot;sum&quot;: &#123;</span><br><span class="line">            &quot;field&quot;: &quot;balance&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  # 聚合后置过滤器，对聚合结果无影响</span><br><span class="line">  &quot;post_filter&quot;: &#123; </span><br><span class="line">    &quot;term&quot;: &#123; &quot;color&quot;: &quot;red&quot; &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="示例2：条件过滤，多列分组、排序、分页"><a href="#示例2：条件过滤，多列分组、排序、分页" class="headerlink" title="示例2：条件过滤，多列分组、排序、分页"></a>示例2：条件过滤，多列分组、排序、分页</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line">GET /unififi-order/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;size&quot;: 0,</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;range&quot;: &#123;</span><br><span class="line">      &quot;gmtCreate&quot;: &#123;</span><br><span class="line">        &quot;gte&quot;: &quot;2021-05-06 00:00:00&quot;,</span><br><span class="line">        &quot;lte&quot;: &quot;2021-05-06 23:59:59&quot;,</span><br><span class="line">        &quot;format&quot;: &quot;yyyy-MM-dd HH:mm:ss&quot;,</span><br><span class="line">        &quot;time_zone&quot;:&quot;+08:00&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;aggs&quot;: &#123;</span><br><span class="line">    &quot;group_by_fields&quot;: &#123;</span><br><span class="line">      &quot;composite&quot;:&#123;</span><br><span class="line">        &quot;sources&quot;: [</span><br><span class="line">          &#123;</span><br><span class="line">            &quot;supplierCid&quot;: &#123;</span><br><span class="line">              &quot;terms&quot;: &#123;</span><br><span class="line">                &quot;field&quot;: &quot;supplierCid&quot;</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;,&#123;</span><br><span class="line">            &quot;ipcc&quot;: &#123;</span><br><span class="line">              &quot;terms&quot;: &#123;</span><br><span class="line">                &quot;field&quot;: &quot;ipcc&quot;</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        ],</span><br><span class="line">        &quot;size&quot;: 50</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;aggs&quot;: &#123;</span><br><span class="line">        &quot;sum_totalApiAmount&quot;: &#123;</span><br><span class="line">          &quot;sum&quot;: &#123;</span><br><span class="line">            &quot;field&quot;: &quot;totalApiAmount&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;order_count&quot;: &#123;</span><br><span class="line">          &quot;value_count&quot;: &#123;</span><br><span class="line">            &quot;field&quot;: &quot;id&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;sales_bucket_sort&quot;: &#123;</span><br><span class="line">          &quot;bucket_sort&quot;: &#123;</span><br><span class="line">            &quot;sort&quot;: [</span><br><span class="line">              &#123; &quot;order_count&quot;: &#123; &quot;order&quot;: &quot;asc&quot; &#125; &#125;</span><br><span class="line">            ],</span><br><span class="line">            &quot;from&quot;: 0, </span><br><span class="line">            &quot;size&quot;: 10</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;Elasticsearch聚合速查表，介绍指标聚合、桶分聚合、管道聚合的分类和聚合示例。&lt;br&gt; 基于7.11版本。&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="技术" scheme="http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="ELK" scheme="http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/ELK/"/>
    
    
    <category term="技术" scheme="http://www.lights8080.com/tags/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="ELK" scheme="http://www.lights8080.com/tags/ELK/"/>
    
    <category term="Elasticsearch" scheme="http://www.lights8080.com/tags/Elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>语录-3</title>
    <link href="http://www.lights8080.com/2021/04/16/%E8%AF%AD%E5%BD%95/%E8%AF%AD%E5%BD%95-3/"/>
    <id>http://www.lights8080.com/2021/04/16/%E8%AF%AD%E5%BD%95/%E8%AF%AD%E5%BD%95-3/</id>
    <published>2021-04-15T16:00:00.000Z</published>
    <updated>2021-06-01T10:47:46.000Z</updated>
    
    <content type="html"><![CDATA[<ol><li>五只猴子的故事</li><li>任正非在一次座谈会上谈加强项目财务的有效管理</li><li>眼镜蛇效应</li><li>能源效率的诅咒</li></ol><span id="more"></span><p>“ 分享几个小故事，都是从“阮一峰的网络日志”中读到。”</p><h2 id="1-五只猴子的故事"><a href="#1-五只猴子的故事" class="headerlink" title="1. 五只猴子的故事"></a>1. 五只猴子的故事</h2><p>科学家在笼子里放了五只猴子。笼子中间有一架梯子，梯子上面放着香蕉。<br>每当一只猴子爬上梯子，科学家就用冷水泼洒其余的猴子。过了一阵子，只要一只猴子爬上梯子，其他猴子就会殴打它。一段时间后，所有猴子都不敢爬上梯子。<br>然后，科学家用一只新猴子，替换了原来的一只猴子，并且停止用冷水泼洒猴子。这只新猴子立即爬楼梯去拿香蕉，但随即遭到其他猴子的殴打。经过几次殴打，新猴子学会了不爬梯子，即使它从来不知道为什么。<br>接着，替换了第二只猴子，也发生了同样的事情。刚才放进笼子的那只猴子，同样殴打了新来的猴子。替换了第三只猴子，也是如此。就这样，第四只、第五只猴子也接连被替换了。<br>最终，笼子里面的五只猴子，尽管从未被泼冷水，仍然继续殴打任何试图爬上梯子的猴子。<br>​</p><h2 id="2-任正非在一次座谈会上谈加强项目财务的有效管理"><a href="#2-任正非在一次座谈会上谈加强项目财务的有效管理" class="headerlink" title="2. 任正非在一次座谈会上谈加强项目财务的有效管理"></a>2. 任正非在一次座谈会上谈加强项目财务的有效管理</h2><p>任正非：我在越南提出一个问题，百年一遇的台风，把爱立信的铁塔吹倒了，诺基亚的铁塔也吹倒了，就我们的铁塔没有倒，我请问你这个财务人员，如何评价？</p><p>杜仲夏：这说明对成本管理并没有做好，这说明项目存在过度交付的问题。就像飞利浦的灯泡，只有两年寿命，用了两年刚好坏掉，这就是最好的产品。如果客户只付了两年灯泡的钱，但是我们保证10年的寿命，只能说明我们不懂经营。</p><p>任正非：但是我们当年考市场人员和财务人员的时候，每个人都充满了自豪感，你看，诺基亚和爱立信的铁塔都倒了，就我们没倒，华为的水平多高啊！华为公司的铁塔只有一个标准，在永远不会有台风的沙漠里，装的也是这种铁塔。我们僵化地制定了太高的标准，为此我们每年多浪费了10万到20万吨钢铁。所以，我们今天必须加强项目财务的有效管理，我想三五年后我们一定会看到有结果。</p><h2 id="3-眼镜蛇效应"><a href="#3-眼镜蛇效应" class="headerlink" title="3. 眼镜蛇效应"></a>3. 眼镜蛇效应</h2><p>眼镜蛇效应一词来自殖民时期的印度：英国政府计划要减少眼镜蛇的数量，因而颁布法令说每打死一条眼镜蛇都可以领取赏金。然而印度人为了赏金反而开始养殖眼镜蛇。当英国政府意识到这种情况而取消赏金后，养殖蛇的人把蛇都放了；放出去的蛇继而大量繁殖，结果眼镜蛇族群数量不減反增。</p><h2 id="4-能源效率的诅咒"><a href="#4-能源效率的诅咒" class="headerlink" title="4. 能源效率的诅咒"></a>4. 能源效率的诅咒</h2><p>我们为了降低能源消耗，发明了节省能源的 LED 照明。结果，更高效的照明导致了更多的照明，从而使得社会整体能源消耗增加。<br>很多事情都是这样，为了省电，我们提高了能源效率，结果人们因此买更多的电器，消耗更多的电。</p>]]></content>
    
    
    <summary type="html">&lt;ol&gt;
&lt;li&gt;五只猴子的故事&lt;/li&gt;
&lt;li&gt;任正非在一次座谈会上谈加强项目财务的有效管理&lt;/li&gt;
&lt;li&gt;眼镜蛇效应&lt;/li&gt;
&lt;li&gt;能源效率的诅咒&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    <category term="语录" scheme="http://www.lights8080.com/categories/%E8%AF%AD%E5%BD%95/"/>
    
    
    <category term="语录" scheme="http://www.lights8080.com/tags/%E8%AF%AD%E5%BD%95/"/>
    
  </entry>
  
  <entry>
    <title>Elasticsearch-映射（Mapping）</title>
    <link href="http://www.lights8080.com/2021/04/08/%E6%8A%80%E6%9C%AF/ELK/Elasticsearch-%E6%90%9C%E7%B4%A2%EF%BC%88Search-DSL%EF%BC%89/"/>
    <id>http://www.lights8080.com/2021/04/08/%E6%8A%80%E6%9C%AF/ELK/Elasticsearch-%E6%90%9C%E7%B4%A2%EF%BC%88Search-DSL%EF%BC%89/</id>
    <published>2021-04-08T03:27:15.000Z</published>
    <updated>2021-06-01T10:47:46.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Elasticsearch介绍查询搜索请求包含哪些选项，并介绍其中的Query DSL。包括语法说明、查询和过滤上下文、复合查询等和查询示例。<br> 基于7.11版本。</p></blockquote><span id="more"></span><p>搜索请求是对Elasticsearch数据流或索引中的数据信息的请求，包括以下自定义选项：</p><ul><li>Query DSL（查询语法）</li><li>Aggregations（分组聚合）</li><li>Search multiple data streams and indices（多数据流和索引搜索）</li><li>Paginate search results（分页查询）</li><li>Retrieve selected fields（查询指定字段）</li><li>Sort search results（排序）</li><li>Run an async search（异步搜索）<br>本文介绍其中的Query DSL。</li></ul><h2 id="查询特定语言（Query-DSL-Domain-Specific-Language）"><a href="#查询特定语言（Query-DSL-Domain-Specific-Language）" class="headerlink" title="查询特定语言（Query DSL - Domain Specific Language）"></a>查询特定语言（Query DSL - Domain Specific Language）</h2><p>Elasticsearch提供了基于JSON的丰富的查询特定语言来定义查询，包含两种类型的子句组成：</p><ul><li>Leaf query clauses：页查询。在特定的字段中查找特定值，如match、term和range查询</li><li>Compound query clauses：复合查询。包装其他的Leaf和Compound子查询，逻辑组合多个查询（bool、dis_max），或更改其行为（constant_score）。</li></ul><h3 id="查询和过滤上下文（Query-and-filter-context）"><a href="#查询和过滤上下文（Query-and-filter-context）" class="headerlink" title="查询和过滤上下文（Query and filter context）"></a>查询和过滤上下文（Query and filter context）</h3><h4 id="相关性得分（relevance-scores）："><a href="#相关性得分（relevance-scores）：" class="headerlink" title="相关性得分（relevance scores）："></a>相关性得分（relevance scores）：</h4><p>Elasticsearch按相关性得分对匹配的搜索结果进行排序，该得分衡量每个文档与查询的匹配程度。<br>相关性得分是一个正浮点数，在查询API的_score元数据字段中返回，分值越高，文档越相关。<br>不同的查询类型可以计算不同的相关性得分，计算分数还取决于查询子句是运行在查询上下文还是过滤器上下文中。</p><h4 id="查询上下文（Query-context）："><a href="#查询上下文（Query-context）：" class="headerlink" title="查询上下文（Query context）："></a>查询上下文（Query context）：</h4><p>回答的是文档与该查询子句的匹配程度如何，主要用于计算文档相关性得分。</p><h4 id="过滤器上下文（Filter-context）："><a href="#过滤器上下文（Filter-context）：" class="headerlink" title="过滤器上下文（Filter context）："></a>过滤器上下文（Filter context）：</h4><p>回答的是文档与该查询子句是否匹配，主要用于过滤结构化数据，不计算相关性得分。<br>频繁的使用filter context将会被ES自动缓存，以提升性能。</p><h3 id="Compound-queries：复合查询"><a href="#Compound-queries：复合查询" class="headerlink" title="Compound queries：复合查询"></a>Compound queries：复合查询</h3><ul><li>boolean：匹配和过滤，满足条件可以获得更高的得分</li><li>boosting：降低文档的得分，而不是排除</li><li>constant_score：固定值得分</li><li>dis_max：提升多个文档具有相同固定值得分</li><li>function_score：根据算法修改查询文档得分</li></ul><h4 id="1-boolean-query"><a href="#1-boolean-query" class="headerlink" title="1. boolean query"></a>1. boolean query</h4><p>用于匹配和筛选文档。bool查询是采用more-matches-is-better的机制，因此满足must和should子句的文档将获得更高的分值。</p><ul><li>must：返回的文档必须满足此查询子句，参与分值计算</li><li>filter：返回的文档必须满足此查询子句，不参与分值计算，缓存结果</li><li>should：返回的文档可能满足此查询子句，参与分值计算</li><li>must_not：该查询子句必须不能出现在匹配的文档中，不参与分值计算，缓存结果</li><li>minimum_should_match：指定至少匹配几个should子句，若一个bool查询包含至少一个should子句且无must或filter子句，则默认值为1。</li><li>boost：提升权重</li></ul><h4 id="2-boosting"><a href="#2-boosting" class="headerlink" title="2. boosting"></a>2. boosting</h4><p>目的是降低某些文档分值，而不是从结果中排除。</p><p>boosting计算相关性得分规则：</p><ol><li>从符合positive子句的查询中获得原始的相关性得分</li><li>得分 乘上 negative_boost系数，获得最终得分</li></ol><ul><li>positive：必填，返回的文档必须匹配此查询。</li><li>negative：必填，降低匹配文档的分值。</li><li>negative_boost：必填，介于0~1.0之间的数</li></ul><h4 id="3-constant-score"><a href="#3-constant-score" class="headerlink" title="3. constant_score"></a>3. constant_score</h4><p>包装filter query并返回分值，分值等于boost参数。</p><ul><li>filter：必填，返回索引文档都必须匹配的查询条件</li><li>boost：可选，指定分值，默认为1</li></ul><h4 id="4-dis-max"><a href="#4-dis-max" class="headerlink" title="4. dis_max"></a>4. dis_max</h4><p>用于提升多个字段中包含相同术语的文档分配更高的得分。<br>dis_max计算相关性得分规则：</p><ol><li>获得匹配子句中最高得分</li><li>其他匹配的子句得分 乘上 tie_treaker系数</li><li>将最高得分与其他匹配得分相加，获得最终得分</li></ol><ul><li>queries：必填，返回的文档必须匹配一个或多个查询条件，匹配的条件越多则分值越高</li><li>tie_breaker：可选，介于0~1.0之间的数，用于增加匹配文档的分值。默认为0</li></ul><h4 id="5-function-score"><a href="#5-function-score" class="headerlink" title="5. function_score"></a>5. function_score</h4><p>允许修改查询文档的相关性得分，通过得分函数（function_score）在过滤后的文档集合上计算，获得最终得分。</p><ul><li>query：指定查询条件，默认”match_all”: {}</li><li>score_mode：计算分值的模式。multiply（默认）、sum、avg、first、max、min</li><li>boost_mode：计算的分值与查询分值合并模式。multiply（默认）、replace（忽略查询分值）、sum、avg、max、min</li><li>function_score：计算分值的函数。script_score（函数）、weight（权重）、random_score（0~1随机）、field_value_factor（字段因素）</li></ul><h3 id="Full-text-queries：全文检索，查询已分析的文本字段"><a href="#Full-text-queries：全文检索，查询已分析的文本字段" class="headerlink" title="Full text queries：全文检索，查询已分析的文本字段"></a>Full text queries：全文检索，查询已分析的文本字段</h3><ul><li>intervals：根据匹配项的顺序和接近程度返回文档</li><li>match：标准的全文查询，模糊匹配和短语接近查询</li><li>match_bool_prefix：分析其输入解析构造为bool query，最后一个词在前缀查询中使用</li><li>match_phrase：分析其输入解析为短语匹配查询</li><li>match_phrase_prefix：分析其输入解析为短语匹配查询，最后一个词在前缀查询中使用</li><li>multi_match：多个字段匹配查询</li><li>query_string：语法解析器查询</li><li>simple_query_string：更简单的语法解析器查询</li></ul><h3 id="Geo-queries：坐标查询"><a href="#Geo-queries：坐标查询" class="headerlink" title="Geo queries：坐标查询"></a>Geo queries：坐标查询</h3><ul><li>geo_bounding_box：矩形查询</li><li>geo_distance：坐标点范围查询</li><li>geo_polygon：多边形查询</li><li>geo_shape：包括几何图形查询和指定地理形状相交点查询</li></ul><h3 id="Shape-queries：像geo-shape一样，支持索引任意二维的几何图形功能"><a href="#Shape-queries：像geo-shape一样，支持索引任意二维的几何图形功能" class="headerlink" title="Shape queries：像geo_shape一样，支持索引任意二维的几何图形功能"></a>Shape queries：像geo_shape一样，支持索引任意二维的几何图形功能</h3><h3 id="Joining-queries：连接查询"><a href="#Joining-queries：连接查询" class="headerlink" title="Joining queries：连接查询"></a>Joining queries：连接查询</h3><ul><li>nested：嵌套类型查询</li><li>has_child：匹配子文档的字段，返回父文档。前提是同一索引中建立的父子关系</li><li>has_parent：匹配父文档的字段，返回所有子文档。前提是同一索引中建立的父子关系</li><li>parent_id：查询指定父文档的所有子文档。</li></ul><h3 id="Span-queries：区间查询。精准控制多个输入词的先后顺序，已经多个关键词在文档中的前后距离"><a href="#Span-queries：区间查询。精准控制多个输入词的先后顺序，已经多个关键词在文档中的前后距离" class="headerlink" title="Span queries：区间查询。精准控制多个输入词的先后顺序，已经多个关键词在文档中的前后距离"></a>Span queries：区间查询。精准控制多个输入词的先后顺序，已经多个关键词在文档中的前后距离</h3><ul><li>span_containing：区间列表查询</li><li>field_masking_span：允许跨越不同字段查询</li><li>span_first：跨度查询，匹配项必须出现在该字段的前N个位置</li><li>span_multi：Wraps a term, range, prefix, wildcard, regexp, or fuzzy query.</li><li>span_near：接受多个跨度查询，顺序相同且指定距离之内</li><li>span_not：包装其他span query，排除与该文档匹配的所有文档</li><li>span_or：返回任意指定查询匹配的文档</li><li>span_term：等同于term query，可以和其他span query一起使用</li><li>span_within：</li></ul><h3 id="Specialized-queries：专业的查询"><a href="#Specialized-queries：专业的查询" class="headerlink" title="Specialized queries：专业的查询"></a>Specialized queries：专业的查询</h3><ul><li>distance_feature：基于时间或坐标查询，越接近原点得分越高</li><li>more_like_this：按文本、文档和文档的集合查询</li><li>percolate：按存储的指定文档匹配查询</li><li>rank_feature：通过定义字段的rank_feature或rank_features属性值提高得分</li><li>script：脚本过滤文档</li><li>script_score：通过脚本自定义得分</li><li>wrapper：接受一个base64字符串查询</li><li>pinned：提升特定文档的查询</li></ul><h3 id="Term-level-queries：术语级查询"><a href="#Term-level-queries：术语级查询" class="headerlink" title="Term-level queries：术语级查询"></a>Term-level queries：术语级查询</h3><ul><li>exists：返回包含字段的任意文档</li><li>fuzzy：返回搜索词的相似词的文档</li><li>ids：返回指定ID的文档</li><li>prefix：返回字段中指定前缀的文档</li><li>range：返回范围内的文档</li><li>regexp：返回正则匹配的文档</li><li>term：返回字段中包含特定术语的文档</li><li>terms：返回字段中包含一个或多个术语的文档</li><li>terms_set：返回字段中包含最少数目术语的文档</li><li>type：返回指定类型的文档</li><li>wildcard：返回通配符匹配文档</li></ul><h3 id="查询示例"><a href="#查询示例" class="headerlink" title="查询示例"></a>查询示例</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"># 多索引同步搜索</span><br><span class="line">GET /my-index-000001,my-index-000002/_search</span><br><span class="line">&#123;</span><br><span class="line">  # 指定查询超时时间</span><br><span class="line">  &quot;timeout&quot;: &quot;2s&quot;,</span><br><span class="line">  # 字段匹配，相当于query context</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;bool&quot;: &#123;</span><br><span class="line">      &quot;must&quot;: [</span><br><span class="line">        &#123; &quot;match_all&quot;: &#123;&#125;&#125;,</span><br><span class="line">        &#123; &quot;match&quot;: &#123; &quot;title&quot;: &quot;Search&quot; &#125;&#125;</span><br><span class="line">      ],</span><br><span class="line">      # 相当于filter context</span><br><span class="line">      &quot;filter&quot;: [</span><br><span class="line">        &#123; &quot;term&quot;:  &#123; &quot;status&quot;: &quot;published&quot; , &quot;_name&quot; : &quot;status_pub&quot;&#125;&#125;,</span><br><span class="line">        &#123; &quot;range&quot;: &#123; &quot;publish_date&quot;: &#123; &quot;gte&quot;: &quot;2015-01-01&quot; &#125;&#125;&#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  # 排序</span><br><span class="line">  &quot;sort&quot;: [</span><br><span class="line">    &#123; &quot;account_number&quot;: &quot;asc&quot; &#125;,</span><br><span class="line">    &#123; &quot;post_date&quot; : &#123;&quot;order&quot; : &quot;asc&quot;&#125;&#125;,</span><br><span class="line">    &quot;_score&quot;</span><br><span class="line">  ],</span><br><span class="line">  # 范围搜索</span><br><span class="line">  &quot;range&quot;: &#123;</span><br><span class="line">    &quot;gmtCreate&quot;: &#123;</span><br><span class="line">      &quot;gte&quot;: &quot;2020-10-01 00:00:00&quot;,</span><br><span class="line">      &quot;lte&quot;: &quot;2020-10-31 23:59:59&quot;,</span><br><span class="line">      &quot;format&quot;: &quot;yyyy-MM-dd HH:mm:ss&quot;,</span><br><span class="line">      &quot;time_zone&quot;:&quot;+08:00&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  # 查询指定字段</span><br><span class="line">  &quot;fields&quot;: [&quot;user.id&quot;, &quot;@timestamp&quot;],</span><br><span class="line">  &quot;_source&quot;: false</span><br><span class="line">  # 分页</span><br><span class="line">  &quot;from&quot;: 10,</span><br><span class="line">  &quot;size&quot;: 10</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;Elasticsearch介绍查询搜索请求包含哪些选项，并介绍其中的Query DSL。包括语法说明、查询和过滤上下文、复合查询等和查询示例。&lt;br&gt; 基于7.11版本。&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="技术" scheme="http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="ELK" scheme="http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/ELK/"/>
    
    
    <category term="技术" scheme="http://www.lights8080.com/tags/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="ELK" scheme="http://www.lights8080.com/tags/ELK/"/>
    
    <category term="Elasticsearch" scheme="http://www.lights8080.com/tags/Elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>Elasticsearch-索引（Index）</title>
    <link href="http://www.lights8080.com/2021/04/07/%E6%8A%80%E6%9C%AF/ELK/Elasticsearch-%E7%B4%A2%E5%BC%95%EF%BC%88Index%EF%BC%89/"/>
    <id>http://www.lights8080.com/2021/04/07/%E6%8A%80%E6%9C%AF/ELK/Elasticsearch-%E7%B4%A2%E5%BC%95%EF%BC%88Index%EF%BC%89/</id>
    <published>2021-04-07T03:27:15.000Z</published>
    <updated>2021-06-01T10:47:46.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Elasticsearch索引介绍，包括索引设置、索引模板、索引生命周期管理、翻滚索引。<br> 基于7.11版本。</p></blockquote><span id="more"></span><h2 id="索引设置（Index-Settings）"><a href="#索引设置（Index-Settings）" class="headerlink" title="索引设置（Index Settings）"></a>索引设置（Index Settings）</h2><h3 id="static"><a href="#static" class="headerlink" title="static"></a>static</h3><p>只能在创建索引时或关闭的索引上设置</p><ul><li>index.number_of_shards：主分片数量，默认1</li><li>index.number_of_routing_shards：拆分索引的路由分片数量，默认值位于2~1024之间，依赖索引主分片数量</li><li>index.shard.check_on_startup：打开前检查分片是否损坏，默认false</li><li>index.codec：压缩存储算法，默认LZ4</li><li>index.routing_partition_size：自定义路由可以到达的分片数量，默认1</li></ul><h3 id="dynamic"><a href="#dynamic" class="headerlink" title="dynamic"></a>dynamic</h3><p>可以使用API实时对索引进行操作</p><ul><li>index.number_of_replicas：主分片的副本数，默认1</li><li>index.auto_expand_replicas：根据集群中数据节点的数量自动扩展副本的数量，默认false</li><li>index.search.idle.after：搜索空闲之前不能接收搜索和获取请求的时间，默认30s</li><li>index.refresh_interval：刷新操作频率，最近对索引的更改既可见，默认1s。-1关闭刷新操作</li><li>index.max_result_window：查询索引结果的最大数量，默认10000</li><li>index.max_inner_result_window：内部或聚合命中最大数量，默认100</li><li>index.max_rescore_window：打分请求的最大索引数量，默认10000（同index.max_result_window）</li><li>index.max_docvalue_fields_search：查询中允许的最大字段数，默认100</li><li>index.max_script_fields：查询中允许的最大脚本字段数，默认32</li><li>index.query.default_field：查询返回的默认字段，默认*（表示所有）</li></ul><h2 id="索引模板（Index-Templates）"><a href="#索引模板（Index-Templates）" class="headerlink" title="索引模板（Index Templates）"></a>索引模板（Index Templates）</h2><p>索引模板是告诉Elasticsearch在创建索引时如何配置索引的一种方法。对于数据流（data stream），索引模板配置是创建他们的后备索引。在创建索引之前先配置模板，模板设置将用作创建索引的基础。</p><p>模板有两种类型，索引模板（index templates）和组件模板（component templates）。</p><p>组件模板是可重用的构建块，用于配置映射（mappings）、设置（settings）和别名（alias）。使用组件模板来构造索引模板，但它们不会直接应用于索引。索引模板可以包含组件模板的集合，也可以直接指定设置，映射和别名。如果匹配多个模板，优先使用优先级最高的模板。</p><p>可以使用模拟API创建索引，确定最终的索引设置。<code>POST /_index_template/_simulate</code>。</p><p>注意事项：</p><ul><li>如果新数据流或索引与多个索引模板匹配，则使用优先级最高的索引模板。</li><li>Elasticsearch内置了许多索引模板（如：metrics-<em>-</em>,logs-*-*），每个模板的优先级是100。如果不想使用内置模板，请为您的模板分配更高的优先级。</li><li>如果显式设置创建索引，并且该索引与索引模板匹配，则创建索引请求中的设置将优先于索引模板中指定的设置。</li><li>索引模板仅在创建索引期间应用。索引模板的更改不会影响现有索引。</li><li>当可组合模板匹配给定索引时，它始终优先于旧模板。如果没有可组合模板匹配，则旧版模板可能仍匹配并被应用。</li></ul><h2 id="索引生命周期管理（Index-Lifecycle-Manager-ILM）"><a href="#索引生命周期管理（Index-Lifecycle-Manager-ILM）" class="headerlink" title="索引生命周期管理（Index Lifecycle Manager - ILM）"></a>索引生命周期管理（Index Lifecycle Manager - ILM）</h2><p>配置索引生命周期管理策略，能够随着时间推移根据性能、弹性和保留要求自动的管理索引。</p><p>索引生命周期策略可以触发以下操作：</p><ul><li>翻转（Rollover）：当现有索引达到一定分片大小，文档数或使用年限时，为翻转目标创建新索引。翻转目标可以是索引别名或数据流。</li><li>收缩（Shrink）：减少索引中主碎片的数量。</li><li>强制合并（Force merge）：手动触发合并以减少索引每个分片中的段数，并释放已删除文档所使用的空间。</li><li>冻结（Freeze）：将索引设为只读，并最大程度地减少其内存占用量。</li><li>删除（Delete）：永久删除索引，包括其所有数据和元数据。</li></ul><p>使用ILM可以更轻松地管理热-温-冷体系结构中的索引，在使用时间序列数据时很常见（如日志和指标）。</p><h3 id="索引生命周期（Index-lifecycle）"><a href="#索引生命周期（Index-lifecycle）" class="headerlink" title="索引生命周期（Index lifecycle）"></a>索引生命周期（Index lifecycle）</h3><p>ILM定义了以下四个阶段（Phases）</p><ul><li>Hot：频繁的写入和查询</li><li>Warm：索引不在更新，仍然在查询</li><li>Cold：不再更新的索引，很少查询仍然可以搜索，查询较慢也没关系</li><li>Delete：不再需要的索引，可以安全的删除</li></ul><p>索引的生命周期策略指定了应用于哪些阶段，每个阶段中执行什么操作，以及何时在两个阶段之间进行转换。</p><p>创建索引时可以手动应用生命周期策略。对于时间序列索引，需要将生命周期策略与用于在序列中创建新索引的索引模板相关联。当索引滚动时，不会自动将手动应用的策略应用于新索引。</p><h4 id="阶段转换（phase-transitions）"><a href="#阶段转换（phase-transitions）" class="headerlink" title="阶段转换（phase transitions）"></a>阶段转换（phase transitions）</h4><p>ILM根据其年龄在整个生命周期中移动索引。要控制这些翻转的时间，请为每个阶段设置一个最小年龄。为了使索引移至下一阶段，当前阶段中的所有操作都必须完成，并且索引必须早于下一阶段的最小年龄。</p><p>最小年龄默认为0，这会导致ILM在当前阶段中的所有操作完成后立即将索引移至下一阶段。</p><p>如果索引具有未分配的分片并且集群运行状况为黄色，则索引仍可以根据其索引生命周期管理策略过渡到下一阶段。但是，由于Elasticsearch只能在绿色集群上执行某些清理任务，因此可能会有意外的副作用。</p><h4 id="阶段执行（phase-execution）"><a href="#阶段执行（phase-execution）" class="headerlink" title="阶段执行（phase execution）"></a>阶段执行（phase execution）</h4><p>ILM控制阶段中的动作的执行的顺序，以及哪些步骤是执行每个动作的必要索引操作。</p><p>当索引进入阶段后，ILM将阶段定义信息缓存在索引元数据中，这样可以确保索引政策更新不会将索引置于永远不退出阶段的状态。</p><p>ILM定期运行，检查索引是否符合策略标准，并执行所需的步骤。为了避免竞争情况，ILM可能需要运行多次执行，完成一项动作所需的所有步骤。这意味着即使<code>indexs.lifecycle.poll_interval</code>设置为10分钟并且索引满足翻转条件，也可能需要20分钟才能完成翻转。</p><h4 id="阶段动作（phase-actions）"><a href="#阶段动作（phase-actions）" class="headerlink" title="阶段动作（phase actions）"></a>阶段动作（phase actions）</h4><p>参考<a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.11/ilm-index-lifecycle.html#ilm-phase-actions">https://www.elastic.co/guide/en/elasticsearch/reference/7.11/ilm-index-lifecycle.html#ilm-phase-actions</a></p><h3 id="索引生命周期动作（Index-Lifecycle-Actions）"><a href="#索引生命周期动作（Index-Lifecycle-Actions）" class="headerlink" title="索引生命周期动作（Index Lifecycle Actions）"></a>索引生命周期动作（Index Lifecycle Actions）</h3><ul><li>Allocate：将分片移动到具有不同性能特征的节点，并减少副本的数量。</li><li>Delete：永久删除索引。</li><li>Force merge：减少索引段的数量并清除已删除的文档。将索引设为只读。</li><li>Freeze：冻结索引以最大程度地减少其内存占用量。</li><li>Migrate：将索引分片移动到对应于当前 ILM 阶段的数据层。</li><li>Read only：阻止对索引的写操作。</li><li>Rollover：移动索引作为滚动别名的写索引，并开始索引到新索引。</li><li>Searchable snapshot：为配置库中的管理索引拍摄快照，并将其作为可搜索快照。</li><li>Set priority：降低索引在生命周期中的优先级，以确保首先恢复热索引。</li><li>Shrink：通过将索引缩小为新索引来减少主碎片的数量。</li><li>Unfollow：将关注者索引转换为常规索引。在Rollover、Shrink和Searchable snapshot操作之前自动执行。</li><li>Wait for snapshot：删除索引之前，请确保快照已存在。</li></ul><h3 id="ILM更新（Lifecycle-policy-updates）"><a href="#ILM更新（Lifecycle-policy-updates）" class="headerlink" title="ILM更新（Lifecycle policy updates）"></a>ILM更新（Lifecycle policy updates）</h3><p>您可以通过修改当前策略或切换到其他策略的方式来更改管理索引或滚动索引集合的生命周期。</p><p>为确保策略更新不会将索引置于无法退出当前阶段的状态，进入这个阶段时，阶段定义会缓存在索引元数据中。如果策略更新可以安全的应用，ILM更新缓冲的阶段定义；如果不能，则使用缓冲阶段定义完成该阶段。</p><h3 id="Rollover（翻转）"><a href="#Rollover（翻转）" class="headerlink" title="Rollover（翻转）"></a>Rollover（翻转）</h3><p>在为日志或指标等时间序列数据编制索引时，不能无限期地写入单个索引。为了满足索引和搜索性能要求并管理资源使用，可以写入索引直到达到某个阈值，然后创建一个新索引并开始写入该索引。</p><p>使用滚动索引能够：</p><ul><li>优化活跃的索引，以在高性能热节点上获得高接收速率。</li><li>针对热节点上的搜索性能进行优化。</li><li>将较旧的，访问频率较低的数据转移到价格较低的冷节点上。</li><li>根据您的保留政策，通过删除整个索引来删除数据。</li></ul><p>我们建议使用数据流来管理时间序列数据。数据流自动跟踪写入索引，同时将配置保持在最低水平。数据流设计用于仅追加数据，其中数据流名称可用作操作（读取，写入，翻转，收缩等）目标。如果您的用例需要就地更新数据，则可以使用索引别名来管理时间序列数据。</p><h4 id="自动翻转（automatic-rollover）："><a href="#自动翻转（automatic-rollover）：" class="headerlink" title="自动翻转（automatic rollover）："></a>自动翻转（automatic rollover）：</h4><p>ILM使您能够根据索引大小，文档数或使用年限自动翻转到新索引。触发翻转后，将创建一个新索引，将写入别名更新为指向新索引，并将所有后续更新写入新索引。<br>与基于时间的过渡相比，基于大小，文档数或使用年限翻转至新索引更可取。在任意时间滚动通常会导致许多小的索引，这可能会对性能和资源使用产生负面影响。</p><h2 id="数据流（Data-streams）"><a href="#数据流（Data-streams）" class="headerlink" title="数据流（Data streams）"></a>数据流（Data streams）</h2><p>数据流用于跨多个索引存储仅追加的时间序列数据，同时提供一个用于请求的数据流名称。<br>可以将索引和搜索请求直接提交到数据流。流自动将请求路由到存储流数据的索引。同样可以使用索引生命周期管理（ILM）来自动管理这些后备索引。<br>数据流非常适合日志，事件，指标和其他连续生成的数据。</p><h2 id="滚动索引（rollover-index）"><a href="#滚动索引（rollover-index）" class="headerlink" title="滚动索引（rollover index）"></a>滚动索引（rollover index）</h2><p>当现有的索引满足您提供的条件（a list of conditions）时，滚动索引API会为滚动目标（rollover target）创建一个新的索引。<br>当滚动目标是别名（alias）时，别名会指向新索引（当指向多个索引时，必须有一个索引设置<code>is_write_index=true</code>）<br>当滚动目标是数据流（data stream）时，新索引会成为数据流的写索引，并生成一个增量</p><h3 id="Rollover-request"><a href="#Rollover-request" class="headerlink" title="Rollover request"></a>Rollover request</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">POST /&lt;rollover-target&gt;/_rollover/&lt;target-index&gt;</span><br><span class="line">POST /&lt;rollover-target&gt;/_rollover/</span><br></pre></td></tr></table></figure><h4 id="Path-parameters"><a href="#Path-parameters" class="headerlink" title="Path parameters"></a>Path parameters</h4><ul><li><rollover-target>：必填，现有的分配给目标索引的索引别名或数据流名称。</li><li><target-index>：可选，用于创建和分配索引别名的目标索引名称。如果<rollover-target>是数据流，则不允许使用此参数。如果<rollover-target>是索引别名，则分配给以”-“和数字结尾的索引名称，如logs-000001。</li></ul><h4 id="Request-body"><a href="#Request-body" class="headerlink" title="Request body"></a>Request body</h4><ul><li>aliases：可选，索引别名</li><li>conditions：可选，滚动操作的触发条件<ul><li>max_age：最大年龄</li><li>max_docs：最大文档数</li><li>max_size：最大索引大小</li></ul></li><li>mappings：可选，映射配置</li><li>settings：可选，索引配置</li></ul>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;Elasticsearch索引介绍，包括索引设置、索引模板、索引生命周期管理、翻滚索引。&lt;br&gt; 基于7.11版本。&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="技术" scheme="http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="ELK" scheme="http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/ELK/"/>
    
    
    <category term="技术" scheme="http://www.lights8080.com/tags/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="ELK" scheme="http://www.lights8080.com/tags/ELK/"/>
    
    <category term="Elasticsearch" scheme="http://www.lights8080.com/tags/Elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>Elasticsearch-介绍</title>
    <link href="http://www.lights8080.com/2021/04/01/%E6%8A%80%E6%9C%AF/ELK/Elasticsearch-%E4%BB%8B%E7%BB%8D/"/>
    <id>http://www.lights8080.com/2021/04/01/%E6%8A%80%E6%9C%AF/ELK/Elasticsearch-%E4%BB%8B%E7%BB%8D/</id>
    <published>2021-04-01T03:27:15.000Z</published>
    <updated>2021-06-01T10:47:46.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Elasticsearch介绍，包括文档与索引、倒排索引、搜索和分析、可伸缩和弹性（节点、分片、跨集群复制）。<br> 内容大部分源自官方文档第一节“What is Elasticsearch?”<br> 基于7.11版本。</p></blockquote><span id="more"></span><p>Elasticsearch是一个分布式搜索和分析引擎，为所有类型的数据提供了近实时的搜索和分析。不仅可以进行简单的数据探索，还可以汇总信息来发现数据中的趋势和模式。随着数据和查询量的增长，分布式特性可以使部署顺畅的无缝的增长。</p><h2 id="1-文档和索引"><a href="#1-文档和索引" class="headerlink" title="1. 文档和索引"></a>1. 文档和索引</h2><h3 id="文档（Document）"><a href="#文档（Document）" class="headerlink" title="文档（Document）"></a>文档（Document）</h3><p>Elasticsearch是分布式文档存储，它不会将信息存储为“行-列”数据结构，而是存储为JSON文档的数据结构。当一个集群中有多个节点时，存储的文档分布在集群中，并且可以从任何节点访问。</p><p>Elasticsearch使用倒排索引的数据结构，支持非常快速的全文本搜索。一个倒排索引由文档中所有不重复词的列表构成，对于其中每个词，有一个包含它的文档列表。</p><h3 id="索引（Index）"><a href="#索引（Index）" class="headerlink" title="索引（Index）"></a>索引（Index）</h3><p>索引是一个逻辑命名空间，可以看作是文档的优化集合，每个文档都是字段的集合。默认Elasticsearch对每个字段中的所有数据建立索引，并且每个索引字段都具有专用的优化数据结构。如：文本字段存储在倒排索引中，数字、地理字段存储在BKD树中。</p><p>Elasticsearch还支持动态映射（dynamic mapping），自动检测并向索引添加新字段。可以定义规则来控制动态映射，也可以显式定义映射以完全控制字段的存储和索引方式。</p><p>显式定义映射的意义：</p><ul><li>区分全文本字符串字段和精确值字符串字段</li><li>执行特定语言的文本分析</li><li>优化字段进行部分匹配</li><li>自定义日期格式</li><li>无法自动检测到的数据类型，如地理信息</li></ul><p>为不同的目的以不同的方式对同一字段建立索引通常很有用。</p><h3 id="倒排索引（inverted-index）"><a href="#倒排索引（inverted-index）" class="headerlink" title="倒排索引（inverted index）"></a>倒排索引（inverted index）</h3><p>倒排索引的结构，适用于快速的全文（Text）搜索。一个倒排索引由文档中所有不重复词的列表构成，对于其中每个词，有一个包含它的文档列表。</p><p>倒排索引建立的是分词（Term）和文档（Document）之间的映射关系，在倒排索引中，数据是面向词而不是面向文档的。</p><ul><li>Term（词）：精准值，foo、Foo是不相同的词</li><li>Text（文本）：非结构化文本，默认文本会被解析为词，这是索引中实际存储的内容</li></ul><p>Elasticsearch索引存储结构图：<br><img src="https://gitee.com/lights8080/lights8080-oss/raw/master/uPic/hGcjkj.jpg"></p><p>一个索引包含很多分片，一个分片是一个Lucene索引，它本身就是一个完整的搜索引擎，可以独立执行建立索引和搜索任务。</p><p>Lucene索引又由很多分段组成，每个分段都是一个倒排索引。 Elasticsearch每次refresh都会生成一个新的分段，其中包含若干文档的数据。</p><p>每个分段（Segment）内部，文档的不同字段被单独建立索引。每个字段的值由若干词（Term）组成。</p><p>词（Term）是原文本内容经过分词器处理和语言处理后的最终结果。</p><h2 id="2-搜索和分析"><a href="#2-搜索和分析" class="headerlink" title="2. 搜索和分析"></a>2. 搜索和分析</h2><h3 id="搜索（Search）"><a href="#搜索（Search）" class="headerlink" title="搜索（Search）"></a>搜索（Search）</h3><p>Elasticsearch提供了一个简单，一致的REST API，用于管理集群以及建立索引和搜索数据。<br>REST APIs支持结构化查询、全文本查询和结合了两者的复杂查询。</p><ul><li>结构化查询：类似于SQL构建的查询，按索引中搜索字段，然后按字段对匹配项进行排序。</li><li>全文本查询：查找到所有与查询字符串匹配的文档，按相关性对它们进行排序。</li></ul><p>可以使用Elasticsearch的全面JSON风格的查询语言(Query DSL)访问所有这些搜索功能。还可以构造SQL风格的查询来在Elasticsearch内部本地搜索和聚合数据。</p><h3 id="分析（Analyze）"><a href="#分析（Analyze）" class="headerlink" title="分析（Analyze）"></a>分析（Analyze）</h3><p>聚合使您能够构建数据的复杂摘要，并深入了解关键指标，模式和趋势。聚合利用了用于搜索的相同数据结构，速度很快，可以实时分析和可视化数据。聚合操作和搜索的请求在一起运行，可以在单个请求中同一时间相同的数据进行搜索文档，过滤结果并执行分析。</p><h2 id="3-可伸缩和弹性"><a href="#3-可伸缩和弹性" class="headerlink" title="3. 可伸缩和弹性"></a>3. 可伸缩和弹性</h2><h3 id="集群（Cluster）"><a href="#集群（Cluster）" class="headerlink" title="集群（Cluster）"></a>集群（Cluster）</h3><p>一个Elasticsearch集群由一个或多个节点（Node）组成，每个集群都有一个cluster name作为标识。</p><p>集群的三种状态：</p><ul><li>Green：所有主分片和副本分片都准备就绪。数据不会丢失</li><li>Yellow：所有主分片准备就绪，但至少一个主分片对应的副本分片没有就绪。意味着高可用和容灾能力下降</li><li>Red：至少有一个主分片没有就绪。此时查询的结果会出现数据丢失</li></ul><p>Elasticsearch可以根据需要进行扩展，它天生就实现了分布式。你可以向集群添加节点以增加容量，它会自动将数据和查询负载分布到所有可用节点，不需要大改应用程序。</p><p>Elasticsearch索引只是一个或多个物理分片的逻辑分组，其中每个分片实际上是一个独立的的索引。通过将文档分布在索引中的多个分片上，并将这些分片分布在多个节点上，当集群增长(或缩小)时，Elasticsearch自动迁移分片以平衡集群。</p><h3 id="节点（Node）"><a href="#节点（Node）" class="headerlink" title="节点（Node）"></a>节点（Node）</h3><p>节点是属于集群的运行实例，测试时可以一个服务器上启动多个节点，线上通常一个服务器只有一个实例。</p><p>启动时，节点将使用单播来发现具有相同集群名称的现有集群，并尝试加入。</p><ul><li>候选主节点（Master-eligible Node）</li><li>主节点（Master Node）</li><li>数据节点（Data Node）</li><li>协调节点（Coordinating Node）</li><li>热节点（Hot Node）</li><li>冷节点（Warm Node）</li><li>预处理节点（Ingest Node）</li></ul><h3 id="分片（Shard）"><a href="#分片（Shard）" class="headerlink" title="分片（Shard）"></a>分片（Shard）</h3><p>分片是单个Lucene实例。这是一个低级的工作单元，由ElasticSearch自动管理，在节点发生故障或新增时，可以自动的将分片从一个节点移动到另一个节点。分为主分片（primaries）和副本分片（replicas）两种类型。</p><ul><li>主分片：建立索引时默认会有一个主分片，每个文档都属于一个主分片，创建索引后，主分片数量是固定的无法更改。</li><li>副本分片：每个主分片可以有零个或多个副本，可以随时更改，副本永远不会和主分片在同一节点上启动。副本提供数据的冗余副本，以防止硬件故障，并增加处理像搜索或检索文档这样的读请求的能力。</li></ul><h3 id="跨集群复制（Cross-cluster-replication）"><a href="#跨集群复制（Cross-cluster-replication）" class="headerlink" title="跨集群复制（Cross-cluster replication）"></a>跨集群复制（Cross-cluster replication）</h3><p>出于性能原因，群集中的节点必须位于同一网络上，跨不同数据中心中的节点在群集中平衡分片的时间太长了。但是这不符合高可用架构的要求，跨群集复制(CCR)可以解决单个集群重大故障问题。</p><p>CCR提供了一种将主集群的索引自动同步到次要远程集群的方法，次要远程集群可以作为热备份。如果主集群失败，次要集群可以接管。您还可以使用CCR创建次要集群，以满足用户在地理位置上接近的读请求。主集群上的索引是Leader，负责所有写请求，复制到次要集群上的索引是只读的Follower。</p>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;Elasticsearch介绍，包括文档与索引、倒排索引、搜索和分析、可伸缩和弹性（节点、分片、跨集群复制）。&lt;br&gt; 内容大部分源自官方文档第一节“What is Elasticsearch?”&lt;br&gt; 基于7.11版本。&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="技术" scheme="http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="ELK" scheme="http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/ELK/"/>
    
    
    <category term="技术" scheme="http://www.lights8080.com/tags/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="ELK" scheme="http://www.lights8080.com/tags/ELK/"/>
    
    <category term="Elasticsearch" scheme="http://www.lights8080.com/tags/Elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>Elasticsearch-文本分析（Text Analysis）</title>
    <link href="http://www.lights8080.com/2021/04/01/%E6%8A%80%E6%9C%AF/ELK/Elasticsearch-%E6%96%87%E6%9C%AC%E5%88%86%E6%9E%90%EF%BC%88Text%20Analysis%EF%BC%89/"/>
    <id>http://www.lights8080.com/2021/04/01/%E6%8A%80%E6%9C%AF/ELK/Elasticsearch-%E6%96%87%E6%9C%AC%E5%88%86%E6%9E%90%EF%BC%88Text%20Analysis%EF%BC%89/</id>
    <published>2021-04-01T03:27:15.000Z</published>
    <updated>2021-06-01T10:47:46.000Z</updated>
    
    <content type="html"><![CDATA[<p>文本分析使Elasticsearch能够执行全文搜索，其中搜索返回所有相关结果，而不仅仅是精确匹配。<br>文本通过标记化（tokenization）使全文搜索成为可能，将文本分解为标记的更小块。在大多数情况下，这些标记是单个单词。</p><h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p>分析器（无论是内置的还是自定义的）只是一个包，其中包含三个较低级别的构建块：字符过滤器（character filters），标记生成器（tokenizers）和标记过滤器（token filters）。</p><ul><li><p>索引和搜索分析器：文本分析发生在两次时间，索引时间（index time）和搜索时间（search time）。大多数情况，应在索引和搜索时使用同一台分析器，这样可以确保将字段的值和查询字符串更改为相同形式的标记。</p></li><li><p>词干化（Stemming）：词干化是将单词还原为词根形式的过程。这样可以确保在搜索过程中单词匹配的变体。如walking和walked的词根是walk。</p></li><li><p>标记图（Token graphs）：标记生成器将文本转换为标记流时，还会标记位置（position）和标记跨越的位置数（positionLength）。使用这些，可以为流创建有向无环图，称为标记图。</p></li></ul><h2 id="内置解析器"><a href="#内置解析器" class="headerlink" title="内置解析器"></a>内置解析器</h2><ul><li>standard analyzer：标准分析器；按照Unicode编码算法，将文本按照单词边界划分为terms，转为小写，支持删除停用词。</li><li>simple analyzer：简易分析器；遇到非字母字时，将文本划分terms，转为小写，支持删除停用词。</li><li>whitespace analyzer：空格分析器；遇到任意空格是，将文本划分为terms，不会小写。</li><li>stop analyzer：同simple analyzer</li><li>keyword analyzer：无操作解析器；会将文本作为单个term输出。</li><li>pattern analyzer：正则表达式解析器；按照正则表达式，将文本分成多个term，支持小写字母和停用词。</li><li>language analyzer：特定语言分析器；如：english</li><li>custom analyzer：自定义解析器</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;文本分析使Elasticsearch能够执行全文搜索，其中搜索返回所有相关结果，而不仅仅是精确匹配。&lt;br&gt;文本通过标记化（tokenization）使全文搜索成为可能，将文本分解为标记的更小块。在大多数情况下，这些标记是单个单词。&lt;/p&gt;
&lt;h2 id=&quot;概念&quot;&gt;&lt;a h</summary>
      
    
    
    
    <category term="技术" scheme="http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="ELK" scheme="http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/ELK/"/>
    
    
    <category term="技术" scheme="http://www.lights8080.com/tags/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="ELK" scheme="http://www.lights8080.com/tags/ELK/"/>
    
    <category term="Elasticsearch" scheme="http://www.lights8080.com/tags/Elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>Elasticsearch-映射（Mapping）</title>
    <link href="http://www.lights8080.com/2021/04/01/%E6%8A%80%E6%9C%AF/ELK/Elasticsearch-%E6%98%A0%E5%B0%84%EF%BC%88Mapping%EF%BC%89/"/>
    <id>http://www.lights8080.com/2021/04/01/%E6%8A%80%E6%9C%AF/ELK/Elasticsearch-%E6%98%A0%E5%B0%84%EF%BC%88Mapping%EF%BC%89/</id>
    <published>2021-04-01T03:27:15.000Z</published>
    <updated>2021-06-01T10:47:46.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Elasticsearch映射介绍，包括动态映射、显式映射、字段数据类型、映射参数、映射限制设置。<br> 内容大纲源自官方文档“Mapping”模块<br> 基于7.11版本。</p></blockquote><span id="more"></span><p>映射（Mapping）是定义文档及其包含的字段如何存储和索引的过程。<br>每个文档都是字段的集合，每个字段都有自己的数据类型。为数据创建一个映射定义，包含与文档相关的字段列表。</p><h2 id="动态映射（Dynamic-mapping）"><a href="#动态映射（Dynamic-mapping）" class="headerlink" title="动态映射（Dynamic mapping）"></a>动态映射（Dynamic mapping）</h2><p>当Elasticsearch在文档中检测到新字段时，会动态将该字段添加到映射中称为动态映射。</p><ul><li>动态字段映射：根据数据类型规则应用于动态添加的字段。支持的数据类型包括：boolean、double、integer、object、array、date。<ul><li>dynamic：开启动态映射的模式</li><li>date_detection：开启日期检测</li><li>dynamic_date_formats：检测的日期格式</li><li>numeric_detection: true：开启数值检测</li></ul></li><li>动态模板：又称自定义映射，根据匹配条件应用于动态添加的字段。<ul><li>match_mapping_type:  Elasticsearch检测到的数据类型进行操作</li><li>match and unmatch: 使用模式来匹配字段名称</li><li>path_match and path_unmatch:  使用字段的路径来匹配</li></ul></li></ul><h2 id="显式映射（Explicit-mapping）"><a href="#显式映射（Explicit-mapping）" class="headerlink" title="显式映射（Explicit mapping）"></a>显式映射（Explicit mapping）</h2><p>显式映射以完全控制字段的存储和索引方式。</p><p>显式映射的意义：</p><ul><li>区分全文本字符串字段和精确值字符串字段</li><li>执行特定语言的文本分析</li><li>优化字段进行部分匹配</li><li>自定义日期格式</li><li>无法自动检测到的数据类型，如地理信息</li></ul><h2 id="字段数据类型（Field-data-types）"><a href="#字段数据类型（Field-data-types）" class="headerlink" title="字段数据类型（Field data types）"></a>字段数据类型（Field data types）</h2><p>常见的类型：</p><ul><li>binary：二进制编码为Base64字符串</li><li>boolean：布尔值</li><li>Keywords：关键字，通常用于过滤、排序和聚合。包括keyword、constant_keyword和wildcard。</li><li>Numbers：数值类型，包括long、integer、short、byte、double、float</li><li>Dates：日期类型，包括date和date_nanos</li><li>alias：为现有字段定义别名</li></ul><p>对象和关系类型：</p><ul><li>object：JSON对象。扁平的键-值对列表</li><li>flattened：将整个JSON对象作为单个字段值</li><li>nested：保留其子字段之间关系的JSON对象，维护每个对象的独立性</li><li>join：为同一索引中的文档定义父/子关系</li></ul><p>结构化数据类型：</p><ul><li>Range：范围，包括long_range, double_range, date_range, and ip_range</li><li>ip：IPv4和IPv6地址</li><li>version：软件版本。特殊的关键字，用于处理软件版本值并支持它们的专用优先级规则</li><li>murmur3：计算和存储值的散列。提供了在索引时计算字段值的哈希并将其存储在索引中的功能</li></ul><p>聚合数据类型：</p><ul><li>aggregate_metric_double：度量值进行聚合</li><li>histogram：柱状图，以直方图形式聚合数值</li></ul><p>文本搜索类型：</p><ul><li>text：非结构化文本。配置分词器</li><li>annotated_text：注解文本。带有映射器注释的文本插件提供了索引文本的功能。如WWW与World Wide Web同义</li><li>completion：补全提示。是一个导航功能，引导用户在输入时查看相关结果，提高搜索精度</li><li>search_as_you_type：自定义搜索。类似文本的字段，经过优化提供开箱即用的按需输入搜索服务。如搜索框</li><li>token_count：符号计数。分词分析后对数量进行索引</li></ul><p>文档排名类型：</p><ul><li>rank_feature：记录一个数字特性，以便在查询中增强文档。</li></ul><p>空间数据类型：</p><ul><li>geo_point：经纬度</li><li>geo_shape：复杂的形状，如多边形</li></ul><p>元数据：</p><ul><li>_index：文档所属的索引</li><li>_id：文档ID</li><li>_doc_count：桶聚合（Bucket）返回字段，显示桶中已聚合和分区的文档数</li><li>_source：原始JSON文档</li><li>_size：_source字段的大小</li><li>_routing：自定义路由</li><li>_meta：元数据信息</li></ul><h2 id="映射参数（Mapping-parameters）"><a href="#映射参数（Mapping-parameters）" class="headerlink" title="映射参数（Mapping parameters）"></a>映射参数（Mapping parameters）</h2><ul><li>analyzer：text字段文本解析器</li><li>boots：增强匹配权重，默认1.0。如：title的匹配权重大于content匹配权重</li><li>coerce：强行类型转换，默认true。如：如string（“10”）强制转换为integer（10）</li><li>copy_to：将多个字段的值复制到同一字段中。如：first_name和last_name，复制到full_name</li><li>doc_values：开启字段的排序、聚合和脚本中访问字段，支持除了text和annotated_text的所有字段类型，默认true。本质上是列式存储，保持与原始文档字段相同的值，关闭可节省空间</li><li>dynamic：新检测到的字段添加到映射，默认true。false表示不建立索引，strict表示拒绝文档</li><li>eager_global_ordinals：全局序号映射。文档中字段的值仅存储序号，而不存原始内容，用于聚合时提高性能</li><li>enabled：尝试为字段建立索引，仅可应用于顶级映射和object类型下，默认true。如果禁用整个映射，意味着可以对其进行获取，但是不会以任何方式对它的内容建立索引</li><li>format：自定义日期格式</li><li>ignore_above：超过长度的字符串内容将不会被索引</li><li>ignore_malformed：忽略错误的数据类型插入到索引中。默认抛出异常并丢弃文档</li><li>index：控制是否对字段值建立索引，默认true。未索引的字段不可查询</li><li>index_options：控制哪些信息添加到倒排索引已进行搜索并突出显示，仅使用于文本字段</li><li>index_phrases：将两个词的组合词索引到一个单独的字段中。默认false</li><li>index_prefixes：为字段值的前缀编制索引，以加快前缀搜索速度</li><li>meta：附加到字段的元数据</li><li>fields：为不同的目的以不同的方式对同一字段建立索引</li><li>norms：用于计算查询的文档分数，默认true。对于仅用于过滤或聚合的字段，不需要对字段进行打分排序时设置为false</li><li>null_value：使用指定的值替换为null值，以便可以进行索引和搜索</li><li>position_increment_gap：当为具有多个值的文本字段建立索引时，将在值之间添加“假”间隙，以防止大多数短语查询在值之间进行匹配，默认值为100</li><li>properties：类型映射，object字段和nested字段包含子字段叫properties</li><li>search_analyzer：查询时使用指定的分析器</li><li>similarity：字段打分的相似性算法，默认BM25</li><li>store：单独存储属性值。默认对字段值进行索引以使其可搜索，但不单独存储它们，但是已存储在_source字段中</li><li>term_vector：存储分析过程的词矢量（Term vectors）信息。包括：词、位置、偏移量、有效载荷</li></ul><h2 id="映射限制设置（mapping-limit-settings）"><a href="#映射限制设置（mapping-limit-settings）" class="headerlink" title="映射限制设置（mapping limit settings）"></a>映射限制设置（mapping limit settings）</h2><p>索引中定义太多字段会导致映射爆炸，从而导致内存不足错误和难以恢复的情况。在动态映射中，如果每个新插入的文档都引入新字段，每个新字段都添加到索引映射中，随着映射的增长，这会成为一个问题。使用映射限制设置可以限制（手动或动态创建的）字段映射的数量，并防止文档引起映射爆炸。</p><ul><li>index.mapping.total_fields.limit: 字段最大数限制，默认1000</li><li>index.mapping.depth.limit: 字段的最大深度，默认20</li><li>index.mapping.nested_fields.limit: 单个索引中嵌套类型（nested）最大数限制，默认50</li><li>index.mapping.nested_objects.limit: 单个文档中嵌套JSON对象的最大数限制，默认10000</li></ul>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;Elasticsearch映射介绍，包括动态映射、显式映射、字段数据类型、映射参数、映射限制设置。&lt;br&gt; 内容大纲源自官方文档“Mapping”模块&lt;br&gt; 基于7.11版本。&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="技术" scheme="http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="ELK" scheme="http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/ELK/"/>
    
    
    <category term="技术" scheme="http://www.lights8080.com/tags/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="ELK" scheme="http://www.lights8080.com/tags/ELK/"/>
    
    <category term="Elasticsearch" scheme="http://www.lights8080.com/tags/Elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>语录-2</title>
    <link href="http://www.lights8080.com/2021/03/25/%E8%AF%AD%E5%BD%95/%E8%AF%AD%E5%BD%95-2/"/>
    <id>http://www.lights8080.com/2021/03/25/%E8%AF%AD%E5%BD%95/%E8%AF%AD%E5%BD%95-2/</id>
    <published>2021-03-24T16:00:00.000Z</published>
    <updated>2021-06-01T10:47:46.000Z</updated>
    
    <content type="html"><![CDATA[<ol><li>如果你像这样全速开上五分钟，就抵得上某些人碌碌无为的活一辈子</li><li>少许的牺牲是必须的</li></ol><span id="more"></span><h2 id="1-如果你像这样全速开上五分钟，就抵得上某些人碌碌无为的活一辈子。"><a href="#1-如果你像这样全速开上五分钟，就抵得上某些人碌碌无为的活一辈子。" class="headerlink" title="1. 如果你像这样全速开上五分钟，就抵得上某些人碌碌无为的活一辈子。"></a>1. 如果你像这样全速开上五分钟，就抵得上某些人碌碌无为的活一辈子。</h2><p>《世界上最快的印第安摩托》讲述伯特·孟若的真实故事，为了速度与极限，跨越半个地球前往美国犹他州的盐湖城参加世界机车大赛。他的摩托车甚至没有刹车、没有减速伞、没有灭火器，刷新了当时的世界纪录。此后他又多次刷新世界纪录，最后于1967年创下1000CC以下改装摩托车速度记录，至今无人打破。创纪录时他年近七十。</p><h4 id="电影中的语录："><a href="#电影中的语录：" class="headerlink" title="电影中的语录："></a>电影中的语录：</h4><p>活到我这把年纪，在世界上的每一天都是最好的一天。<br>做人如果没有梦想，还不如当颗白菜。<br>荣誉永远都不属于评论家，他们一直在等着别人犯错，然后告诉他们如何改进，荣誉只属于那些真正有行动的人。<br>于我而言，驰骋本身就是回报。<br>这是我这辈子最想做的大事，相比于其他家伙，做的更好，更大的事。<br>很多人都想让我们这些老东西，安安静静的一边等死，但是哥们我告诉你，还不到时候。<br>也许我外表上已经老态龙钟，但我的内心永远都是十八岁，年轻人，我依然可以跟你赛车赌钱。<br>你不知道这对我来说意味着什么，为了今天，我已经等了25年。<br>在追梦者眼里，所爱隔山海，山海皆可平。</p><p>解说最后总结的非常好：<br>“””<br>对一些人来说，梦想是人生中可有可无的调味品，如果生活不允许，那就放弃。但对另一部分人来说，梦想就是一辈子的事，是绝对无法妥协的事。所以，有些人是为梦想拼了命，有些人只是为梦想踮了踮脚尖。</p><p>我们普通人不是没有梦想，而是没有为梦想孤注一掷的信念，我们会计算得失，计算成本，会计算为梦想付出的代价是否值得，当我们在给梦想做这样的计算时，实际上我们已经做好了随时退缩的准备。<br>“””</p><h2 id="2-少许的牺牲是必须的"><a href="#2-少许的牺牲是必须的" class="headerlink" title="2. 少许的牺牲是必须的"></a>2. 少许的牺牲是必须的</h2><p>奥托·利林塔尔，滑翔机之父，从1891年～1896年，飞行试验次数多达2000次。最后一次飞行过程中因为一股风力，失去控制栽向地面，脊椎骨折，第二天逝世。临终前最后的一句话就是”少许的牺牲是必须的”。</p><p>但愿所有的人都能忠于自己，拥有一个梦想，并为之努力奋斗。最终实现不了也没关系，因为你就是被上天选中来凑数的。<br>也但愿梦想也不要像下面这位这么疯狂。</p><h2 id="3-《上吊的研究》"><a href="#3-《上吊的研究》" class="headerlink" title="3. 《上吊的研究》"></a>3. 《上吊的研究》</h2><p>尼古拉-米诺维奇。为了更好的研究绞刑，自己进行了十几次的上吊实验，每次做完实验清醒后，做的第一件事就是做记录。最终总结出了200多页的权威报告。</p>]]></content>
    
    
    <summary type="html">&lt;ol&gt;
&lt;li&gt;如果你像这样全速开上五分钟，就抵得上某些人碌碌无为的活一辈子&lt;/li&gt;
&lt;li&gt;少许的牺牲是必须的&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    <category term="语录" scheme="http://www.lights8080.com/categories/%E8%AF%AD%E5%BD%95/"/>
    
    
    <category term="语录" scheme="http://www.lights8080.com/tags/%E8%AF%AD%E5%BD%95/"/>
    
  </entry>
  
  <entry>
    <title>Logstash-配置</title>
    <link href="http://www.lights8080.com/2021/03/22/%E6%8A%80%E6%9C%AF/ELK/Logstash-%E9%85%8D%E7%BD%AE/"/>
    <id>http://www.lights8080.com/2021/03/22/%E6%8A%80%E6%9C%AF/ELK/Logstash-%E9%85%8D%E7%BD%AE/</id>
    <published>2021-03-22T03:27:15.000Z</published>
    <updated>2021-06-01T10:47:46.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Logstash配置介绍、插件说明、配置说明、高级配置、命令说明<br>基于7.11版本。<br><a href="https://www.elastic.co/guide/en/logstash/7.11/index.html">https://www.elastic.co/guide/en/logstash/7.11/index.html</a></p></blockquote><span id="more"></span><h2 id="一、配置Logstash"><a href="#一、配置Logstash" class="headerlink" title="一、配置Logstash"></a>一、配置Logstash</h2><p>配置 Logstash，你需要创建一个配置文件来指定想要使用的插件和每个插件的设置。可以引用配置中的事件字段，并在事件满足某些条件时使用条件来处理它们。运行logstash时使用-f指定配置文件。</p><p>每种类型的插件都有一个单独的部分，每个部分都包含一个或多个插件的配置选项。如果指定多个过滤器，则会按照它们在配置文件中出现的顺序进行应用。</p><p>logstash-simple.conf</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">input</span> &#123; <span class="string">stdin</span> &#123; &#125; &#125;</span><br><span class="line"><span class="string">filter</span> &#123;</span><br><span class="line">  <span class="string">grok</span> &#123;</span><br><span class="line">    <span class="string">match</span> <span class="string">=&gt;</span> &#123; <span class="string">&quot;message&quot;</span> <span class="string">=&gt;</span> <span class="string">&quot;<span class="template-variable">%&#123;COMBINEDAPACHELOG&#125;</span>&quot;</span> &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="string">date</span> &#123;</span><br><span class="line">    <span class="string">match</span> <span class="string">=&gt;</span> [ <span class="string">&quot;timestamp&quot;</span> , <span class="string">&quot;dd/MMM/yyyy:HH:mm:ss Z&quot;</span> ]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="string">output</span> &#123;</span><br><span class="line">  <span class="string">elasticsearch</span> &#123; <span class="string">hosts</span> <span class="string">=&gt;</span> [<span class="string">&quot;localhost:9200&quot;</span>] &#125;</span><br><span class="line">  <span class="string">stdout</span> &#123; <span class="string">codec</span> <span class="string">=&gt;</span> <span class="string">rubydebug</span> &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="1-在配置中访问事件数据和字段"><a href="#1-在配置中访问事件数据和字段" class="headerlink" title="1. 在配置中访问事件数据和字段"></a>1. 在配置中访问事件数据和字段</h3><p>Logstash中的某些配置选项需要使用事件的字段。因为输入会生成事件，所以输入块中没有要评估的字段，因为它们还不存在。</p><h4 id="引用事件数据和字段"><a href="#引用事件数据和字段" class="headerlink" title="引用事件数据和字段"></a>引用事件数据和字段</h4><p>仅在过滤器和输出块内起作用。基本语法是[fieldname]，引用顶级字段时可以去掉[]，引用嵌套字段时，要指定完成整路径[top-level field][nested field]。</p><h4 id="sprintf格式化"><a href="#sprintf格式化" class="headerlink" title="sprintf格式化"></a>sprintf格式化</h4><p>引用事件字段：increment =&gt; “apache.%{[response][status]}”<br>引用事件日期和类型：path =&gt; “/var/log/%{type}.%{+yyyy.MM.dd.HH}”</p><h4 id="条件"><a href="#条件" class="headerlink" title="条件"></a>条件</h4><p>只想在特定条件下过滤或输出事件，这时可以使用条件。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">if EXPRESSION &#123;</span><br><span class="line">  ...</span><br><span class="line">&#125; else if EXPRESSION &#123;</span><br><span class="line">  ...</span><br><span class="line">&#125; else &#123;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li>比较运算符:<br>equality: ==, !=, &lt;, &gt;, &lt;=, &gt;=<br>regexp: =<del>, !</del> (checks a pattern on the right against a string value on the left)<br>inclusion: in, not in</li><li>布尔运算符:<br>and, or, nand, xor</li><li>一元运算符：<br>!（取反）</li></ol><p>还可以使用<code>(...)</code>，对表达式进行分组。</p><h4 id="metadata字段"><a href="#metadata字段" class="headerlink" title="@metadata字段"></a>@metadata字段</h4><p>一个特殊的字段，在输出时不会成为任何事件的一部分。非常适用于做条件，扩展和构建事件字段等</p><h2 id="二、插件说明"><a href="#二、插件说明" class="headerlink" title="二、插件说明"></a>二、插件说明</h2><h3 id="Input-plugins"><a href="#Input-plugins" class="headerlink" title="Input plugins"></a>Input plugins</h3><ul><li>beats</li><li>file</li><li>kafka</li></ul><h3 id="Filter-plugins"><a href="#Filter-plugins" class="headerlink" title="Filter plugins"></a>Filter plugins</h3><ul><li><p>aggregate<br>聚合属于同一任务的多个事件（通常是日志行）中的可用信息，最后将聚合的信息推送到最终任务事件中</p></li><li><p>clone<br>克隆事件，原始事件保持不变。新事件作为正常的事件插入到管道中，并从生成事件的过滤器开始继续执行。</p></li><li><p>date<br>解析字段中的日期，然后使用该日期或时间戳作为事件的Logstash的时间戳</p></li><li><p>Grok filter plugin<br>解析任何文本并将其结构化。适用于文本的结构是逐行变化。%{SYNTAX:SEMANTIC}<br><a href="https://github.com/logstash-plugins/logstash-patterns-core/blob/3cdd3f6c81/patterns/grok-patterns">grok-patterns</a></p></li><li><p>Dissect filter plugin<br>适用于界定符拆分，不使用正则表达式，而且速度非常快。%{id-&gt;} %{function} %{+ts}</p></li></ul><ol><li><code>%&#123;+ts&#125;</code>：表示前面已经捕获到一个ts字段了，而这次捕获的内容，自动添补到之前ts字段内容的后面</li><li><code>-&gt;</code>：表示忽略它右边的填充</li><li><code>%&#123;+key/2&#125;</code>：表示在有多次捕获内容都填到key字段里的时候，拼接字符串的顺序谁前谁后。/2表示排第2位</li><li><code>%&#123;&#125;</code>：表示是一个空的跳过字段</li><li><code>%&#123;?string&#125;</code>：表示这块只是一个占位，并不会实际生成捕获字段存到事件里面</li><li><code>%&#123;?string&#125; %&#123;&amp;string&#125;</code>：表示当同样捕获名称都是string，但是一个?一个&amp;的时候，表示这是一个键值对</li></ol><ul><li><p>drop<br>删除到达此过滤器的所有内容</p></li><li><p>elapsed<br>跟踪一对开始/结束事件，并使用它们的时间戳来计算它们之间的经过时间</p></li><li><p>elasticsearch<br>在Elasticsearch中搜索上一个日志事件，并将其中的某些字段复制到当前事件中</p></li><li><p>fingerprint<br>创建一个或多个字段的一致哈希（指纹），并将结果存储在新字段中</p></li><li><p>geoip<br>根据来自Maxmind GeoLite2数据库的数据添加有关IP地址地理位置的信息</p></li><li><p>http<br>提供了与外部Web服务/ REST API的集成。</p></li><li><p>java_uuid<br>允许您生成UUID并将其作为字段添加到每个已处理事件</p></li><li><p>uuid<br>uuid过滤器允许您生成UUID并将其作为字段添加到每个已处理事件。</p></li><li><p>jdbc_static<br>通过从远程数据库预加载的数据来丰富事件</p></li><li><p>jdbc_streaming<br>执行SQL查询，并将结果集存储在指定为目标的字段中。它会将结果本地缓存到过期的LRU缓存中</p></li><li><p>json<br>这是一个JSON解析过滤器。它采用一个包含JSON的现有字段，并将其扩展为Logstash事件内的实际数据结构</p></li><li><p>kv<br>有助于自动解析foo=bar种类的消息（或特定事件字段）</p></li><li><p>metrics<br>对于汇总指标很有用</p></li><li><p>mutate<br>可以重命名，删除，替换和修改事件中的字段。需要注意的是，一个mutate块中的命令执行是有序的<code>coerce -&gt; ... -&gt; copy</code>，可以使用多个mutate块控制执行顺序。<br>coerce: 设置空字段的默认值<br>replace: 从事件中的其他部分构件一个新值，替换掉已有字段<br>strip: 删除字段的前后空格<br>update: 用新值更新现有字段，该字段不存在不采取任何操作<br>gsub: 正则表达式匹配，将所有的匹配项更新为替换的字符串，只支持字符串和字符串数组，其他类型不采取任何操作<br>join: 用分隔符连接数组，非数组字段不采取任何操作<br>convert: 将字段的值转换为其他类型，如字符串转整数</p></li><li><p>prune<br>用于根据字段名称或其值的白名单或黑名单从事件中删除字段（名称和值也可以是正则表达式）。如果使用json/kv过滤器解析出来一些不是事先知道的字段，只想保留其中一部分，这个功能很有用</p></li><li><p>range<br>用于检查某些字段是否在预期的大小/长度范围内。支持的类型是数字和字符串。当在指定范围内时，执行一个操作。</p></li><li><p>ruby<br>接受嵌入式Ruby代码或Ruby文件</p></li><li><p>sleep<br>睡眠一定时间。这将导致logstash在给定的时间内停止运行。这对于速率限制等很有用</p></li><li><p>throttle<br>节流过滤器用于限制事件数量</p></li><li><p>translate<br>使用配置的哈希或文件确定替换值的常规搜索和替换工具。当前支持的是YAML，JSON和CSV文件。每个字典项目都是一个键值对</p></li><li><p>truncate<br>允许您截断长度超过给定长度的字段</p></li><li><p>urldecode<br>解码经过urlencoded的字段</p></li><li><p>useragent<br>UserAgent过滤器，添加有关用户代理的信息，例如家族，操作系统，版本和设备</p></li><li><p>xml<br>XML过滤器。获取一个包含XML的字段，并将其扩展为实际的数据结构</p></li></ul><h3 id="Output-plugins"><a href="#Output-plugins" class="headerlink" title="Output plugins"></a>Output plugins</h3><ul><li>elasticsearch</li><li>file</li><li>stdout</li><li>exec</li></ul><h2 id="三、配置说明"><a href="#三、配置说明" class="headerlink" title="三、配置说明"></a>三、配置说明</h2><p>包括：logstash.yaml、pipelines.yml、jvm.options、log4j2.properties、startup.options</p><h3 id="logstash-yml"><a href="#logstash-yml" class="headerlink" title="logstash.yml"></a>logstash.yml</h3><blockquote><p>Logstash配置选项可以控制Logstash的执行。如：指定管道设置、配置文件位置、日志记录选项等。运行Logstash时，大多数配置可以命令行中指定，并覆盖文件的相关配置。</p></blockquote><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">node.name:</span> <span class="string">`hostname`</span></span><br><span class="line"><span class="attr">path.data:</span> <span class="string">LOGSTASH_HOME/data</span></span><br><span class="line"><span class="attr">path.logs:</span> <span class="string">LOGSTASH_HOME/logs</span></span><br><span class="line"><span class="comment"># 指定main pipeline的配置文件路径</span></span><br><span class="line"><span class="attr">path.config:</span> </span><br><span class="line"><span class="comment"># 指定main pipeline的配置数据。语法同配置文件</span></span><br><span class="line"><span class="attr">config.string:</span> </span><br><span class="line"><span class="comment"># 开启后，检查配置是否有效，然后退出</span></span><br><span class="line"><span class="attr">config.test_and_exit:</span> <span class="literal">false</span></span><br><span class="line"><span class="comment"># 开启后，修改配置文件自动加载，过程：暂停管道所有输入；创新新管道并检验配置；检查成功切换到新管道，失败则继续使用老的管道。</span></span><br><span class="line"><span class="attr">config.reload.automatic:</span> <span class="literal">false</span></span><br><span class="line"><span class="comment"># 检查配置文件更新的时间间隔</span></span><br><span class="line"><span class="attr">config.reload.interval:</span> <span class="string">3s</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 内部队列模型，memory(default)：内存，persisted：磁盘</span></span><br><span class="line"><span class="attr">queue.type:</span> <span class="string">memory</span></span><br><span class="line"><span class="comment"># 持久队列的数据文件存储路径（queue.type: persisted时启用）</span></span><br><span class="line"><span class="attr">path.queue:</span> <span class="string">path.data/queue</span></span><br><span class="line"><span class="comment"># 持久队列的页容量，持久化以页为单位</span></span><br><span class="line"><span class="attr">queue.page_capacity:</span> <span class="string">64mb</span></span><br><span class="line"><span class="comment"># 开启后，关闭logstash之前等待持久队列消耗完毕</span></span><br><span class="line"><span class="attr">queue.drain:</span> <span class="literal">false</span></span><br><span class="line"><span class="comment"># 队列中允许的最大事件数，默认0表示无限制</span></span><br><span class="line"><span class="attr">queue.max_events:</span> <span class="number">0</span></span><br><span class="line"><span class="comment"># 事件缓冲的内部队列的总容量，达到限制时Logstash将不再接受新事件</span></span><br><span class="line"><span class="attr">queue.max_bytes:</span> <span class="string">1024mb</span></span><br><span class="line"><span class="comment"># 强制执行检查点之前的最大ACKed事件数</span></span><br><span class="line"><span class="attr">queue.checkpoint.acks:</span> <span class="number">1024</span></span><br><span class="line"><span class="comment"># 强制执行检查点之前，可以写入磁盘的最大事件数</span></span><br><span class="line"><span class="attr">queue.checkpoint.writes:</span> <span class="number">1024</span></span><br><span class="line"><span class="comment"># 对每次检查点写入失败将重试一次</span></span><br><span class="line"><span class="attr">queue.checkpoint.retry:</span> <span class="literal">false</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># metrics REST endpoint绑定的地址和端口</span></span><br><span class="line"><span class="attr">http.host:</span> <span class="string">&quot;127.0.0.1&quot;</span></span><br><span class="line"><span class="attr">http.port:</span> <span class="number">9600</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 工作线程ID</span></span><br><span class="line"><span class="attr">pipeline.id:</span> <span class="string">main</span></span><br><span class="line"><span class="comment"># 控制事件排序，auto：如果`pipeline.workers: 1`开启排序。true：如果有多个工作线程，强制对管道进行排序，并防止Logstash启动。false：禁用排序所需的处理，节省处理成本。</span></span><br><span class="line"><span class="attr">pipeline.ordered:</span> <span class="string">auto</span></span><br><span class="line"><span class="comment"># 管道筛选和输出阶段的工作线程数，CPU没有饱和可以增加此数字更好的利用机器处理能力。</span></span><br><span class="line"><span class="attr">pipeline.workers:</span> <span class="string">`number</span> <span class="string">of</span> <span class="string">cpu</span> <span class="string">cores`</span></span><br><span class="line"><span class="comment"># 单个工作线程在发送到filters+workers之前，从输入中获取的最大事件数</span></span><br><span class="line"><span class="attr">pipeline.batch.size:</span> <span class="number">125</span></span><br><span class="line"><span class="comment"># 将小批量事件派送到filters+outputs之前，轮询下一个事件等待毫秒时间，可以理解为未到达批处理最大事件数时延迟发送时间</span></span><br><span class="line"><span class="attr">pipeline.batch.delay:</span> <span class="number">50</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 开启后，每个pipeline分割为不同的日志，使用pipeline.id作为文件名</span></span><br><span class="line"><span class="attr">pipeline.separate_logs:</span> <span class="literal">false</span></span><br><span class="line"><span class="comment"># 开启后，强行退出可能会导致关机期间丢失数据</span></span><br><span class="line"><span class="attr">pipeline.unsafe_shutdown:</span> <span class="literal">false</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 启用死信队列，默认false</span></span><br><span class="line"><span class="attr">dead_letter_queue.enable:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">dead_letter_queue.max_bytes:</span> <span class="string">1024mb</span></span><br><span class="line"><span class="attr">path.dead_letter_queue:</span> <span class="string">path.data/dead_letter_queue</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 指定自定义插件的位置</span></span><br><span class="line"><span class="attr">path.plugins:</span> </span><br><span class="line"><span class="comment"># 配置模块，遵循yaml结构</span></span><br><span class="line"><span class="attr">modules:</span></span><br></pre></td></tr></table></figure><h2 id="四、高级配置"><a href="#四、高级配置" class="headerlink" title="四、高级配置"></a>四、高级配置</h2><h3 id="1-多管道配置（multiple-pipelines-configuration）"><a href="#1-多管道配置（multiple-pipelines-configuration）" class="headerlink" title="1. 多管道配置（multiple pipelines configuration）"></a>1. 多管道配置（multiple pipelines configuration）</h3><p>如果需要在同一个进程中运行多个管道，通过配置pipelines.yml文件来处理，必须放在path.settings文件夹中。并遵循以下结构：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># config/pipelines.yml</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">pipeline.id:</span> <span class="string">my-pipeline_1</span></span><br><span class="line">  <span class="attr">path.config:</span> <span class="string">&quot;/etc/path/to/p1.config&quot;</span></span><br><span class="line">  <span class="attr">pipeline.workers:</span> <span class="number">3</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">pipeline.id:</span> <span class="string">my-other-pipeline</span></span><br><span class="line">  <span class="attr">path.config:</span> <span class="string">&quot;/etc/different/path/p2.cfg&quot;</span></span><br><span class="line">  <span class="attr">queue.type:</span> <span class="string">persisted</span></span><br></pre></td></tr></table></figure><p>不带任何参数启动Logstash时，将读取pipelines.yml文件并实例化该文件中指定的所有管道。如果使用-e或-f时，Logstash会忽略pipelines.yml文件并记录相关警告。</p><ul><li>如果当前的配置中的事件流不共享相同的输入/过滤器和输出，并且使用标签和条件相互分隔，则使用多个管道特别有用。</li><li>在单个实例中具有多个管道还可以使这些事件流具有不同的性能和持久性参数（例如，工作线程数和持久队列的不同设置）。</li></ul><h3 id="2-管道到管道的通信（pipeline-to-pipeline-Communication）"><a href="#2-管道到管道的通信（pipeline-to-pipeline-Communication）" class="headerlink" title="2. 管道到管道的通信（pipeline-to-pipeline Communication）"></a>2. 管道到管道的通信（pipeline-to-pipeline Communication）</h3><p>使用Logstash的多管道功能时，可以在同一Logstash实例中连接多个管道。此配置对于隔离这些管道的执行以及有助于打破复杂管道的逻辑很有用。</p><h3 id="3-重新加载配置文件（Reloading-the-Config-File）"><a href="#3-重新加载配置文件（Reloading-the-Config-File）" class="headerlink" title="3. 重新加载配置文件（Reloading the Config File）"></a>3. 重新加载配置文件（Reloading the Config File）</h3><p>如果没有开启自动重新加载（–config.reload.automatic），可以强制Logstash重新加载配置文件并重新启动管道。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kill -SIGHUP 14175</span><br></pre></td></tr></table></figure><h3 id="4-管理多行事件（Managing-Multiline-Events）"><a href="#4-管理多行事件（Managing-Multiline-Events）" class="headerlink" title="4. 管理多行事件（Managing Multiline Events）"></a>4. 管理多行事件（Managing Multiline Events）</h3><h3 id="5-Glob模式支持（glob-pattern-support）"><a href="#5-Glob模式支持（glob-pattern-support）" class="headerlink" title="5. Glob模式支持（glob pattern support）"></a>5. Glob模式支持（glob pattern support）</h3><p>注意Logstash不会按照glob表达式中编写的文件顺序执行，是按照字母顺序对其进行排序执行的。</p><h3 id="6-Logstash到Logstash通讯（Logstash-to-Logstash-Communication）"><a href="#6-Logstash到Logstash通讯（Logstash-to-Logstash-Communication）" class="headerlink" title="6. Logstash到Logstash通讯（Logstash-to-Logstash Communication）"></a>6. Logstash到Logstash通讯（Logstash-to-Logstash Communication）</h3><h3 id="7-Ingest-Node解析数据转换到Logstash解析数据（Converting-Ingest-Node-Pipelines）"><a href="#7-Ingest-Node解析数据转换到Logstash解析数据（Converting-Ingest-Node-Pipelines）" class="headerlink" title="7. Ingest Node解析数据转换到Logstash解析数据（Converting Ingest Node Pipelines）"></a>7. Ingest Node解析数据转换到Logstash解析数据（Converting Ingest Node Pipelines）</h3><h3 id="8-集中配置管理（Centralized-Pipeline-Management）"><a href="#8-集中配置管理（Centralized-Pipeline-Management）" class="headerlink" title="8. 集中配置管理（Centralized Pipeline Management）"></a>8. 集中配置管理（Centralized Pipeline Management）</h3><h2 id="五、命令说明"><a href="#五、命令说明" class="headerlink" title="五、命令说明"></a>五、命令说明</h2><p>命令行上设置的所有参数都会覆盖logstash.yml中的相应设置。生产环境建议使用logstash.yml控制Logstash执行。</p><p>参数：</p><ul><li>–node.name NAME：指定Logstash实例的名称，默认当前主机名</li><li>-f, –path.config CONFIG_PATH：加载Logstash配置的文件或目录</li><li>-e, –config.string CONFIG_STRING：Logstash配置数据，如果未指定输入，则使用<code>input &#123; stdin &#123; type =&gt; stdin &#125; &#125;</code>作为默认的输入，如果未指定输出，则使用<code>output &#123; stdout &#123; codec =&gt; rubydebug &#125; &#125;</code>作为默认的输出。</li><li>-M “CONFIG_SETTING=VALUE”：覆盖指定的配置</li><li>–config.test_and_exit: 检查配置是否有效，然后退出</li><li>–config.reload.automatic: 修改配置文件自动加载</li><li>–modules MODULE_NAME：指定运行的模块名称</li><li>–setup：是一次性设置步骤，在Elasticsearch中创建索引模式并导入Kibana仪表板和可视化文件。</li><li>…</li></ul><p>示例：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/logstash -f logstash-simple.conf --config.reload.automatic</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;Logstash配置介绍、插件说明、配置说明、高级配置、命令说明&lt;br&gt;基于7.11版本。&lt;br&gt;&lt;a href=&quot;https://www.elastic.co/guide/en/logstash/7.11/index.html&quot;&gt;https://www.elastic.co/guide/en/logstash/7.11/index.html&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="技术" scheme="http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="ELK" scheme="http://www.lights8080.com/categories/%E6%8A%80%E6%9C%AF/ELK/"/>
    
    
    <category term="技术" scheme="http://www.lights8080.com/tags/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="ELK" scheme="http://www.lights8080.com/tags/ELK/"/>
    
    <category term="Logstash" scheme="http://www.lights8080.com/tags/Logstash/"/>
    
  </entry>
  
</feed>
